{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer,HashingVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD,SparsePCA\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,f1_score,recall_score\n",
    "\n",
    "import gc\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = \"../pickle\"\n",
    "vector_path = \"../vector\"\n",
    "\n",
    "app_data_nlp = pd.read_pickle(\"{}/device_new_app.pickle\".format(pickle_path))\n",
    "user_fav_nlp = pd.read_pickle(\"{}/tag_weight_new_data.pickle\".format(pickle_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deviceid</th>\n",
       "      <th>applist</th>\n",
       "      <th>app_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000046581b8a28c431be90c278674925</td>\n",
       "      <td>[app_133, app_1]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016381ab699d4e76dc99291e79e7a1</td>\n",
       "      <td>[app_133]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001c7e6a85a3a4498fe0c5f29f3a379</td>\n",
       "      <td>[app_133]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000207c515d01c00e9144c6866b546a7</td>\n",
       "      <td>[app_133, app_1]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000355d66e3fe127c8c2dd1ef60322a3</td>\n",
       "      <td>[app_84, app_85, app_4, app_5, app_86, app_87,...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           deviceid  \\\n",
       "0  000046581b8a28c431be90c278674925   \n",
       "1  00016381ab699d4e76dc99291e79e7a1   \n",
       "2  0001c7e6a85a3a4498fe0c5f29f3a379   \n",
       "3  000207c515d01c00e9144c6866b546a7   \n",
       "4  000355d66e3fe127c8c2dd1ef60322a3   \n",
       "\n",
       "                                             applist  app_len  \n",
       "0                                   [app_133, app_1]        2  \n",
       "1                                          [app_133]        1  \n",
       "2                                          [app_133]        1  \n",
       "3                                   [app_133, app_1]        2  \n",
       "4  [app_84, app_85, app_4, app_5, app_86, app_87,...       86  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_data_nlp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deviceid</th>\n",
       "      <th>all_tag_word</th>\n",
       "      <th>all_tag_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000046581b8a28c431be90c278674925</td>\n",
       "      <td>[美食, --其他, 美食攻略, 花絮片段, 玩具, 吃秀, 社会热点, 中医, 片段, 大...</td>\n",
       "      <td>[0.4171913341996304, 0.36140167938226964, 0.35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016381ab699d4e76dc99291e79e7a1</td>\n",
       "      <td>[未知]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001c7e6a85a3a4498fe0c5f29f3a379</td>\n",
       "      <td>[社会热点, --其他, 古代, 范冰冰, 台湾, 李治廷, 彦希, 灰姑娘, 清朝, 总裁...</td>\n",
       "      <td>[0.8310844893612963, 0.3135020218516166, 6.367...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000207c515d01c00e9144c6866b546a7</td>\n",
       "      <td>[海军, 航母, 导弹, 武器, 武器, 导弹, 洲际导弹, 大妈, 海军, 航母, 网游,...</td>\n",
       "      <td>[17.15805189101101, 13.780793638746603, 13.220...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000355d66e3fe127c8c2dd1ef60322a3</td>\n",
       "      <td>[东北, 大盘, 菜谱]</td>\n",
       "      <td>[37.141856323864594, 35.747926949211916, 4.949...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           deviceid  \\\n",
       "0  000046581b8a28c431be90c278674925   \n",
       "1  00016381ab699d4e76dc99291e79e7a1   \n",
       "2  0001c7e6a85a3a4498fe0c5f29f3a379   \n",
       "3  000207c515d01c00e9144c6866b546a7   \n",
       "4  000355d66e3fe127c8c2dd1ef60322a3   \n",
       "\n",
       "                                        all_tag_word  \\\n",
       "0  [美食, --其他, 美食攻略, 花絮片段, 玩具, 吃秀, 社会热点, 中医, 片段, 大...   \n",
       "1                                               [未知]   \n",
       "2  [社会热点, --其他, 古代, 范冰冰, 台湾, 李治廷, 彦希, 灰姑娘, 清朝, 总裁...   \n",
       "3  [海军, 航母, 导弹, 武器, 武器, 导弹, 洲际导弹, 大妈, 海军, 航母, 网游,...   \n",
       "4                                       [东北, 大盘, 菜谱]   \n",
       "\n",
       "                                      all_tag_weight  \n",
       "0  [0.4171913341996304, 0.36140167938226964, 0.35...  \n",
       "1                                                [0]  \n",
       "2  [0.8310844893612963, 0.3135020218516166, 6.367...  \n",
       "3  [17.15805189101101, 13.780793638746603, 13.220...  \n",
       "4  [37.141856323864594, 35.747926949211916, 4.949...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_fav_nlp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 12 training epochs with 30 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "36.16325783729553\n",
      "Performing 12 training epochs with 30 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "121.92749738693237\n"
     ]
    }
   ],
   "source": [
    "#glove model\n",
    "from glove import *\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "c = Corpus()\n",
    "c.fit(app_data_nlp['applist'].values)\n",
    "glove = Glove(no_components=300, learning_rate=0.05) \n",
    "glove.fit(c.matrix,epochs=12,no_threads=30,verbose=1)\n",
    "glove.add_dictionary(c.dictionary)\n",
    "glove.save(\"{}/app_data_glove300.model\".format(vector_path))\n",
    "print(time.time()-t1)\n",
    "# 耗时51.98334240913391\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "c = Corpus()\n",
    "c.fit(user_fav_nlp['all_tag_word'].values)\n",
    "glove = Glove(no_components=300, learning_rate=0.05) \n",
    "glove.fit(c.matrix,epochs=12,no_threads=30,verbose=1)\n",
    "glove.add_dictionary(c.dictionary)\n",
    "glove.save(\"{}/user_favorite_glove300.model\".format(vector_path))\n",
    "print(time.time()-t1)\n",
    "# 耗时179.15632033348083"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.68525004386902\n",
      "41.50236511230469\n"
     ]
    }
   ],
   "source": [
    "# Gen W2V Vector\n",
    "from gensim import models\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "w2v = models.Word2Vec(app_data_nlp['applist'].values, size=300, window=20, workers=40,hs=1) # 设置sg的话 变成skip-gram方法 我们测试效果差不多\n",
    "w2v.wv.save_word2vec_format(\"{}/app_data_w2v300.model\".format(vector_path))\n",
    "print(time.time()-t1)\n",
    "# 耗时19.42617154121399\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "w2v = models.Word2Vec(user_fav_nlp['all_tag_word'].values, size=300, window=20, workers=40,hs=1) # 设置sg的话 变成skip-gram方法 我们测试效果差不多\n",
    "w2v.wv.save_word2vec_format(\"{}/user_fav_w2v300.model\".format(vector_path))\n",
    "print(time.time()-t1)\n",
    "# 耗时43.82200646400452"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.697256326675415\n",
      "5.720769643783569\n"
     ]
    }
   ],
   "source": [
    "t = []\n",
    "c = []\n",
    "\n",
    "t1 = time.time()\n",
    "tfidf = TfidfVectorizer(analyzer='word',token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\",min_df=1,ngram_range=(1,1))\n",
    "t.append(tfidf.fit_transform(app_data_nlp['applist'].map(lambda x:' '.join(x)).values))\n",
    "cv = CountVectorizer(analyzer='word',token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\",min_df=1,ngram_range=(1,1))\n",
    "c.append(cv.fit_transform(app_data_nlp['applist'].map(lambda x:' '.join(x)).values))  \n",
    "print(time.time()-t1)\n",
    "\n",
    "t1 = time.time()\n",
    "tfidf = TfidfVectorizer(analyzer='word',token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\",min_df=1,ngram_range=(1,1))\n",
    "t.append(tfidf.fit_transform(user_fav_nlp['all_tag_word'].map(lambda x:' '.join(x)).values))\n",
    "cv = CountVectorizer(analyzer='word',token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\",min_df=1,ngram_range=(1,1))\n",
    "c.append(cv.fit_transform(user_fav_nlp['all_tag_word'].map(lambda x:' '.join(x)).values))\n",
    "print(time.time()-t1)\n",
    "\n",
    "from scipy import sparse\n",
    "if not os.path.exists(\"{}/Sparse_Matrix\".format(vector_path)):\n",
    "    os.mkdir(\"{}/Sparse_Matrix\".format(vector_path))\n",
    "sparse.save_npz('{}/Sparse_Matrix/app_data_tfidf.npz'.format(vector_path), t[0])\n",
    "sparse.save_npz('{}/Sparse_Matrix/user_fav_tfidf.npz'.format(vector_path), t[1])\n",
    "\n",
    "sparse.save_npz('{}/Sparse_Matrix/app_data_count.npz'.format(vector_path), c[0])\n",
    "sparse.save_npz('{}/Sparse_Matrix/user_fav_count.npz'.format(vector_path), c[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<114584x25730 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2092443 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<114584x25730 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2092443 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
