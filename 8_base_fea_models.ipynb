{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from scipy.stats import entropy\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "import gc\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from tqdm.autonotebook import *\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from gensim.models import FastText, Word2Vec\n",
    "import re\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import *\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "import keras.backend as K\n",
    "from keras.optimizers import *\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import logging\n",
    "import gensim\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    print('{:.2f} Mb, {:.2f} Mb ({:.2f} %)'.format(start_mem, end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    gc.collect()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================== read train ===============================================\n",
      "runtime: 53.88511657714844\n",
      "=============================================== click data ===============================================\n",
      "runtime: 60.337608337402344\n",
      "=============================================== read test ===============================================\n",
      "runtime: 82.82342743873596\n"
     ]
    }
   ],
   "source": [
    "print('=============================================== read train ===============================================')\n",
    "t = time.time()\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "train_df['date'] = pd.to_datetime(\n",
    "    train_df['ts'].apply(lambda x: time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(x / 1000)))\n",
    ")\n",
    "train_df['day'] = train_df['date'].dt.day\n",
    "train_df.loc[train_df['day'] == 7, 'day'] = 8\n",
    "train_df['hour'] = train_df['date'].dt.hour\n",
    "train_df['minute'] = train_df['date'].dt.minute\n",
    "train_num = train_df.shape[0]\n",
    "labels = train_df['target'].values\n",
    "print('runtime:', time.time() - t)\n",
    "\n",
    "print('=============================================== click data ===============================================')\n",
    "click_df = train_df[train_df['target'] == 1].sort_values('timestamp').reset_index(drop=True)\n",
    "click_df['exposure_click_gap'] = click_df['timestamp'] - click_df['ts']\n",
    "click_df = click_df[click_df['exposure_click_gap'] >= 0].reset_index(drop=True)\n",
    "click_df['date'] = pd.to_datetime(\n",
    "    click_df['timestamp'].apply(lambda x: time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(x / 1000)))\n",
    ")\n",
    "click_df['day'] = click_df['date'].dt.day\n",
    "click_df.loc[click_df['day'] == 7, 'day'] = 8\n",
    "del train_df['target'], train_df['timestamp']\n",
    "for f in ['date', 'exposure_click_gap', 'timestamp', 'ts', 'target', 'hour', 'minute']:\n",
    "    del click_df[f]\n",
    "print('runtime:', time.time() - t)\n",
    "\n",
    "print('=============================================== read test ===============================================')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "test_df['date'] = pd.to_datetime(\n",
    "    test_df['ts'].apply(lambda x: time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(x / 1000)))\n",
    ")\n",
    "test_df['day'] = test_df['date'].dt.day\n",
    "test_df.loc[test_df['day'] == 10, 'day'] = 11\n",
    "test_df['hour'] = test_df['date'].dt.hour\n",
    "test_df['minute'] = test_df['date'].dt.minute\n",
    "df = pd.concat([train_df, test_df], axis=0, ignore_index=False)\n",
    "del train_df, test_df, df['date']\n",
    "gc.collect()\n",
    "print('runtime:', time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================== cate enc ===============================================\n",
      "deviceid\n",
      "newsid\n",
      "pos\n",
      "app_version\n",
      "device_vendor\n",
      "netmodel\n",
      "osversion\n",
      "device_version\n",
      "lng\n",
      "lat\n",
      "lng_lat\n",
      "2580.12 Mb, 1390.40 Mb (46.11 %)\n",
      "77.91 Mb, 46.97 Mb (39.71 %)\n",
      "1204.05 Mb, 673.70 Mb (44.05 %)\n",
      "runtime: 237.66832995414734\n"
     ]
    }
   ],
   "source": [
    "print('=============================================== cate enc ===============================================')\n",
    "df['lng_lat'] = df['lng'].astype('str') + '_' + df['lat'].astype('str')\n",
    "del df['guid']\n",
    "click_df['lng_lat'] = click_df['lng'].astype('str') + '_' + click_df['lat'].astype('str')\n",
    "sort_df = df.sort_values('ts').reset_index(drop=True)\n",
    "cate_cols = [\n",
    "    'deviceid', 'newsid', 'pos', 'app_version', 'device_vendor',\n",
    "    'netmodel', 'osversion', 'device_version', 'lng', 'lat', 'lng_lat'\n",
    "]\n",
    "for f in cate_cols:\n",
    "    print(f)\n",
    "    if(f == 'deviceid'):\n",
    "        map_dict_deviceid = dict(zip(df[f].unique(), range(df[f].nunique())))\n",
    "        df[f] = df[f].map(map_dict_deviceid).fillna(-1).astype('int32')\n",
    "        click_df[f] = click_df[f].map(map_dict_deviceid).fillna(-1).astype('int32')\n",
    "        sort_df[f] = sort_df[f].map(map_dict_deviceid).fillna(-1).astype('int32')\n",
    "        df[f + '_count'] = df[f].map(df[f].value_counts())\n",
    "    if(f == 'newsid'):\n",
    "        map_dict_newsid = dict(zip(df[f].unique(), range(df[f].nunique())))\n",
    "        df[f] = df[f].map(map_dict_newsid).fillna(-1).astype('int32')\n",
    "        click_df[f] = click_df[f].map(map_dict_newsid).fillna(-1).astype('int32')\n",
    "        sort_df[f] = sort_df[f].map(map_dict_newsid).fillna(-1).astype('int32')\n",
    "        df[f + '_count'] = df[f].map(df[f].value_counts())\n",
    "    if(f == 'lng_lat'):\n",
    "        map_dict_ll = dict(zip(df[f].unique(), range(df[f].nunique())))\n",
    "        df[f] = df[f].map(map_dict_ll).fillna(-1).astype('int32')\n",
    "        click_df[f] = click_df[f].map(map_dict_ll).fillna(-1).astype('int32')\n",
    "        sort_df[f] = sort_df[f].map(map_dict_ll).fillna(-1).astype('int32')\n",
    "        df[f + '_count'] = df[f].map(df[f].value_counts())\n",
    "    \n",
    "    map_dict = dict(zip(df[f].unique(), range(df[f].nunique())))\n",
    "    df[f] = df[f].map(map_dict).fillna(-1).astype('int32')\n",
    "    click_df[f] = click_df[f].map(map_dict).fillna(-1).astype('int32')\n",
    "    sort_df[f] = sort_df[f].map(map_dict).fillna(-1).astype('int32')\n",
    "    df[f + '_count'] = df[f].map(df[f].value_counts())\n",
    "df = reduce_mem(df)\n",
    "click_df = reduce_mem(click_df)\n",
    "sort_df = reduce_mem(sort_df)\n",
    "del map_dict\n",
    "gc.collect()\n",
    "print('runtime:', time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================== feat eng ===============================================\n",
      "*************************** history stats ***************************\n",
      "------------------ deviceid ------------------\n",
      "runtime: 258.8171241283417\n",
      "------------------ pos_deviceid ------------------\n",
      "runtime: 284.7622137069702\n",
      "------------------ newsid ------------------\n",
      "runtime: 315.93544578552246\n",
      "------------------ newsid_pos ------------------\n",
      "runtime: 355.2394235134125\n",
      "2766.46 Mb, 1734.41 Mb (37.31 %)\n",
      "*************************** exposure_ts_gap ***************************\n",
      "------------------ deviceid ------------------\n",
      "2881.13 Mb, 2307.77 Mb (19.90 %)\n",
      "runtime: 496.04815316200256\n",
      "------------------ newsid ------------------\n",
      "3454.49 Mb, 2881.13 Mb (16.60 %)\n",
      "runtime: 632.4443359375\n",
      "------------------ lng_lat ------------------\n",
      "4027.85 Mb, 3454.49 Mb (14.23 %)\n",
      "runtime: 765.5021119117737\n",
      "------------------ pos_deviceid ------------------\n",
      "4601.21 Mb, 4027.85 Mb (12.46 %)\n",
      "runtime: 916.6941893100739\n",
      "------------------ pos_newsid ------------------\n",
      "5174.57 Mb, 4601.21 Mb (11.08 %)\n",
      "runtime: 1092.9380884170532\n",
      "------------------ pos_lng_lat ------------------\n",
      "5747.93 Mb, 5174.57 Mb (9.98 %)\n",
      "runtime: 1264.991124868393\n",
      "------------------ pos_deviceid_lng_lat ------------------\n",
      "6321.29 Mb, 5747.93 Mb (9.07 %)\n",
      "runtime: 1453.2342567443848\n",
      "------------------ netmodel_deviceid ------------------\n",
      "6894.65 Mb, 6321.29 Mb (8.32 %)\n",
      "runtime: 1637.2641668319702\n",
      "------------------ pos_netmodel_deviceid ------------------\n",
      "7468.01 Mb, 6894.65 Mb (7.68 %)\n",
      "runtime: 1838.7924420833588\n",
      "------------------ netmodel_lng_lat ------------------\n",
      "8041.37 Mb, 7468.01 Mb (7.13 %)\n",
      "runtime: 2042.0567226409912\n",
      "------------------ deviceid_lng_lat ------------------\n",
      "8614.73 Mb, 8041.37 Mb (6.66 %)\n",
      "runtime: 2245.932071208954\n",
      "------------------ netmodel_deviceid_lng_lat ------------------\n",
      "9188.08 Mb, 8614.73 Mb (6.24 %)\n",
      "runtime: 2472.4687213897705\n",
      "------------------ pos_netmodel_lng_lat ------------------\n",
      "9761.44 Mb, 9188.08 Mb (5.87 %)\n",
      "runtime: 2723.092509508133\n",
      "------------------ pos_netmodel_deviceid_lng_lat ------------------\n",
      "10334.80 Mb, 9761.44 Mb (5.55 %)\n",
      "runtime: 2995.3062674999237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('=============================================== feat eng ===============================================')\n",
    "\n",
    "print('*************************** history stats ***************************')\n",
    "for f in [\n",
    "    ['deviceid'],\n",
    "    ['pos', 'deviceid'],\n",
    "    ['newsid'],\n",
    "    ['newsid','pos'],\n",
    "    # ...\n",
    "]:\n",
    "    print('------------------ {} ------------------'.format('_'.join(f)))\n",
    "    \n",
    "    # 对前一天的点击次数进行统计\n",
    "    tmp = click_df[f + ['day', 'id']].groupby(f + ['day'], as_index=False)['id'].agg({'_'.join(f) + '_prev_day_click_count': 'count'})\n",
    "    tmp['day'] += 1\n",
    "    df = df.merge(tmp, on=f + ['day'], how='left')\n",
    "    df['_'.join(f) + '_prev_day_click_count'] = df['_'.join(f) + '_prev_day_click_count'].fillna(0)\n",
    "    df.loc[df['day'] == 8, '_'.join(f) + '_prev_day_click_count'] = None\n",
    "    \n",
    "    # 对前一天的曝光量进行统计\n",
    "    tmp = df[f + ['day', 'id']].groupby(f + ['day'], as_index=False)['id'].agg({'_'.join(f) + '_prev_day_count': 'count'})\n",
    "    tmp['day'] += 1\n",
    "    df = df.merge(tmp, on=f + ['day'], how='left')\n",
    "    df['_'.join(f) + '_prev_day_count'] = df['_'.join(f) + '_prev_day_count'].fillna(0)\n",
    "    df.loc[df['day'] == 8, '_'.join(f) + '_prev_day_count'] = None\n",
    "    \n",
    "    # 计算前一天的点击率\n",
    "    df['_'.join(f) + '_prev_day_ctr'] = df['_'.join(f) + '_prev_day_click_count'] / (\n",
    "            df['_'.join(f) + '_prev_day_count'] + df['_'.join(f) + '_prev_day_count'].mean())\n",
    "\n",
    "    del tmp\n",
    "    print('runtime:', time.time() - t)\n",
    "del click_df\n",
    "df = reduce_mem(df)\n",
    "\n",
    "print('*************************** exposure_ts_gap ***************************')\n",
    "for f in [\n",
    "    ['deviceid'], ['newsid'], ['lng_lat'],\n",
    "    ['pos', 'deviceid'], ['pos', 'newsid'], ['pos', 'lng_lat'],\n",
    "    ['pos', 'deviceid', 'lng_lat'],\n",
    "    ['netmodel', 'deviceid'],\n",
    "    ['pos', 'netmodel', 'deviceid'],\n",
    "    ['netmodel', 'lng_lat'], ['deviceid', 'lng_lat'],\n",
    "    ['netmodel', 'deviceid', 'lng_lat'], ['pos', 'netmodel', 'lng_lat'],\n",
    "    ['pos', 'netmodel', 'deviceid', 'lng_lat']\n",
    "]:\n",
    "    print('------------------ {} ------------------'.format('_'.join(f)))\n",
    "\n",
    "    tmp = sort_df[f + ['ts']].groupby(f)\n",
    "    # 前x次、后x次曝光到当前的时间差\n",
    "    for gap in [1, 2, 3, 5, 10]:\n",
    "        sort_df['{}_prev{}_exposure_ts_gap'.format('_'.join(f), gap)] = tmp['ts'].shift(0) - tmp['ts'].shift(gap)\n",
    "        sort_df['{}_next{}_exposure_ts_gap'.format('_'.join(f), gap)] = tmp['ts'].shift(-gap) - tmp['ts'].shift(0)\n",
    "        tmp2 = sort_df[\n",
    "            f + ['ts', '{}_prev{}_exposure_ts_gap'.format('_'.join(f), gap), '{}_next{}_exposure_ts_gap'.format('_'.join(f), gap)]\n",
    "        ].drop_duplicates(f + ['ts']).reset_index(drop=True)\n",
    "        df = df.merge(tmp2, on=f + ['ts'], how='left')\n",
    "        del sort_df['{}_prev{}_exposure_ts_gap'.format('_'.join(f), gap)]\n",
    "        del sort_df['{}_next{}_exposure_ts_gap'.format('_'.join(f), gap)]\n",
    "        del tmp2\n",
    "\n",
    "    del tmp\n",
    "    df = reduce_mem(df)\n",
    "    print('runtime:', time.time() - t)\n",
    "del df['ts']\n",
    "gc.collect()\n",
    "\n",
    "print('*************************** cross feat (second order) ***************************')\n",
    "# 二阶交叉特征，可以继续做更高阶的交叉。\n",
    "cross_cols = ['deviceid', 'newsid', 'pos', 'netmodel', 'lng_lat']\n",
    "for f in cross_cols:\n",
    "    for col in cross_cols:\n",
    "        if col == f:\n",
    "            continue\n",
    "        print('------------------ {} {} ------------------'.format(f, col))\n",
    "        df = df.merge(df[[f, col]].groupby(f, as_index=False)[col].agg({\n",
    "            'cross_{}_{}_nunique'.format(f, col): 'nunique',\n",
    "            'cross_{}_{}_ent'.format(f, col): lambda x: entropy(x.value_counts() / x.shape[0]) # 熵\n",
    "        }), on=f, how='left')\n",
    "        if 'cross_{}_{}_count'.format(f, col) not in df.columns.values and 'cross_{}_{}_count'.format(col, f) not in df.columns.values:\n",
    "            df = df.merge(df[[f, col, 'id']].groupby([f, col], as_index=False)['id'].agg({\n",
    "                'cross_{}_{}_count'.format(f, col): 'count' # 共现次数\n",
    "            }), on=[f, col], how='left')\n",
    "        if 'cross_{}_{}_count_ratio'.format(col, f) not in df.columns.values:\n",
    "            df['cross_{}_{}_count_ratio'.format(col, f)] = df['cross_{}_{}_count'.format(f, col)] / df[f + '_count'] # 比例偏好\n",
    "        if 'cross_{}_{}_count_ratio'.format(f, col) not in df.columns.values:\n",
    "            df['cross_{}_{}_count_ratio'.format(f, col)] = df['cross_{}_{}_count'.format(f, col)] / df[col + '_count'] # 比例偏好\n",
    "        df['cross_{}_{}_nunique_ratio_{}_count'.format(f, col, f)] = df['cross_{}_{}_nunique'.format(f, col)] / df[f + '_count']\n",
    "        print('runtime:', time.time() - t)\n",
    "    df = reduce_mem(df)\n",
    "del df['id']\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================== deviceid newsid ======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zxh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "/home/zxh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.74 Mb, 3.06 Mb (65.00 %)\n",
      "runtime: 13617.837913513184\n",
      "====================================== newsid deviceid ======================================\n",
      "100.68 Mb, 35.24 Mb (65.00 %)\n",
      "runtime: 14052.586945056915\n",
      "====================================== deviceid lng_lat ======================================\n",
      "8.74 Mb, 3.06 Mb (65.00 %)\n",
      "runtime: 14283.030943393707\n",
      "====================================== lng_lat deviceid ======================================\n",
      "35.64 Mb, 12.48 Mb (65.00 %)\n",
      "runtime: 14532.700240135193\n",
      "====================================== newsid lng_lat ======================================\n",
      "100.68 Mb, 35.24 Mb (65.00 %)\n",
      "runtime: 14984.698087215424\n",
      "====================================== lng_lat newsid ======================================\n",
      "35.64 Mb, 12.48 Mb (65.00 %)\n",
      "runtime: 15316.422714471817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def emb(df, f1, f2):\n",
    "    emb_size = 8\n",
    "    print('====================================== {} {} ======================================'.format(f1, f2))\n",
    "    tmp = df.groupby(f1, as_index=False)[f2].agg({'{}_{}_list'.format(f1, f2): list})\n",
    "    sentences = tmp['{}_{}_list'.format(f1, f2)].values.tolist()\n",
    "    del tmp['{}_{}_list'.format(f1, f2)]\n",
    "    for i in range(len(sentences)):\n",
    "        sentences[i] = [str(x) for x in sentences[i]]\n",
    "    model = Word2Vec(sentences, size=emb_size, window=5, min_count=5, sg=0, hs=1, seed=2019)\n",
    "    emb_matrix = []\n",
    "    for seq in sentences:\n",
    "        vec = []\n",
    "        for w in seq:\n",
    "            if w in model:\n",
    "                 vec.append(model[w])\n",
    "        if len(vec) > 0:\n",
    "            emb_matrix.append(np.mean(vec, axis=0))\n",
    "        else:\n",
    "            emb_matrix.append([0] * emb_size)\n",
    "    emb_matrix = np.array(emb_matrix)\n",
    "    for i in range(emb_size):\n",
    "        tmp['{}_{}_emb_{}'.format(f1, f2, i)] = emb_matrix[:, i]\n",
    "    del model, emb_matrix, sentences\n",
    "    tmp = reduce_mem(tmp)\n",
    "    print('runtime:', time.time() - t)\n",
    "    return tmp\n",
    "\n",
    "\n",
    "emb_cols = [\n",
    "    ['deviceid', 'newsid'],\n",
    "    ['deviceid', 'lng_lat'],\n",
    "    ['newsid', 'lng_lat'],\n",
    "    # ...\n",
    "]\n",
    "for f1, f2 in emb_cols:\n",
    "    df = df.merge(emb(sort_df, f1, f2), on=f1, how='left')\n",
    "    df = df.merge(emb(sort_df, f2, f1), on=f2, how='left')\n",
    "del sort_df\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================\n",
      "7215.02 Mb, 7215.02 Mb (0.00 %)\n",
      "2317.08 Mb, 2317.08 Mb (0.00 %)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('========================================================================================================')\n",
    "train_df = df[:train_num].reset_index(drop=True)\n",
    "train_df = reduce_mem(train_df)\n",
    "test_df = df[train_num:].reset_index(drop=True)\n",
    "test_df = reduce_mem(test_df)\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('========================================================================================================')\n",
    "train_df = df[:train_num].reset_index(drop=True)\n",
    "test_df = df[train_num:].reset_index(drop=True)\n",
    "del df\n",
    "gc.collect()\n",
    "\n",
    "train_idx = train_df[train_df['day'] < 10].index.tolist()\n",
    "val_idx = train_df[train_df['day'] == 10].index.tolist()\n",
    "\n",
    "train_x = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "train_y = labels[train_idx]\n",
    "val_x = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "val_y = labels[val_idx]\n",
    "\n",
    "# del train_x['day'], val_x['day'], train_df['day'], test_df['day']\n",
    "gc.collect()\n",
    "print('runtime:', time.time() - t)\n",
    "print('========================================================================================================')\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape,val_x.shape,test_df.shape,train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************** app tag prone  ***************************\n",
      "====================== app  tag begin =================\n",
      "12.24 Mb, 4.37 Mb (64.29 %)\n",
      "12.24 Mb, 4.37 Mb (64.29 %)\n",
      "~~~~~~~~~~test_df~~~~~~~~~~~~\n",
      "~~~~~~~~~~train_df~~~~~~~~~~~~\n",
      "~~~~~~~~~~test_df~~~~~~~~~~~~\n",
      "~~~~~~~~~~~train_df~~~~~~~~~~~\n",
      "====================== app  tag end =================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('*************************** app tag prone  ***************************')\n",
    "print('====================== app  tag begin =================')\n",
    "\n",
    "app_prone = pd.read_pickle('../pickle/Graph_prone_app.pickle')\n",
    "app_prone = reduce_mem(app_prone)\n",
    "tag_prone = pd.read_pickle('../pickle/Graph_prone_tag.pickle')\n",
    "tag_prone = reduce_mem(tag_prone)\n",
    "\n",
    "app_prone['deviceid'] = app_prone['deviceid'].map(map_dict_deviceid).fillna(-1).astype('int32')\n",
    "tag_prone['deviceid'] = tag_prone['deviceid'].map(map_dict_deviceid).fillna(-1).astype('int32')\n",
    "\n",
    "#train_x = train_x.merge(app_prone,on = 'deviceid',how = 'left')\n",
    "#print('~~~~~~~~train_x~~~~~~~~~~~~~~')\n",
    "#val_x = val_x.merge(app_prone,on = 'deviceid',how = 'left')\n",
    "#print('~~~~~~~~~val_x~~~~~~~~~~~~~')\n",
    "test_df = test_df.merge(app_prone,on = 'deviceid',how = 'left')\n",
    "print('~~~~~~~~~~test_df~~~~~~~~~~~~')\n",
    "train_df = train_df.merge(app_prone,on = 'deviceid',how = 'left')\n",
    "print('~~~~~~~~~~train_df~~~~~~~~~~~~')\n",
    "del app_prone\n",
    "gc.collect()\n",
    "\n",
    "#train_x = train_x.merge(tag_prone,on = 'deviceid',how = 'left')\n",
    "#print('~~~~~~~~train_x~~~~~~~~~~~~~~')\n",
    "#val_x = val_x.merge(tag_prone,on = 'deviceid',how = 'left')\n",
    "#print('~~~~~~~~~~val_x~~~~~~~~~~~~')\n",
    "test_df = test_df.merge(tag_prone,on = 'deviceid',how = 'left')\n",
    "print('~~~~~~~~~~test_df~~~~~~~~~~~~')\n",
    "train_df = train_df.merge(tag_prone,on = 'deviceid',how = 'left')\n",
    "print('~~~~~~~~~~~train_df~~~~~~~~~~~')\n",
    "print('====================== app  tag end =================')\n",
    "\n",
    "del tag_prone\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3653592, 202), (11376681, 202))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape,train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************** embedding ***************************\n",
      "====================== read devid  newsid  prone emb =================\n",
      "12.24 Mb, 4.37 Mb (64.29 %)\n",
      "140.95 Mb, 50.34 Mb (64.29 %)\n",
      "~~~~~~~~test_df~~~~~~~~~~~~~~\n",
      "~~~~~~~~train_df~~~~~~~~~~~~~~\n",
      "~~~~~~~~test_df~~~~~~~~~~~~~~\n",
      "~~~~~~~~train_df~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('*************************** embedding ***************************')\n",
    "print('====================== read devid  newsid  prone emb =================')\n",
    "dev_newsid = pd.read_pickle('../pickle/Graph_prone_all_data_dev_news.pickle')\n",
    "dev_newsid = reduce_mem(dev_newsid)\n",
    "newsid_dev = pd.read_pickle('../pickle/Graph_prone_all_data_news_dev.pickle')\n",
    "newsid_dev = reduce_mem(newsid_dev)\n",
    "dev_newsid['deviceid'] = dev_newsid['deviceid'].map(map_dict_deviceid).fillna(-1).astype('int32')\n",
    "newsid_dev['newsid'] = newsid_dev['newsid'].map(map_dict_newsid).fillna(-1).astype('int32')\n",
    "\n",
    "# train_x = train_x.merge(dev_newsid,on = 'deviceid',how = 'left')\n",
    "# print('~~~~~~~~train_x~~~~~~~~~~~~~~')\n",
    "# val_x = val_x.merge(dev_newsid,on = 'deviceid',how = 'left')\n",
    "# print('~~~~~~~~val_x~~~~~~~~~~~~~~')\n",
    "test_df = test_df.merge(dev_newsid,on = 'deviceid',how = 'left')\n",
    "print('~~~~~~~~test_df~~~~~~~~~~~~~~')\n",
    "train_df = train_df.merge(dev_newsid,on = 'deviceid',how = 'left')\n",
    "print('~~~~~~~~train_df~~~~~~~~~~~~~~')\n",
    "\n",
    "\n",
    "# train_x = train_x.merge(newsid_dev,on = 'newsid',how = 'left')\n",
    "# print('~~~~~~~~train_x~~~~~~~~~~~~~~')\n",
    "# val_x = val_x.merge(newsid_dev,on = 'newsid',how = 'left')\n",
    "# print('~~~~~~~~val_x~~~~~~~~~~~~~~')\n",
    "test_df = test_df.merge(newsid_dev,on = 'newsid',how = 'left')\n",
    "print('~~~~~~~~test_df~~~~~~~~~~~~~~')\n",
    "train_df = train_df.merge(newsid_dev,on = 'newsid',how = 'left')\n",
    "print('~~~~~~~~train_df~~~~~~~~~~~~~~')\n",
    "del dev_newsid,newsid_dev\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11376681, 226), (3653592, 226))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape,test_df.shape\n",
    "# ,train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************** embedding ***************************\n",
      "====================== read devid  lhg_lat  prone emb =================\n",
      "12.24 Mb, 4.37 Mb (64.29 %)\n",
      "49.90 Mb, 17.82 Mb (64.29 %)\n",
      "~~~~~~~~test_df~~~~~~~~~~~~~~\n",
      "~~~~~~~~train_df~~~~~~~~~~~~~~\n",
      "~~~~~~~~test_df~~~~~~~~~~~~~~\n",
      "~~~~~~~~train_df~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('*************************** embedding ***************************')\n",
    "print('====================== read devid  lhg_lat  prone emb =================')\n",
    "dev_ll = pd.read_pickle('../pickle/Graph_prone_all_data_dev_ll.pickle')\n",
    "dev_ll = reduce_mem(dev_ll)\n",
    "ll_dev = pd.read_pickle('../pickle/Graph_prone_all_data_ll_dev.pickle')\n",
    "ll_dev = reduce_mem(ll_dev)\n",
    "dev_ll['deviceid'] = dev_ll['deviceid'].map(map_dict_deviceid).fillna(-1).astype('int32')\n",
    "ll_dev['lng_lat'] = ll_dev['lng_lat'].map(map_dict_ll).fillna(-1).astype('int32')\n",
    "\n",
    "# train_x = train_x.merge(dev_ll,on = 'deviceid',how = 'left')\n",
    "# print('~~~~~~~~train_x~~~~~~~~~~~~~~')\n",
    "# val_x = val_x.merge(dev_ll,on = 'deviceid',how = 'left')\n",
    "# print('~~~~~~~~val_x~~~~~~~~~~~~~~')\n",
    "test_df = test_df.merge(dev_ll,on = 'deviceid',how = 'left')\n",
    "print('~~~~~~~~test_df~~~~~~~~~~~~~~')\n",
    "train_df = train_df.merge(dev_ll,on = 'deviceid',how = 'left')\n",
    "print('~~~~~~~~train_df~~~~~~~~~~~~~~')\n",
    "\n",
    "\n",
    "# train_x = train_x.merge(ll_dev,on = 'lng_lat',how = 'left')\n",
    "# print('~~~~~~~~train_x~~~~~~~~~~~~~~')\n",
    "# val_x = val_x.merge(ll_dev,on = 'lng_lat',how = 'left')\n",
    "# print('~~~~~~~~val_x~~~~~~~~~~~~~~')\n",
    "test_df = test_df.merge(ll_dev,on = 'lng_lat',how = 'left')\n",
    "print('~~~~~~~~test_df~~~~~~~~~~~~~~')\n",
    "train_df = train_df.merge(ll_dev,on = 'lng_lat',how = 'left')\n",
    "print('~~~~~~~~train_df~~~~~~~~~~~~~~')\n",
    "del dev_ll,ll_dev\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11376681, 250), (3653592, 250))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape,test_df.shape\n",
    "# ,train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************** embedding ***************************\n",
      "====================== read newsid  lhg_lat  prone emb =================\n",
      "140.95 Mb, 50.34 Mb (64.29 %)\n",
      "49.90 Mb, 17.82 Mb (64.29 %)\n",
      "~~~~~~~~test_df~~~~~~~~~~~~~~\n",
      "~~~~~~~~train_df~~~~~~~~~~~~~~\n",
      "~~~~~~~~test_df~~~~~~~~~~~~~~\n",
      "~~~~~~~~train_df~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('*************************** embedding ***************************')\n",
    "print('====================== read newsid  lhg_lat  prone emb =================')\n",
    "news_ll = pd.read_pickle('../pickle/Graph_prone_all_data_news_ll.pickle')\n",
    "news_ll = reduce_mem(news_ll)\n",
    "\n",
    "ll_news = pd.read_pickle('../pickle/Graph_prone_all_data_ll_news.pickle')\n",
    "ll_news = reduce_mem(ll_news)\n",
    "\n",
    "news_ll['newsid'] = news_ll['newsid'].map(map_dict_newsid).fillna(-1).astype('int32')\n",
    "ll_news['lng_lat'] = ll_news['lng_lat'].map(map_dict_ll).fillna(-1).astype('int32')\n",
    "\n",
    "# train_x = train_x.merge(news_ll,on = 'newsid',how = 'left')\n",
    "# print('~~~~~~~~train_x~~~~~~~~~~~~~~')\n",
    "# val_x = val_x.merge(news_ll,on = 'newsid',how = 'left')\n",
    "# print('~~~~~~~~val_x~~~~~~~~~~~~~~')\n",
    "test_df = test_df.merge(news_ll,on = 'newsid',how = 'left')\n",
    "print('~~~~~~~~test_df~~~~~~~~~~~~~~')\n",
    "train_df = train_df.merge(news_ll,on = 'newsid',how = 'left')\n",
    "print('~~~~~~~~train_df~~~~~~~~~~~~~~')\n",
    "\n",
    "\n",
    "# train_x = train_x.merge(ll_news,on = 'lng_lat',how = 'left')\n",
    "# print('~~~~~~~~train_x~~~~~~~~~~~~~~')\n",
    "# val_x = val_x.merge(ll_news,on = 'lng_lat',how = 'left')\n",
    "# print('~~~~~~~~val_x~~~~~~~~~~~~~~')\n",
    "test_df = test_df.merge(ll_news,on = 'lng_lat',how = 'left')\n",
    "print('~~~~~~~~test_df~~~~~~~~~~~~~~')\n",
    "train_df = train_df.merge(ll_news,on = 'lng_lat',how = 'left')\n",
    "print('~~~~~~~~train_df~~~~~~~~~~~~~~')\n",
    "del news_ll,ll_news\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11376681, 274), (3653592, 274))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape,test_df.shape\n",
    "# ,train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************** prone edges ***************************\n",
      "====================== app_flatten  =================\n",
      "~~~~~~~~~~test_df~~~~~~~~~~~~\n",
      "~~~~~~~~~~train_df~~~~~~~~~~~~\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('*************************** prone edges ***************************')\n",
    "print('====================== app_flatten  =================')\n",
    "\n",
    "app_flatten = pd.read_csv('../pickle/app_flatten_all_data.csv')\n",
    "\n",
    "app_flatten['deviceid'] = app_flatten['deviceid'].map(map_dict_deviceid).fillna(-1).astype('int32')\n",
    "\n",
    "\n",
    "# train_x = train_x.merge(app_flatten,on = 'deviceid',how = 'left')\n",
    "# print('~~~~~~~~train_x~~~~~~~~~~~~~~')\n",
    "# val_x = val_x.merge(app_flatten,on = 'deviceid',how = 'left')\n",
    "# print('~~~~~~~~~val_x~~~~~~~~~~~~~')\n",
    "test_df = test_df.merge(app_flatten,on = 'deviceid',how = 'left')\n",
    "print('~~~~~~~~~~test_df~~~~~~~~~~~~')\n",
    "train_df = train_df.merge(app_flatten,on = 'deviceid',how = 'left')\n",
    "print('~~~~~~~~~~train_df~~~~~~~~~~~~')\n",
    "del app_flatten\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11376681, 290), (3653592, 290))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape,test_df.shape\n",
    "# ,train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************** prone edges ***************************\n",
      "====================== tag  =================\n",
      "~~~~~~~~~~test_df~~~~~~~~~~~~\n",
      "~~~~~~~~~~train_df~~~~~~~~~~~~\n",
      "~~~~~~~~~~test_df~~~~~~~~~~~~\n",
      "~~~~~~~~~~~train_df~~~~~~~~~~~\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('*************************** prone edges ***************************')\n",
    "print('====================== tag  =================')\n",
    "\n",
    "app_doc2vec = pd.read_csv('../pickle/device_app_doc2vec_emb.csv')\n",
    "tag_doc2vec = pd.read_csv('../pickle/tag_data_doc2vec_emb.csv')\n",
    "\n",
    "del app_doc2vec['Unnamed: 0']\n",
    "del tag_doc2vec['Unnamed: 0']\n",
    "\n",
    "app_doc2vec['deviceid'] = app_doc2vec['deviceid'].map(map_dict_deviceid).fillna(-1).astype('int32')\n",
    "tag_doc2vec['deviceid'] = tag_doc2vec['deviceid'].map(map_dict_deviceid).fillna(-1).astype('int32')\n",
    "\n",
    "# train_x = train_x.merge(app_doc2vec,on = 'deviceid',how = 'left')\n",
    "# print('~~~~~~~~train_x~~~~~~~~~~~~~~')\n",
    "# val_x = val_x.merge(app_doc2vec,on = 'deviceid',how = 'left')\n",
    "# print('~~~~~~~~~val_x~~~~~~~~~~~~~')\n",
    "test_df = test_df.merge(app_doc2vec,on = 'deviceid',how = 'left')\n",
    "print('~~~~~~~~~~test_df~~~~~~~~~~~~')\n",
    "train_df = train_df.merge(app_doc2vec,on = 'deviceid',how = 'left')\n",
    "print('~~~~~~~~~~train_df~~~~~~~~~~~~')\n",
    "del app_doc2vec\n",
    "gc.collect()\n",
    "\n",
    "# train_x = train_x.merge(tag_doc2vec,on = 'deviceid',how = 'left')\n",
    "# print('~~~~~~~~train_x~~~~~~~~~~~~~~')\n",
    "# val_x = val_x.merge(tag_doc2vec,on = 'deviceid',how = 'left')\n",
    "# print('~~~~~~~~~~val_x~~~~~~~~~~~~')\n",
    "test_df = test_df.merge(tag_doc2vec,on = 'deviceid',how = 'left')\n",
    "print('~~~~~~~~~~test_df~~~~~~~~~~~~')\n",
    "train_df = train_df.merge(tag_doc2vec,on = 'deviceid',how = 'left')\n",
    "print('~~~~~~~~~~~train_df~~~~~~~~~~~')\n",
    "del tag_doc2vec\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11376681, 418), (3653592, 418))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape,test_df.shape\n",
    "# ,train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>deviceid</th>\n",
       "      <th>newsid</th>\n",
       "      <th>pos</th>\n",
       "      <th>app_version</th>\n",
       "      <th>device_vendor</th>\n",
       "      <th>netmodel</th>\n",
       "      <th>osversion</th>\n",
       "      <th>lng</th>\n",
       "      <th>lat</th>\n",
       "      <th>device_version</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>lng_lat</th>\n",
       "      <th>deviceid_count</th>\n",
       "      <th>newsid_count</th>\n",
       "      <th>pos_count</th>\n",
       "      <th>app_version_count</th>\n",
       "      <th>device_vendor_count</th>\n",
       "      <th>netmodel_count</th>\n",
       "      <th>osversion_count</th>\n",
       "      <th>device_version_count</th>\n",
       "      <th>lng_count</th>\n",
       "      <th>lat_count</th>\n",
       "      <th>lng_lat_count</th>\n",
       "      <th>deviceid_prev_day_click_count</th>\n",
       "      <th>deviceid_prev_day_count</th>\n",
       "      <th>deviceid_prev_day_ctr</th>\n",
       "      <th>pos_deviceid_prev_day_click_count</th>\n",
       "      <th>pos_deviceid_prev_day_count</th>\n",
       "      <th>pos_deviceid_prev_day_ctr</th>\n",
       "      <th>newsid_prev_day_click_count</th>\n",
       "      <th>newsid_prev_day_count</th>\n",
       "      <th>newsid_prev_day_ctr</th>\n",
       "      <th>newsid_pos_prev_day_click_count</th>\n",
       "      <th>newsid_pos_prev_day_count</th>\n",
       "      <th>newsid_pos_prev_day_ctr</th>\n",
       "      <th>deviceid_prev1_exposure_ts_gap</th>\n",
       "      <th>deviceid_next1_exposure_ts_gap</th>\n",
       "      <th>deviceid_prev2_exposure_ts_gap</th>\n",
       "      <th>deviceid_next2_exposure_ts_gap</th>\n",
       "      <th>deviceid_prev3_exposure_ts_gap</th>\n",
       "      <th>deviceid_next3_exposure_ts_gap</th>\n",
       "      <th>deviceid_prev5_exposure_ts_gap</th>\n",
       "      <th>deviceid_next5_exposure_ts_gap</th>\n",
       "      <th>deviceid_prev10_exposure_ts_gap</th>\n",
       "      <th>deviceid_next10_exposure_ts_gap</th>\n",
       "      <th>newsid_prev1_exposure_ts_gap</th>\n",
       "      <th>newsid_next1_exposure_ts_gap</th>\n",
       "      <th>newsid_prev2_exposure_ts_gap</th>\n",
       "      <th>newsid_next2_exposure_ts_gap</th>\n",
       "      <th>newsid_prev3_exposure_ts_gap</th>\n",
       "      <th>newsid_next3_exposure_ts_gap</th>\n",
       "      <th>newsid_prev5_exposure_ts_gap</th>\n",
       "      <th>newsid_next5_exposure_ts_gap</th>\n",
       "      <th>newsid_prev10_exposure_ts_gap</th>\n",
       "      <th>newsid_next10_exposure_ts_gap</th>\n",
       "      <th>lng_lat_prev1_exposure_ts_gap</th>\n",
       "      <th>lng_lat_next1_exposure_ts_gap</th>\n",
       "      <th>lng_lat_prev2_exposure_ts_gap</th>\n",
       "      <th>lng_lat_next2_exposure_ts_gap</th>\n",
       "      <th>lng_lat_prev3_exposure_ts_gap</th>\n",
       "      <th>lng_lat_next3_exposure_ts_gap</th>\n",
       "      <th>lng_lat_prev5_exposure_ts_gap</th>\n",
       "      <th>lng_lat_next5_exposure_ts_gap</th>\n",
       "      <th>lng_lat_prev10_exposure_ts_gap</th>\n",
       "      <th>lng_lat_next10_exposure_ts_gap</th>\n",
       "      <th>pos_deviceid_prev1_exposure_ts_gap</th>\n",
       "      <th>pos_deviceid_next1_exposure_ts_gap</th>\n",
       "      <th>pos_deviceid_prev2_exposure_ts_gap</th>\n",
       "      <th>pos_deviceid_next2_exposure_ts_gap</th>\n",
       "      <th>pos_deviceid_prev3_exposure_ts_gap</th>\n",
       "      <th>pos_deviceid_next3_exposure_ts_gap</th>\n",
       "      <th>pos_deviceid_prev5_exposure_ts_gap</th>\n",
       "      <th>pos_deviceid_next5_exposure_ts_gap</th>\n",
       "      <th>pos_deviceid_prev10_exposure_ts_gap</th>\n",
       "      <th>pos_deviceid_next10_exposure_ts_gap</th>\n",
       "      <th>pos_newsid_prev1_exposure_ts_gap</th>\n",
       "      <th>pos_newsid_next1_exposure_ts_gap</th>\n",
       "      <th>pos_newsid_prev2_exposure_ts_gap</th>\n",
       "      <th>pos_newsid_next2_exposure_ts_gap</th>\n",
       "      <th>pos_newsid_prev3_exposure_ts_gap</th>\n",
       "      <th>pos_newsid_next3_exposure_ts_gap</th>\n",
       "      <th>pos_newsid_prev5_exposure_ts_gap</th>\n",
       "      <th>pos_newsid_next5_exposure_ts_gap</th>\n",
       "      <th>pos_newsid_prev10_exposure_ts_gap</th>\n",
       "      <th>pos_newsid_next10_exposure_ts_gap</th>\n",
       "      <th>pos_lng_lat_prev1_exposure_ts_gap</th>\n",
       "      <th>pos_lng_lat_next1_exposure_ts_gap</th>\n",
       "      <th>pos_lng_lat_prev2_exposure_ts_gap</th>\n",
       "      <th>pos_lng_lat_next2_exposure_ts_gap</th>\n",
       "      <th>pos_lng_lat_prev3_exposure_ts_gap</th>\n",
       "      <th>pos_lng_lat_next3_exposure_ts_gap</th>\n",
       "      <th>pos_lng_lat_prev5_exposure_ts_gap</th>\n",
       "      <th>pos_lng_lat_next5_exposure_ts_gap</th>\n",
       "      <th>pos_lng_lat_prev10_exposure_ts_gap</th>\n",
       "      <th>pos_lng_lat_next10_exposure_ts_gap</th>\n",
       "      <th>pos_deviceid_lng_lat_prev1_exposure_ts_gap</th>\n",
       "      <th>pos_deviceid_lng_lat_next1_exposure_ts_gap</th>\n",
       "      <th>pos_deviceid_lng_lat_prev2_exposure_ts_gap</th>\n",
       "      <th>pos_deviceid_lng_lat_next2_exposure_ts_gap</th>\n",
       "      <th>pos_deviceid_lng_lat_prev3_exposure_ts_gap</th>\n",
       "      <th>pos_deviceid_lng_lat_next3_exposure_ts_gap</th>\n",
       "      <th>pos_deviceid_lng_lat_prev5_exposure_ts_gap</th>\n",
       "      <th>pos_deviceid_lng_lat_next5_exposure_ts_gap</th>\n",
       "      <th>pos_deviceid_lng_lat_prev10_exposure_ts_gap</th>\n",
       "      <th>pos_deviceid_lng_lat_next10_exposure_ts_gap</th>\n",
       "      <th>netmodel_deviceid_prev1_exposure_ts_gap</th>\n",
       "      <th>netmodel_deviceid_next1_exposure_ts_gap</th>\n",
       "      <th>netmodel_deviceid_prev2_exposure_ts_gap</th>\n",
       "      <th>netmodel_deviceid_next2_exposure_ts_gap</th>\n",
       "      <th>netmodel_deviceid_prev3_exposure_ts_gap</th>\n",
       "      <th>netmodel_deviceid_next3_exposure_ts_gap</th>\n",
       "      <th>netmodel_deviceid_prev5_exposure_ts_gap</th>\n",
       "      <th>netmodel_deviceid_next5_exposure_ts_gap</th>\n",
       "      <th>netmodel_deviceid_prev10_exposure_ts_gap</th>\n",
       "      <th>netmodel_deviceid_next10_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_deviceid_prev1_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_deviceid_next1_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_deviceid_prev2_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_deviceid_next2_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_deviceid_prev3_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_deviceid_next3_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_deviceid_prev5_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_deviceid_next5_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_deviceid_prev10_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_deviceid_next10_exposure_ts_gap</th>\n",
       "      <th>netmodel_lng_lat_prev1_exposure_ts_gap</th>\n",
       "      <th>netmodel_lng_lat_next1_exposure_ts_gap</th>\n",
       "      <th>netmodel_lng_lat_prev2_exposure_ts_gap</th>\n",
       "      <th>netmodel_lng_lat_next2_exposure_ts_gap</th>\n",
       "      <th>netmodel_lng_lat_prev3_exposure_ts_gap</th>\n",
       "      <th>netmodel_lng_lat_next3_exposure_ts_gap</th>\n",
       "      <th>netmodel_lng_lat_prev5_exposure_ts_gap</th>\n",
       "      <th>netmodel_lng_lat_next5_exposure_ts_gap</th>\n",
       "      <th>netmodel_lng_lat_prev10_exposure_ts_gap</th>\n",
       "      <th>netmodel_lng_lat_next10_exposure_ts_gap</th>\n",
       "      <th>deviceid_lng_lat_prev1_exposure_ts_gap</th>\n",
       "      <th>deviceid_lng_lat_next1_exposure_ts_gap</th>\n",
       "      <th>deviceid_lng_lat_prev2_exposure_ts_gap</th>\n",
       "      <th>deviceid_lng_lat_next2_exposure_ts_gap</th>\n",
       "      <th>deviceid_lng_lat_prev3_exposure_ts_gap</th>\n",
       "      <th>deviceid_lng_lat_next3_exposure_ts_gap</th>\n",
       "      <th>deviceid_lng_lat_prev5_exposure_ts_gap</th>\n",
       "      <th>deviceid_lng_lat_next5_exposure_ts_gap</th>\n",
       "      <th>deviceid_lng_lat_prev10_exposure_ts_gap</th>\n",
       "      <th>deviceid_lng_lat_next10_exposure_ts_gap</th>\n",
       "      <th>netmodel_deviceid_lng_lat_prev1_exposure_ts_gap</th>\n",
       "      <th>netmodel_deviceid_lng_lat_next1_exposure_ts_gap</th>\n",
       "      <th>netmodel_deviceid_lng_lat_prev2_exposure_ts_gap</th>\n",
       "      <th>netmodel_deviceid_lng_lat_next2_exposure_ts_gap</th>\n",
       "      <th>netmodel_deviceid_lng_lat_prev3_exposure_ts_gap</th>\n",
       "      <th>netmodel_deviceid_lng_lat_next3_exposure_ts_gap</th>\n",
       "      <th>netmodel_deviceid_lng_lat_prev5_exposure_ts_gap</th>\n",
       "      <th>netmodel_deviceid_lng_lat_next5_exposure_ts_gap</th>\n",
       "      <th>netmodel_deviceid_lng_lat_prev10_exposure_ts_gap</th>\n",
       "      <th>netmodel_deviceid_lng_lat_next10_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_lng_lat_prev1_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_lng_lat_next1_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_lng_lat_prev2_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_lng_lat_next2_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_lng_lat_prev3_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_lng_lat_next3_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_lng_lat_prev5_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_lng_lat_next5_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_lng_lat_prev10_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_lng_lat_next10_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_deviceid_lng_lat_prev1_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_deviceid_lng_lat_next1_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_deviceid_lng_lat_prev2_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_deviceid_lng_lat_next2_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_deviceid_lng_lat_prev3_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_deviceid_lng_lat_next3_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_deviceid_lng_lat_prev5_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_deviceid_lng_lat_next5_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_deviceid_lng_lat_prev10_exposure_ts_gap</th>\n",
       "      <th>pos_netmodel_deviceid_lng_lat_next10_exposure_ts_gap</th>\n",
       "      <th>ProNE_Emb_deviceidapplist_0</th>\n",
       "      <th>ProNE_Emb_deviceidapplist_1</th>\n",
       "      <th>ProNE_Emb_deviceidapplist_2</th>\n",
       "      <th>ProNE_Emb_deviceidapplist_3</th>\n",
       "      <th>ProNE_Emb_deviceidapplist_4</th>\n",
       "      <th>ProNE_Emb_deviceidapplist_5</th>\n",
       "      <th>ProNE_Emb_deviceidapplist_6</th>\n",
       "      <th>ProNE_Emb_deviceidapplist_7</th>\n",
       "      <th>ProNE_Emb_deviceidapplist_8</th>\n",
       "      <th>ProNE_Emb_deviceidapplist_9</th>\n",
       "      <th>ProNE_Emb_deviceidapplist_10</th>\n",
       "      <th>ProNE_Emb_deviceidapplist_11</th>\n",
       "      <th>ProNE_Emb_deviceidall_tag_word_0</th>\n",
       "      <th>ProNE_Emb_deviceidall_tag_word_1</th>\n",
       "      <th>ProNE_Emb_deviceidall_tag_word_2</th>\n",
       "      <th>ProNE_Emb_deviceidall_tag_word_3</th>\n",
       "      <th>ProNE_Emb_deviceidall_tag_word_4</th>\n",
       "      <th>ProNE_Emb_deviceidall_tag_word_5</th>\n",
       "      <th>ProNE_Emb_deviceidall_tag_word_6</th>\n",
       "      <th>ProNE_Emb_deviceidall_tag_word_7</th>\n",
       "      <th>ProNE_Emb_deviceidall_tag_word_8</th>\n",
       "      <th>ProNE_Emb_deviceidall_tag_word_9</th>\n",
       "      <th>ProNE_Emb_deviceidall_tag_word_10</th>\n",
       "      <th>ProNE_Emb_deviceidall_tag_word_11</th>\n",
       "      <th>ProNE_Emb_deviceidnewsid_0</th>\n",
       "      <th>ProNE_Emb_deviceidnewsid_1</th>\n",
       "      <th>ProNE_Emb_deviceidnewsid_2</th>\n",
       "      <th>ProNE_Emb_deviceidnewsid_3</th>\n",
       "      <th>ProNE_Emb_deviceidnewsid_4</th>\n",
       "      <th>ProNE_Emb_deviceidnewsid_5</th>\n",
       "      <th>ProNE_Emb_deviceidnewsid_6</th>\n",
       "      <th>ProNE_Emb_deviceidnewsid_7</th>\n",
       "      <th>ProNE_Emb_deviceidnewsid_8</th>\n",
       "      <th>ProNE_Emb_deviceidnewsid_9</th>\n",
       "      <th>ProNE_Emb_deviceidnewsid_10</th>\n",
       "      <th>ProNE_Emb_deviceidnewsid_11</th>\n",
       "      <th>ProNE_Emb_newsiddeviceid_0</th>\n",
       "      <th>ProNE_Emb_newsiddeviceid_1</th>\n",
       "      <th>ProNE_Emb_newsiddeviceid_2</th>\n",
       "      <th>ProNE_Emb_newsiddeviceid_3</th>\n",
       "      <th>ProNE_Emb_newsiddeviceid_4</th>\n",
       "      <th>ProNE_Emb_newsiddeviceid_5</th>\n",
       "      <th>ProNE_Emb_newsiddeviceid_6</th>\n",
       "      <th>ProNE_Emb_newsiddeviceid_7</th>\n",
       "      <th>ProNE_Emb_newsiddeviceid_8</th>\n",
       "      <th>ProNE_Emb_newsiddeviceid_9</th>\n",
       "      <th>ProNE_Emb_newsiddeviceid_10</th>\n",
       "      <th>ProNE_Emb_newsiddeviceid_11</th>\n",
       "      <th>ProNE_Emb_deviceidlng_lat_0</th>\n",
       "      <th>ProNE_Emb_deviceidlng_lat_1</th>\n",
       "      <th>ProNE_Emb_deviceidlng_lat_2</th>\n",
       "      <th>ProNE_Emb_deviceidlng_lat_3</th>\n",
       "      <th>ProNE_Emb_deviceidlng_lat_4</th>\n",
       "      <th>ProNE_Emb_deviceidlng_lat_5</th>\n",
       "      <th>ProNE_Emb_deviceidlng_lat_6</th>\n",
       "      <th>ProNE_Emb_deviceidlng_lat_7</th>\n",
       "      <th>ProNE_Emb_deviceidlng_lat_8</th>\n",
       "      <th>ProNE_Emb_deviceidlng_lat_9</th>\n",
       "      <th>ProNE_Emb_deviceidlng_lat_10</th>\n",
       "      <th>ProNE_Emb_deviceidlng_lat_11</th>\n",
       "      <th>ProNE_Emb_lng_latdeviceid_0</th>\n",
       "      <th>ProNE_Emb_lng_latdeviceid_1</th>\n",
       "      <th>ProNE_Emb_lng_latdeviceid_2</th>\n",
       "      <th>ProNE_Emb_lng_latdeviceid_3</th>\n",
       "      <th>ProNE_Emb_lng_latdeviceid_4</th>\n",
       "      <th>ProNE_Emb_lng_latdeviceid_5</th>\n",
       "      <th>ProNE_Emb_lng_latdeviceid_6</th>\n",
       "      <th>ProNE_Emb_lng_latdeviceid_7</th>\n",
       "      <th>ProNE_Emb_lng_latdeviceid_8</th>\n",
       "      <th>ProNE_Emb_lng_latdeviceid_9</th>\n",
       "      <th>ProNE_Emb_lng_latdeviceid_10</th>\n",
       "      <th>ProNE_Emb_lng_latdeviceid_11</th>\n",
       "      <th>ProNE_Emb_newsidlng_lat_0</th>\n",
       "      <th>ProNE_Emb_newsidlng_lat_1</th>\n",
       "      <th>ProNE_Emb_newsidlng_lat_2</th>\n",
       "      <th>ProNE_Emb_newsidlng_lat_3</th>\n",
       "      <th>ProNE_Emb_newsidlng_lat_4</th>\n",
       "      <th>ProNE_Emb_newsidlng_lat_5</th>\n",
       "      <th>ProNE_Emb_newsidlng_lat_6</th>\n",
       "      <th>ProNE_Emb_newsidlng_lat_7</th>\n",
       "      <th>ProNE_Emb_newsidlng_lat_8</th>\n",
       "      <th>ProNE_Emb_newsidlng_lat_9</th>\n",
       "      <th>ProNE_Emb_newsidlng_lat_10</th>\n",
       "      <th>ProNE_Emb_newsidlng_lat_11</th>\n",
       "      <th>ProNE_Emb_lng_latnewsid_0</th>\n",
       "      <th>ProNE_Emb_lng_latnewsid_1</th>\n",
       "      <th>ProNE_Emb_lng_latnewsid_2</th>\n",
       "      <th>ProNE_Emb_lng_latnewsid_3</th>\n",
       "      <th>ProNE_Emb_lng_latnewsid_4</th>\n",
       "      <th>ProNE_Emb_lng_latnewsid_5</th>\n",
       "      <th>ProNE_Emb_lng_latnewsid_6</th>\n",
       "      <th>ProNE_Emb_lng_latnewsid_7</th>\n",
       "      <th>ProNE_Emb_lng_latnewsid_8</th>\n",
       "      <th>ProNE_Emb_lng_latnewsid_9</th>\n",
       "      <th>ProNE_Emb_lng_latnewsid_10</th>\n",
       "      <th>ProNE_Emb_lng_latnewsid_11</th>\n",
       "      <th>app_std</th>\n",
       "      <th>app_min</th>\n",
       "      <th>app_median</th>\n",
       "      <th>app_mean</th>\n",
       "      <th>app_max</th>\n",
       "      <th>app_Gini</th>\n",
       "      <th>app_entropy</th>\n",
       "      <th>app_appid_count_0_1e3_mean</th>\n",
       "      <th>app_appid_count_0_1e3_sum</th>\n",
       "      <th>app_appid_count_0_1e3_std</th>\n",
       "      <th>app_appid_count_1e3_1e4_mean</th>\n",
       "      <th>app_appid_count_1e3_1e4_sum</th>\n",
       "      <th>app_appid_count_1e3_1e4_std</th>\n",
       "      <th>app_appid_count_1e4_2e5_mean</th>\n",
       "      <th>app_appid_count_1e4_2e5_sum</th>\n",
       "      <th>app_appid_count_1e4_2e5_std</th>\n",
       "      <th>d2v_AVG_device_app0</th>\n",
       "      <th>d2v_AVG_device_app1</th>\n",
       "      <th>d2v_AVG_device_app2</th>\n",
       "      <th>d2v_AVG_device_app3</th>\n",
       "      <th>d2v_AVG_device_app4</th>\n",
       "      <th>d2v_AVG_device_app5</th>\n",
       "      <th>d2v_AVG_device_app6</th>\n",
       "      <th>d2v_AVG_device_app7</th>\n",
       "      <th>d2v_AVG_device_app8</th>\n",
       "      <th>d2v_AVG_device_app9</th>\n",
       "      <th>d2v_AVG_device_app10</th>\n",
       "      <th>d2v_AVG_device_app11</th>\n",
       "      <th>d2v_AVG_device_app12</th>\n",
       "      <th>d2v_AVG_device_app13</th>\n",
       "      <th>d2v_AVG_device_app14</th>\n",
       "      <th>d2v_AVG_device_app15</th>\n",
       "      <th>d2v_AVG_device_app16</th>\n",
       "      <th>d2v_AVG_device_app17</th>\n",
       "      <th>d2v_AVG_device_app18</th>\n",
       "      <th>d2v_AVG_device_app19</th>\n",
       "      <th>d2v_AVG_device_app20</th>\n",
       "      <th>d2v_AVG_device_app21</th>\n",
       "      <th>d2v_AVG_device_app22</th>\n",
       "      <th>d2v_AVG_device_app23</th>\n",
       "      <th>d2v_AVG_device_app24</th>\n",
       "      <th>d2v_AVG_device_app25</th>\n",
       "      <th>d2v_AVG_device_app26</th>\n",
       "      <th>d2v_AVG_device_app27</th>\n",
       "      <th>d2v_AVG_device_app28</th>\n",
       "      <th>d2v_AVG_device_app29</th>\n",
       "      <th>d2v_AVG_device_app30</th>\n",
       "      <th>d2v_AVG_device_app31</th>\n",
       "      <th>d2v_AVG_device_app32</th>\n",
       "      <th>d2v_AVG_device_app33</th>\n",
       "      <th>d2v_AVG_device_app34</th>\n",
       "      <th>d2v_AVG_device_app35</th>\n",
       "      <th>d2v_AVG_device_app36</th>\n",
       "      <th>d2v_AVG_device_app37</th>\n",
       "      <th>d2v_AVG_device_app38</th>\n",
       "      <th>d2v_AVG_device_app39</th>\n",
       "      <th>d2v_AVG_device_app40</th>\n",
       "      <th>d2v_AVG_device_app41</th>\n",
       "      <th>d2v_AVG_device_app42</th>\n",
       "      <th>d2v_AVG_device_app43</th>\n",
       "      <th>d2v_AVG_device_app44</th>\n",
       "      <th>d2v_AVG_device_app45</th>\n",
       "      <th>d2v_AVG_device_app46</th>\n",
       "      <th>d2v_AVG_device_app47</th>\n",
       "      <th>d2v_AVG_device_app48</th>\n",
       "      <th>d2v_AVG_device_app49</th>\n",
       "      <th>d2v_AVG_device_app50</th>\n",
       "      <th>d2v_AVG_device_app51</th>\n",
       "      <th>d2v_AVG_device_app52</th>\n",
       "      <th>d2v_AVG_device_app53</th>\n",
       "      <th>d2v_AVG_device_app54</th>\n",
       "      <th>d2v_AVG_device_app55</th>\n",
       "      <th>d2v_AVG_device_app56</th>\n",
       "      <th>d2v_AVG_device_app57</th>\n",
       "      <th>d2v_AVG_device_app58</th>\n",
       "      <th>d2v_AVG_device_app59</th>\n",
       "      <th>d2v_AVG_device_app60</th>\n",
       "      <th>d2v_AVG_device_app61</th>\n",
       "      <th>d2v_AVG_device_app62</th>\n",
       "      <th>d2v_AVG_device_app63</th>\n",
       "      <th>d2v_AVG_tag_data0</th>\n",
       "      <th>d2v_AVG_tag_data1</th>\n",
       "      <th>d2v_AVG_tag_data2</th>\n",
       "      <th>d2v_AVG_tag_data3</th>\n",
       "      <th>d2v_AVG_tag_data4</th>\n",
       "      <th>d2v_AVG_tag_data5</th>\n",
       "      <th>d2v_AVG_tag_data6</th>\n",
       "      <th>d2v_AVG_tag_data7</th>\n",
       "      <th>d2v_AVG_tag_data8</th>\n",
       "      <th>d2v_AVG_tag_data9</th>\n",
       "      <th>d2v_AVG_tag_data10</th>\n",
       "      <th>d2v_AVG_tag_data11</th>\n",
       "      <th>d2v_AVG_tag_data12</th>\n",
       "      <th>d2v_AVG_tag_data13</th>\n",
       "      <th>d2v_AVG_tag_data14</th>\n",
       "      <th>d2v_AVG_tag_data15</th>\n",
       "      <th>d2v_AVG_tag_data16</th>\n",
       "      <th>d2v_AVG_tag_data17</th>\n",
       "      <th>d2v_AVG_tag_data18</th>\n",
       "      <th>d2v_AVG_tag_data19</th>\n",
       "      <th>d2v_AVG_tag_data20</th>\n",
       "      <th>d2v_AVG_tag_data21</th>\n",
       "      <th>d2v_AVG_tag_data22</th>\n",
       "      <th>d2v_AVG_tag_data23</th>\n",
       "      <th>d2v_AVG_tag_data24</th>\n",
       "      <th>d2v_AVG_tag_data25</th>\n",
       "      <th>d2v_AVG_tag_data26</th>\n",
       "      <th>d2v_AVG_tag_data27</th>\n",
       "      <th>d2v_AVG_tag_data28</th>\n",
       "      <th>d2v_AVG_tag_data29</th>\n",
       "      <th>d2v_AVG_tag_data30</th>\n",
       "      <th>d2v_AVG_tag_data31</th>\n",
       "      <th>d2v_AVG_tag_data32</th>\n",
       "      <th>d2v_AVG_tag_data33</th>\n",
       "      <th>d2v_AVG_tag_data34</th>\n",
       "      <th>d2v_AVG_tag_data35</th>\n",
       "      <th>d2v_AVG_tag_data36</th>\n",
       "      <th>d2v_AVG_tag_data37</th>\n",
       "      <th>d2v_AVG_tag_data38</th>\n",
       "      <th>d2v_AVG_tag_data39</th>\n",
       "      <th>d2v_AVG_tag_data40</th>\n",
       "      <th>d2v_AVG_tag_data41</th>\n",
       "      <th>d2v_AVG_tag_data42</th>\n",
       "      <th>d2v_AVG_tag_data43</th>\n",
       "      <th>d2v_AVG_tag_data44</th>\n",
       "      <th>d2v_AVG_tag_data45</th>\n",
       "      <th>d2v_AVG_tag_data46</th>\n",
       "      <th>d2v_AVG_tag_data47</th>\n",
       "      <th>d2v_AVG_tag_data48</th>\n",
       "      <th>d2v_AVG_tag_data49</th>\n",
       "      <th>d2v_AVG_tag_data50</th>\n",
       "      <th>d2v_AVG_tag_data51</th>\n",
       "      <th>d2v_AVG_tag_data52</th>\n",
       "      <th>d2v_AVG_tag_data53</th>\n",
       "      <th>d2v_AVG_tag_data54</th>\n",
       "      <th>d2v_AVG_tag_data55</th>\n",
       "      <th>d2v_AVG_tag_data56</th>\n",
       "      <th>d2v_AVG_tag_data57</th>\n",
       "      <th>d2v_AVG_tag_data58</th>\n",
       "      <th>d2v_AVG_tag_data59</th>\n",
       "      <th>d2v_AVG_tag_data60</th>\n",
       "      <th>d2v_AVG_tag_data61</th>\n",
       "      <th>d2v_AVG_tag_data62</th>\n",
       "      <th>d2v_AVG_tag_data63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>3978968</td>\n",
       "      <td>10262467</td>\n",
       "      <td>1917997</td>\n",
       "      <td>608976</td>\n",
       "      <td>4723291</td>\n",
       "      <td>16862</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.005379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3340.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38706112.0</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>38966296.0</td>\n",
       "      <td>218182.0</td>\n",
       "      <td>45601856.0</td>\n",
       "      <td>1845546.0</td>\n",
       "      <td>104100512.0</td>\n",
       "      <td>42743124.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74353472.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97950664.0</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>218182.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43075932.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59235176.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.502930</td>\n",
       "      <td>0.014778</td>\n",
       "      <td>0.129883</td>\n",
       "      <td>0.162964</td>\n",
       "      <td>0.152954</td>\n",
       "      <td>-0.049377</td>\n",
       "      <td>0.108521</td>\n",
       "      <td>0.099731</td>\n",
       "      <td>0.397217</td>\n",
       "      <td>-0.130859</td>\n",
       "      <td>-0.044067</td>\n",
       "      <td>-0.691895</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.344482</td>\n",
       "      <td>0.001275</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>-0.000605</td>\n",
       "      <td>-0.002760</td>\n",
       "      <td>-0.003790</td>\n",
       "      <td>-0.002687</td>\n",
       "      <td>-0.938965</td>\n",
       "      <td>-0.493896</td>\n",
       "      <td>0.178345</td>\n",
       "      <td>-0.666504</td>\n",
       "      <td>0.039032</td>\n",
       "      <td>-0.119263</td>\n",
       "      <td>-0.439453</td>\n",
       "      <td>-0.027100</td>\n",
       "      <td>-0.102661</td>\n",
       "      <td>0.026093</td>\n",
       "      <td>0.104431</td>\n",
       "      <td>-0.027176</td>\n",
       "      <td>-0.217163</td>\n",
       "      <td>-0.256836</td>\n",
       "      <td>0.190674</td>\n",
       "      <td>-0.386230</td>\n",
       "      <td>-0.181885</td>\n",
       "      <td>0.701172</td>\n",
       "      <td>0.299316</td>\n",
       "      <td>-0.311279</td>\n",
       "      <td>0.074585</td>\n",
       "      <td>-0.028839</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.060944</td>\n",
       "      <td>-0.149414</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>-0.361572</td>\n",
       "      <td>0.010559</td>\n",
       "      <td>-0.175537</td>\n",
       "      <td>0.038452</td>\n",
       "      <td>0.873047</td>\n",
       "      <td>-0.003801</td>\n",
       "      <td>-0.267090</td>\n",
       "      <td>-0.011574</td>\n",
       "      <td>0.054718</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>-0.445557</td>\n",
       "      <td>0.003216</td>\n",
       "      <td>0.662598</td>\n",
       "      <td>-0.000787</td>\n",
       "      <td>0.520996</td>\n",
       "      <td>-0.210449</td>\n",
       "      <td>0.012054</td>\n",
       "      <td>0.125732</td>\n",
       "      <td>-0.174927</td>\n",
       "      <td>-0.006397</td>\n",
       "      <td>-0.244385</td>\n",
       "      <td>0.677246</td>\n",
       "      <td>-0.023605</td>\n",
       "      <td>0.248535</td>\n",
       "      <td>-0.416992</td>\n",
       "      <td>-0.255371</td>\n",
       "      <td>-0.323242</td>\n",
       "      <td>0.046844</td>\n",
       "      <td>0.059753</td>\n",
       "      <td>-0.115845</td>\n",
       "      <td>0.229370</td>\n",
       "      <td>-0.062744</td>\n",
       "      <td>0.392090</td>\n",
       "      <td>0.312744</td>\n",
       "      <td>-0.057617</td>\n",
       "      <td>0.248169</td>\n",
       "      <td>-0.309082</td>\n",
       "      <td>0.051453</td>\n",
       "      <td>0.306396</td>\n",
       "      <td>0.084961</td>\n",
       "      <td>-0.006470</td>\n",
       "      <td>-0.001395</td>\n",
       "      <td>0.443115</td>\n",
       "      <td>-0.536621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82968</td>\n",
       "      <td>82968.0</td>\n",
       "      <td>82968.000000</td>\n",
       "      <td>82968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.229667</td>\n",
       "      <td>0.169944</td>\n",
       "      <td>-2.900885</td>\n",
       "      <td>-0.315794</td>\n",
       "      <td>0.124433</td>\n",
       "      <td>2.031552</td>\n",
       "      <td>0.353802</td>\n",
       "      <td>-2.051236</td>\n",
       "      <td>-0.223169</td>\n",
       "      <td>1.835867</td>\n",
       "      <td>0.867515</td>\n",
       "      <td>0.551410</td>\n",
       "      <td>0.138699</td>\n",
       "      <td>-1.922290</td>\n",
       "      <td>0.704013</td>\n",
       "      <td>0.352666</td>\n",
       "      <td>-0.955298</td>\n",
       "      <td>-0.462648</td>\n",
       "      <td>-0.598233</td>\n",
       "      <td>0.018943</td>\n",
       "      <td>0.021031</td>\n",
       "      <td>-1.203783</td>\n",
       "      <td>1.928731</td>\n",
       "      <td>2.574627</td>\n",
       "      <td>0.105483</td>\n",
       "      <td>0.294248</td>\n",
       "      <td>2.049570</td>\n",
       "      <td>-1.422524</td>\n",
       "      <td>1.005745</td>\n",
       "      <td>-2.768200</td>\n",
       "      <td>0.037534</td>\n",
       "      <td>-4.287595</td>\n",
       "      <td>0.360542</td>\n",
       "      <td>1.584735</td>\n",
       "      <td>0.122490</td>\n",
       "      <td>-1.142156</td>\n",
       "      <td>-3.268960</td>\n",
       "      <td>-2.070098</td>\n",
       "      <td>-1.195602</td>\n",
       "      <td>-0.467857</td>\n",
       "      <td>3.079487</td>\n",
       "      <td>0.163314</td>\n",
       "      <td>0.277376</td>\n",
       "      <td>-0.257015</td>\n",
       "      <td>-2.257203</td>\n",
       "      <td>4.383832</td>\n",
       "      <td>-1.318662</td>\n",
       "      <td>1.172728</td>\n",
       "      <td>0.787811</td>\n",
       "      <td>-0.427047</td>\n",
       "      <td>-0.960159</td>\n",
       "      <td>0.298820</td>\n",
       "      <td>0.155137</td>\n",
       "      <td>-1.832210</td>\n",
       "      <td>0.402113</td>\n",
       "      <td>0.563161</td>\n",
       "      <td>0.848237</td>\n",
       "      <td>-2.778049</td>\n",
       "      <td>1.024568</td>\n",
       "      <td>1.785690</td>\n",
       "      <td>-0.591784</td>\n",
       "      <td>-2.410546</td>\n",
       "      <td>1.044089</td>\n",
       "      <td>1.520381</td>\n",
       "      <td>-0.129813</td>\n",
       "      <td>-0.756047</td>\n",
       "      <td>0.143118</td>\n",
       "      <td>-3.003398</td>\n",
       "      <td>1.596543</td>\n",
       "      <td>-0.584900</td>\n",
       "      <td>-1.596267</td>\n",
       "      <td>0.030542</td>\n",
       "      <td>0.388159</td>\n",
       "      <td>-0.557379</td>\n",
       "      <td>0.854521</td>\n",
       "      <td>0.894725</td>\n",
       "      <td>-0.186736</td>\n",
       "      <td>-1.806087</td>\n",
       "      <td>1.897598</td>\n",
       "      <td>-0.131564</td>\n",
       "      <td>0.024668</td>\n",
       "      <td>-2.561837</td>\n",
       "      <td>2.267524</td>\n",
       "      <td>-2.068393</td>\n",
       "      <td>-2.761788</td>\n",
       "      <td>2.386210</td>\n",
       "      <td>-2.718360</td>\n",
       "      <td>-0.548159</td>\n",
       "      <td>1.835239</td>\n",
       "      <td>-1.510004</td>\n",
       "      <td>1.048621</td>\n",
       "      <td>0.541290</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>0.796095</td>\n",
       "      <td>1.088916</td>\n",
       "      <td>-0.767209</td>\n",
       "      <td>1.343837</td>\n",
       "      <td>0.606001</td>\n",
       "      <td>-0.455894</td>\n",
       "      <td>0.051227</td>\n",
       "      <td>1.232644</td>\n",
       "      <td>0.424371</td>\n",
       "      <td>0.432421</td>\n",
       "      <td>0.239747</td>\n",
       "      <td>-1.199381</td>\n",
       "      <td>-0.008993</td>\n",
       "      <td>-2.286062</td>\n",
       "      <td>-0.058223</td>\n",
       "      <td>-0.152359</td>\n",
       "      <td>-0.061779</td>\n",
       "      <td>-0.566637</td>\n",
       "      <td>-1.288559</td>\n",
       "      <td>-2.503040</td>\n",
       "      <td>-0.225740</td>\n",
       "      <td>-0.904949</td>\n",
       "      <td>0.103600</td>\n",
       "      <td>2.627889</td>\n",
       "      <td>0.587643</td>\n",
       "      <td>1.011122</td>\n",
       "      <td>-2.079236</td>\n",
       "      <td>-0.159566</td>\n",
       "      <td>1.615453</td>\n",
       "      <td>3.527793</td>\n",
       "      <td>2.074279</td>\n",
       "      <td>-0.530506</td>\n",
       "      <td>1.772412</td>\n",
       "      <td>0.015235</td>\n",
       "      <td>0.065970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>3978968</td>\n",
       "      <td>10262467</td>\n",
       "      <td>1917997</td>\n",
       "      <td>2944146</td>\n",
       "      <td>4723291</td>\n",
       "      <td>16862</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.005379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1098.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>1164.0</td>\n",
       "      <td>2206.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>217048.0</td>\n",
       "      <td>38707248.0</td>\n",
       "      <td>1844412.0</td>\n",
       "      <td>38967432.0</td>\n",
       "      <td>19481908.0</td>\n",
       "      <td>97951792.0</td>\n",
       "      <td>43074800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91311352.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2206.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>217048.0</td>\n",
       "      <td>97951792.0</td>\n",
       "      <td>43074800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58265816.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158717248.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2206.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2206.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2206.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2206.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.502930</td>\n",
       "      <td>0.014778</td>\n",
       "      <td>0.129883</td>\n",
       "      <td>0.162964</td>\n",
       "      <td>0.152954</td>\n",
       "      <td>-0.049377</td>\n",
       "      <td>0.108521</td>\n",
       "      <td>0.099731</td>\n",
       "      <td>0.397217</td>\n",
       "      <td>-0.130859</td>\n",
       "      <td>-0.044067</td>\n",
       "      <td>-0.691895</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.344482</td>\n",
       "      <td>0.001275</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>-0.000605</td>\n",
       "      <td>-0.002760</td>\n",
       "      <td>-0.003790</td>\n",
       "      <td>-0.002687</td>\n",
       "      <td>-0.938965</td>\n",
       "      <td>-0.493896</td>\n",
       "      <td>0.178345</td>\n",
       "      <td>-0.666504</td>\n",
       "      <td>0.039032</td>\n",
       "      <td>-0.119263</td>\n",
       "      <td>-0.439453</td>\n",
       "      <td>-0.027100</td>\n",
       "      <td>-0.102661</td>\n",
       "      <td>0.026093</td>\n",
       "      <td>0.104431</td>\n",
       "      <td>-0.027176</td>\n",
       "      <td>-0.217163</td>\n",
       "      <td>-0.256836</td>\n",
       "      <td>0.190674</td>\n",
       "      <td>-0.386230</td>\n",
       "      <td>-0.181885</td>\n",
       "      <td>0.701172</td>\n",
       "      <td>0.299316</td>\n",
       "      <td>-0.311279</td>\n",
       "      <td>0.074585</td>\n",
       "      <td>-0.028839</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.060944</td>\n",
       "      <td>-0.149414</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>-0.361572</td>\n",
       "      <td>0.010559</td>\n",
       "      <td>-0.175537</td>\n",
       "      <td>0.038452</td>\n",
       "      <td>0.873047</td>\n",
       "      <td>-0.003801</td>\n",
       "      <td>-0.267090</td>\n",
       "      <td>-0.011574</td>\n",
       "      <td>0.054718</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>-0.445557</td>\n",
       "      <td>0.003216</td>\n",
       "      <td>0.662598</td>\n",
       "      <td>-0.000787</td>\n",
       "      <td>0.520996</td>\n",
       "      <td>-0.210449</td>\n",
       "      <td>0.012054</td>\n",
       "      <td>0.125732</td>\n",
       "      <td>-0.174927</td>\n",
       "      <td>-0.006397</td>\n",
       "      <td>-0.244385</td>\n",
       "      <td>0.677246</td>\n",
       "      <td>-0.023605</td>\n",
       "      <td>0.248535</td>\n",
       "      <td>-0.416992</td>\n",
       "      <td>-0.255371</td>\n",
       "      <td>-0.323242</td>\n",
       "      <td>0.046844</td>\n",
       "      <td>0.059753</td>\n",
       "      <td>-0.115845</td>\n",
       "      <td>0.229370</td>\n",
       "      <td>-0.062744</td>\n",
       "      <td>0.375488</td>\n",
       "      <td>0.319824</td>\n",
       "      <td>-0.021744</td>\n",
       "      <td>0.266113</td>\n",
       "      <td>-0.322510</td>\n",
       "      <td>0.093567</td>\n",
       "      <td>0.349609</td>\n",
       "      <td>0.142822</td>\n",
       "      <td>-0.030502</td>\n",
       "      <td>-0.083679</td>\n",
       "      <td>0.398193</td>\n",
       "      <td>-0.513672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82968</td>\n",
       "      <td>82968.0</td>\n",
       "      <td>82968.000000</td>\n",
       "      <td>82968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.229667</td>\n",
       "      <td>0.169944</td>\n",
       "      <td>-2.900885</td>\n",
       "      <td>-0.315794</td>\n",
       "      <td>0.124433</td>\n",
       "      <td>2.031552</td>\n",
       "      <td>0.353802</td>\n",
       "      <td>-2.051236</td>\n",
       "      <td>-0.223169</td>\n",
       "      <td>1.835867</td>\n",
       "      <td>0.867515</td>\n",
       "      <td>0.551410</td>\n",
       "      <td>0.138699</td>\n",
       "      <td>-1.922290</td>\n",
       "      <td>0.704013</td>\n",
       "      <td>0.352666</td>\n",
       "      <td>-0.955298</td>\n",
       "      <td>-0.462648</td>\n",
       "      <td>-0.598233</td>\n",
       "      <td>0.018943</td>\n",
       "      <td>0.021031</td>\n",
       "      <td>-1.203783</td>\n",
       "      <td>1.928731</td>\n",
       "      <td>2.574627</td>\n",
       "      <td>0.105483</td>\n",
       "      <td>0.294248</td>\n",
       "      <td>2.049570</td>\n",
       "      <td>-1.422524</td>\n",
       "      <td>1.005745</td>\n",
       "      <td>-2.768200</td>\n",
       "      <td>0.037534</td>\n",
       "      <td>-4.287595</td>\n",
       "      <td>0.360542</td>\n",
       "      <td>1.584735</td>\n",
       "      <td>0.122490</td>\n",
       "      <td>-1.142156</td>\n",
       "      <td>-3.268960</td>\n",
       "      <td>-2.070098</td>\n",
       "      <td>-1.195602</td>\n",
       "      <td>-0.467857</td>\n",
       "      <td>3.079487</td>\n",
       "      <td>0.163314</td>\n",
       "      <td>0.277376</td>\n",
       "      <td>-0.257015</td>\n",
       "      <td>-2.257203</td>\n",
       "      <td>4.383832</td>\n",
       "      <td>-1.318662</td>\n",
       "      <td>1.172728</td>\n",
       "      <td>0.787811</td>\n",
       "      <td>-0.427047</td>\n",
       "      <td>-0.960159</td>\n",
       "      <td>0.298820</td>\n",
       "      <td>0.155137</td>\n",
       "      <td>-1.832210</td>\n",
       "      <td>0.402113</td>\n",
       "      <td>0.563161</td>\n",
       "      <td>0.848237</td>\n",
       "      <td>-2.778049</td>\n",
       "      <td>1.024568</td>\n",
       "      <td>1.785690</td>\n",
       "      <td>-0.591784</td>\n",
       "      <td>-2.410546</td>\n",
       "      <td>1.044089</td>\n",
       "      <td>1.520381</td>\n",
       "      <td>-0.129813</td>\n",
       "      <td>-0.756047</td>\n",
       "      <td>0.143118</td>\n",
       "      <td>-3.003398</td>\n",
       "      <td>1.596543</td>\n",
       "      <td>-0.584900</td>\n",
       "      <td>-1.596267</td>\n",
       "      <td>0.030542</td>\n",
       "      <td>0.388159</td>\n",
       "      <td>-0.557379</td>\n",
       "      <td>0.854521</td>\n",
       "      <td>0.894725</td>\n",
       "      <td>-0.186736</td>\n",
       "      <td>-1.806087</td>\n",
       "      <td>1.897598</td>\n",
       "      <td>-0.131564</td>\n",
       "      <td>0.024668</td>\n",
       "      <td>-2.561837</td>\n",
       "      <td>2.267524</td>\n",
       "      <td>-2.068393</td>\n",
       "      <td>-2.761788</td>\n",
       "      <td>2.386210</td>\n",
       "      <td>-2.718360</td>\n",
       "      <td>-0.548159</td>\n",
       "      <td>1.835239</td>\n",
       "      <td>-1.510004</td>\n",
       "      <td>1.048621</td>\n",
       "      <td>0.541290</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>0.796095</td>\n",
       "      <td>1.088916</td>\n",
       "      <td>-0.767209</td>\n",
       "      <td>1.343837</td>\n",
       "      <td>0.606001</td>\n",
       "      <td>-0.455894</td>\n",
       "      <td>0.051227</td>\n",
       "      <td>1.232644</td>\n",
       "      <td>0.424371</td>\n",
       "      <td>0.432421</td>\n",
       "      <td>0.239747</td>\n",
       "      <td>-1.199381</td>\n",
       "      <td>-0.008993</td>\n",
       "      <td>-2.286062</td>\n",
       "      <td>-0.058223</td>\n",
       "      <td>-0.152359</td>\n",
       "      <td>-0.061779</td>\n",
       "      <td>-0.566637</td>\n",
       "      <td>-1.288559</td>\n",
       "      <td>-2.503040</td>\n",
       "      <td>-0.225740</td>\n",
       "      <td>-0.904949</td>\n",
       "      <td>0.103600</td>\n",
       "      <td>2.627889</td>\n",
       "      <td>0.587643</td>\n",
       "      <td>1.011122</td>\n",
       "      <td>-2.079236</td>\n",
       "      <td>-0.159566</td>\n",
       "      <td>1.615453</td>\n",
       "      <td>3.527793</td>\n",
       "      <td>2.074279</td>\n",
       "      <td>-0.530506</td>\n",
       "      <td>1.772412</td>\n",
       "      <td>0.015235</td>\n",
       "      <td>0.065970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>87</td>\n",
       "      <td>3124234</td>\n",
       "      <td>21153</td>\n",
       "      <td>4191913</td>\n",
       "      <td>2944146</td>\n",
       "      <td>4335577</td>\n",
       "      <td>51022</td>\n",
       "      <td>2231783</td>\n",
       "      <td>2231783</td>\n",
       "      <td>2231783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29098.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>31575.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>31629.0</td>\n",
       "      <td>1046.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18560.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78409.0</td>\n",
       "      <td>499575.0</td>\n",
       "      <td>951027.0</td>\n",
       "      <td>538234.0</td>\n",
       "      <td>2108357.0</td>\n",
       "      <td>934449.0</td>\n",
       "      <td>2734495.0</td>\n",
       "      <td>3920295.0</td>\n",
       "      <td>3599072.0</td>\n",
       "      <td>8957758.0</td>\n",
       "      <td>11642736.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>1142.0</td>\n",
       "      <td>771.0</td>\n",
       "      <td>2034.0</td>\n",
       "      <td>2378.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18564.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37186.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8957758.0</td>\n",
       "      <td>3599072.0</td>\n",
       "      <td>19305764.0</td>\n",
       "      <td>11642736.0</td>\n",
       "      <td>37800676.0</td>\n",
       "      <td>16492735.0</td>\n",
       "      <td>168928400.0</td>\n",
       "      <td>66187736.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>1427.0</td>\n",
       "      <td>4293.0</td>\n",
       "      <td>4251.0</td>\n",
       "      <td>5707.0</td>\n",
       "      <td>8676.0</td>\n",
       "      <td>7495.0</td>\n",
       "      <td>10598.0</td>\n",
       "      <td>13198.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37186.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31575.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>31629.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18564.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18564.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105975.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>1431.0</td>\n",
       "      <td>3372.0</td>\n",
       "      <td>6140.0</td>\n",
       "      <td>7915.0</td>\n",
       "      <td>29098.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>31575.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>31629.0</td>\n",
       "      <td>1046.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31575.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>31629.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>1427.0</td>\n",
       "      <td>7495.0</td>\n",
       "      <td>6144.0</td>\n",
       "      <td>7949.0</td>\n",
       "      <td>9303.0</td>\n",
       "      <td>13819.0</td>\n",
       "      <td>19652.0</td>\n",
       "      <td>20776.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.078186</td>\n",
       "      <td>0.263428</td>\n",
       "      <td>0.289551</td>\n",
       "      <td>0.046448</td>\n",
       "      <td>0.199829</td>\n",
       "      <td>-0.338379</td>\n",
       "      <td>-0.049225</td>\n",
       "      <td>-0.733887</td>\n",
       "      <td>-0.030838</td>\n",
       "      <td>0.093689</td>\n",
       "      <td>-0.267334</td>\n",
       "      <td>-0.248535</td>\n",
       "      <td>-0.245361</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.059174</td>\n",
       "      <td>0.233154</td>\n",
       "      <td>0.586426</td>\n",
       "      <td>0.047699</td>\n",
       "      <td>0.249756</td>\n",
       "      <td>0.051117</td>\n",
       "      <td>-0.220581</td>\n",
       "      <td>0.637695</td>\n",
       "      <td>0.123352</td>\n",
       "      <td>-0.007858</td>\n",
       "      <td>-0.501465</td>\n",
       "      <td>0.174561</td>\n",
       "      <td>-0.657715</td>\n",
       "      <td>0.022232</td>\n",
       "      <td>-0.029495</td>\n",
       "      <td>-0.478760</td>\n",
       "      <td>-0.010292</td>\n",
       "      <td>-0.204224</td>\n",
       "      <td>0.097107</td>\n",
       "      <td>0.035980</td>\n",
       "      <td>-0.051910</td>\n",
       "      <td>-0.001026</td>\n",
       "      <td>-0.428711</td>\n",
       "      <td>0.255371</td>\n",
       "      <td>-0.456543</td>\n",
       "      <td>-0.115417</td>\n",
       "      <td>0.599121</td>\n",
       "      <td>0.090637</td>\n",
       "      <td>-0.317139</td>\n",
       "      <td>-0.086609</td>\n",
       "      <td>0.055817</td>\n",
       "      <td>0.111694</td>\n",
       "      <td>0.054413</td>\n",
       "      <td>-0.187988</td>\n",
       "      <td>0.059479</td>\n",
       "      <td>0.586914</td>\n",
       "      <td>-0.001003</td>\n",
       "      <td>-0.736328</td>\n",
       "      <td>-0.058136</td>\n",
       "      <td>-0.000503</td>\n",
       "      <td>-0.002249</td>\n",
       "      <td>-0.326172</td>\n",
       "      <td>0.010796</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>-0.001086</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>-0.260010</td>\n",
       "      <td>0.965820</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>-0.006207</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.226318</td>\n",
       "      <td>0.659180</td>\n",
       "      <td>-0.123352</td>\n",
       "      <td>0.211548</td>\n",
       "      <td>-0.154419</td>\n",
       "      <td>-0.024704</td>\n",
       "      <td>-0.329834</td>\n",
       "      <td>0.016953</td>\n",
       "      <td>0.152710</td>\n",
       "      <td>-0.366211</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.403320</td>\n",
       "      <td>0.999512</td>\n",
       "      <td>-0.029022</td>\n",
       "      <td>-0.006161</td>\n",
       "      <td>-0.001901</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>-0.001487</td>\n",
       "      <td>-0.002813</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>-0.001728</td>\n",
       "      <td>-0.001726</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>8007.348429</td>\n",
       "      <td>232</td>\n",
       "      <td>8728.0</td>\n",
       "      <td>9892.807229</td>\n",
       "      <td>54727</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>6.375039</td>\n",
       "      <td>0.060241</td>\n",
       "      <td>5</td>\n",
       "      <td>0.239379</td>\n",
       "      <td>0.530120</td>\n",
       "      <td>44</td>\n",
       "      <td>0.502126</td>\n",
       "      <td>0.409639</td>\n",
       "      <td>34</td>\n",
       "      <td>0.494757</td>\n",
       "      <td>0.083251</td>\n",
       "      <td>-1.161481</td>\n",
       "      <td>-2.432074</td>\n",
       "      <td>-0.398634</td>\n",
       "      <td>-0.051843</td>\n",
       "      <td>-1.733800</td>\n",
       "      <td>0.555071</td>\n",
       "      <td>-0.139786</td>\n",
       "      <td>0.959530</td>\n",
       "      <td>0.568446</td>\n",
       "      <td>-0.598247</td>\n",
       "      <td>0.270606</td>\n",
       "      <td>0.376979</td>\n",
       "      <td>0.118636</td>\n",
       "      <td>-0.806627</td>\n",
       "      <td>-0.648791</td>\n",
       "      <td>-1.445588</td>\n",
       "      <td>-0.630914</td>\n",
       "      <td>-0.314666</td>\n",
       "      <td>0.202973</td>\n",
       "      <td>0.743717</td>\n",
       "      <td>0.755314</td>\n",
       "      <td>-0.124471</td>\n",
       "      <td>0.657093</td>\n",
       "      <td>-0.126836</td>\n",
       "      <td>0.587155</td>\n",
       "      <td>-1.227516</td>\n",
       "      <td>-0.327221</td>\n",
       "      <td>-0.416939</td>\n",
       "      <td>-2.411052</td>\n",
       "      <td>-0.488869</td>\n",
       "      <td>-0.431798</td>\n",
       "      <td>0.595850</td>\n",
       "      <td>1.019894</td>\n",
       "      <td>0.141429</td>\n",
       "      <td>-0.595154</td>\n",
       "      <td>-0.995288</td>\n",
       "      <td>-0.620115</td>\n",
       "      <td>-1.025364</td>\n",
       "      <td>0.373070</td>\n",
       "      <td>0.488267</td>\n",
       "      <td>-0.158316</td>\n",
       "      <td>0.925359</td>\n",
       "      <td>-0.932690</td>\n",
       "      <td>-0.287787</td>\n",
       "      <td>0.167010</td>\n",
       "      <td>-1.062522</td>\n",
       "      <td>0.940552</td>\n",
       "      <td>-1.887199</td>\n",
       "      <td>-1.232756</td>\n",
       "      <td>1.301492</td>\n",
       "      <td>0.286067</td>\n",
       "      <td>-0.099003</td>\n",
       "      <td>-0.703239</td>\n",
       "      <td>-0.824787</td>\n",
       "      <td>-0.481791</td>\n",
       "      <td>0.822675</td>\n",
       "      <td>-0.023474</td>\n",
       "      <td>-0.938707</td>\n",
       "      <td>-0.236663</td>\n",
       "      <td>1.508289</td>\n",
       "      <td>-0.073710</td>\n",
       "      <td>0.321595</td>\n",
       "      <td>1.408211</td>\n",
       "      <td>0.332665</td>\n",
       "      <td>-1.183276</td>\n",
       "      <td>0.460998</td>\n",
       "      <td>0.678209</td>\n",
       "      <td>-0.088636</td>\n",
       "      <td>0.753745</td>\n",
       "      <td>0.270165</td>\n",
       "      <td>0.993128</td>\n",
       "      <td>-0.927194</td>\n",
       "      <td>-0.484972</td>\n",
       "      <td>0.327580</td>\n",
       "      <td>0.353591</td>\n",
       "      <td>1.495096</td>\n",
       "      <td>0.292199</td>\n",
       "      <td>-1.466242</td>\n",
       "      <td>-1.294926</td>\n",
       "      <td>0.586212</td>\n",
       "      <td>1.577252</td>\n",
       "      <td>-0.345576</td>\n",
       "      <td>0.389614</td>\n",
       "      <td>1.346425</td>\n",
       "      <td>-1.408652</td>\n",
       "      <td>1.997177</td>\n",
       "      <td>0.811635</td>\n",
       "      <td>0.333166</td>\n",
       "      <td>1.139411</td>\n",
       "      <td>0.235408</td>\n",
       "      <td>-0.059956</td>\n",
       "      <td>0.789531</td>\n",
       "      <td>-0.040708</td>\n",
       "      <td>-0.726710</td>\n",
       "      <td>-0.972379</td>\n",
       "      <td>-0.677353</td>\n",
       "      <td>-0.488385</td>\n",
       "      <td>-0.626552</td>\n",
       "      <td>0.752678</td>\n",
       "      <td>-0.228315</td>\n",
       "      <td>-0.213311</td>\n",
       "      <td>0.774806</td>\n",
       "      <td>0.892837</td>\n",
       "      <td>0.874291</td>\n",
       "      <td>-1.411790</td>\n",
       "      <td>-0.446326</td>\n",
       "      <td>-1.297786</td>\n",
       "      <td>-0.503773</td>\n",
       "      <td>0.452777</td>\n",
       "      <td>0.103847</td>\n",
       "      <td>0.671636</td>\n",
       "      <td>0.621443</td>\n",
       "      <td>-0.074798</td>\n",
       "      <td>1.488750</td>\n",
       "      <td>0.290481</td>\n",
       "      <td>-0.202093</td>\n",
       "      <td>-0.917715</td>\n",
       "      <td>-0.636657</td>\n",
       "      <td>1.729508</td>\n",
       "      <td>0.079522</td>\n",
       "      <td>-1.216082</td>\n",
       "      <td>-0.983511</td>\n",
       "      <td>-0.244144</td>\n",
       "      <td>-0.378886</td>\n",
       "      <td>-0.323935</td>\n",
       "      <td>0.244617</td>\n",
       "      <td>-0.926933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>3978968</td>\n",
       "      <td>21153</td>\n",
       "      <td>4191913</td>\n",
       "      <td>2944146</td>\n",
       "      <td>4335577</td>\n",
       "      <td>51022</td>\n",
       "      <td>2231783</td>\n",
       "      <td>2231783</td>\n",
       "      <td>2231783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2477.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31575.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32156.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32621.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53840.0</td>\n",
       "      <td>18044740.0</td>\n",
       "      <td>14122617.0</td>\n",
       "      <td>21919968.0</td>\n",
       "      <td>16511740.0</td>\n",
       "      <td>31771756.0</td>\n",
       "      <td>18323212.0</td>\n",
       "      <td>40624088.0</td>\n",
       "      <td>19697480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>454.0</td>\n",
       "      <td>735.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>1517.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>2430.0</td>\n",
       "      <td>2290.0</td>\n",
       "      <td>4467.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32278.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50146.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53840.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136966.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21919968.0</td>\n",
       "      <td>16511740.0</td>\n",
       "      <td>31771756.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40624088.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>454.0</td>\n",
       "      <td>735.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>3656.0</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>4448.0</td>\n",
       "      <td>3510.0</td>\n",
       "      <td>6097.0</td>\n",
       "      <td>5029.0</td>\n",
       "      <td>8007.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32278.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53840.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109984.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>31575.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32156.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32278.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50135.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137550.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32278.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50146.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136966.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>6252.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>6267.0</td>\n",
       "      <td>4017.0</td>\n",
       "      <td>6970.0</td>\n",
       "      <td>7824.0</td>\n",
       "      <td>7693.0</td>\n",
       "      <td>12653.0</td>\n",
       "      <td>7947.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2477.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31575.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32156.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32621.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>31575.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32156.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32278.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>6267.0</td>\n",
       "      <td>7795.0</td>\n",
       "      <td>7716.0</td>\n",
       "      <td>8739.0</td>\n",
       "      <td>7847.0</td>\n",
       "      <td>17841.0</td>\n",
       "      <td>10963.0</td>\n",
       "      <td>35027.0</td>\n",
       "      <td>15064.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32278.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.078186</td>\n",
       "      <td>0.263428</td>\n",
       "      <td>0.289551</td>\n",
       "      <td>0.046448</td>\n",
       "      <td>0.199829</td>\n",
       "      <td>-0.338379</td>\n",
       "      <td>-0.049225</td>\n",
       "      <td>-0.733887</td>\n",
       "      <td>-0.030838</td>\n",
       "      <td>0.093689</td>\n",
       "      <td>-0.267334</td>\n",
       "      <td>-0.248535</td>\n",
       "      <td>-0.245361</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.059174</td>\n",
       "      <td>0.233154</td>\n",
       "      <td>0.586426</td>\n",
       "      <td>0.047699</td>\n",
       "      <td>0.249756</td>\n",
       "      <td>0.051117</td>\n",
       "      <td>-0.220581</td>\n",
       "      <td>0.637695</td>\n",
       "      <td>0.123352</td>\n",
       "      <td>-0.007858</td>\n",
       "      <td>-0.501465</td>\n",
       "      <td>0.174561</td>\n",
       "      <td>-0.657715</td>\n",
       "      <td>0.022232</td>\n",
       "      <td>-0.029495</td>\n",
       "      <td>-0.478760</td>\n",
       "      <td>-0.010292</td>\n",
       "      <td>-0.204224</td>\n",
       "      <td>0.097107</td>\n",
       "      <td>0.035980</td>\n",
       "      <td>-0.051910</td>\n",
       "      <td>-0.001026</td>\n",
       "      <td>-0.550781</td>\n",
       "      <td>0.251221</td>\n",
       "      <td>-0.387451</td>\n",
       "      <td>-0.122009</td>\n",
       "      <td>0.603516</td>\n",
       "      <td>-0.103943</td>\n",
       "      <td>-0.263184</td>\n",
       "      <td>-0.091064</td>\n",
       "      <td>-0.024979</td>\n",
       "      <td>0.044098</td>\n",
       "      <td>0.007622</td>\n",
       "      <td>-0.117004</td>\n",
       "      <td>0.059479</td>\n",
       "      <td>0.586914</td>\n",
       "      <td>-0.001003</td>\n",
       "      <td>-0.736328</td>\n",
       "      <td>-0.058136</td>\n",
       "      <td>-0.000503</td>\n",
       "      <td>-0.002249</td>\n",
       "      <td>-0.326172</td>\n",
       "      <td>0.010796</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>-0.001086</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>-0.260010</td>\n",
       "      <td>0.965820</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>-0.006207</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.407471</td>\n",
       "      <td>0.448975</td>\n",
       "      <td>-0.065369</td>\n",
       "      <td>0.130981</td>\n",
       "      <td>0.008987</td>\n",
       "      <td>-0.044159</td>\n",
       "      <td>-0.336426</td>\n",
       "      <td>-0.155029</td>\n",
       "      <td>0.211426</td>\n",
       "      <td>-0.209473</td>\n",
       "      <td>-0.061279</td>\n",
       "      <td>-0.616211</td>\n",
       "      <td>0.999512</td>\n",
       "      <td>-0.029022</td>\n",
       "      <td>-0.006161</td>\n",
       "      <td>-0.001901</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>-0.001487</td>\n",
       "      <td>-0.002813</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>-0.001728</td>\n",
       "      <td>-0.001726</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>8007.348429</td>\n",
       "      <td>232</td>\n",
       "      <td>8728.0</td>\n",
       "      <td>9892.807229</td>\n",
       "      <td>54727</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>6.375039</td>\n",
       "      <td>0.060241</td>\n",
       "      <td>5</td>\n",
       "      <td>0.239379</td>\n",
       "      <td>0.530120</td>\n",
       "      <td>44</td>\n",
       "      <td>0.502126</td>\n",
       "      <td>0.409639</td>\n",
       "      <td>34</td>\n",
       "      <td>0.494757</td>\n",
       "      <td>0.083251</td>\n",
       "      <td>-1.161481</td>\n",
       "      <td>-2.432074</td>\n",
       "      <td>-0.398634</td>\n",
       "      <td>-0.051843</td>\n",
       "      <td>-1.733800</td>\n",
       "      <td>0.555071</td>\n",
       "      <td>-0.139786</td>\n",
       "      <td>0.959530</td>\n",
       "      <td>0.568446</td>\n",
       "      <td>-0.598247</td>\n",
       "      <td>0.270606</td>\n",
       "      <td>0.376979</td>\n",
       "      <td>0.118636</td>\n",
       "      <td>-0.806627</td>\n",
       "      <td>-0.648791</td>\n",
       "      <td>-1.445588</td>\n",
       "      <td>-0.630914</td>\n",
       "      <td>-0.314666</td>\n",
       "      <td>0.202973</td>\n",
       "      <td>0.743717</td>\n",
       "      <td>0.755314</td>\n",
       "      <td>-0.124471</td>\n",
       "      <td>0.657093</td>\n",
       "      <td>-0.126836</td>\n",
       "      <td>0.587155</td>\n",
       "      <td>-1.227516</td>\n",
       "      <td>-0.327221</td>\n",
       "      <td>-0.416939</td>\n",
       "      <td>-2.411052</td>\n",
       "      <td>-0.488869</td>\n",
       "      <td>-0.431798</td>\n",
       "      <td>0.595850</td>\n",
       "      <td>1.019894</td>\n",
       "      <td>0.141429</td>\n",
       "      <td>-0.595154</td>\n",
       "      <td>-0.995288</td>\n",
       "      <td>-0.620115</td>\n",
       "      <td>-1.025364</td>\n",
       "      <td>0.373070</td>\n",
       "      <td>0.488267</td>\n",
       "      <td>-0.158316</td>\n",
       "      <td>0.925359</td>\n",
       "      <td>-0.932690</td>\n",
       "      <td>-0.287787</td>\n",
       "      <td>0.167010</td>\n",
       "      <td>-1.062522</td>\n",
       "      <td>0.940552</td>\n",
       "      <td>-1.887199</td>\n",
       "      <td>-1.232756</td>\n",
       "      <td>1.301492</td>\n",
       "      <td>0.286067</td>\n",
       "      <td>-0.099003</td>\n",
       "      <td>-0.703239</td>\n",
       "      <td>-0.824787</td>\n",
       "      <td>-0.481791</td>\n",
       "      <td>0.822675</td>\n",
       "      <td>-0.023474</td>\n",
       "      <td>-0.938707</td>\n",
       "      <td>-0.236663</td>\n",
       "      <td>1.508289</td>\n",
       "      <td>-0.073710</td>\n",
       "      <td>0.321595</td>\n",
       "      <td>1.408211</td>\n",
       "      <td>0.332665</td>\n",
       "      <td>-1.183276</td>\n",
       "      <td>0.460998</td>\n",
       "      <td>0.678209</td>\n",
       "      <td>-0.088636</td>\n",
       "      <td>0.753745</td>\n",
       "      <td>0.270165</td>\n",
       "      <td>0.993128</td>\n",
       "      <td>-0.927194</td>\n",
       "      <td>-0.484972</td>\n",
       "      <td>0.327580</td>\n",
       "      <td>0.353591</td>\n",
       "      <td>1.495096</td>\n",
       "      <td>0.292199</td>\n",
       "      <td>-1.466242</td>\n",
       "      <td>-1.294926</td>\n",
       "      <td>0.586212</td>\n",
       "      <td>1.577252</td>\n",
       "      <td>-0.345576</td>\n",
       "      <td>0.389614</td>\n",
       "      <td>1.346425</td>\n",
       "      <td>-1.408652</td>\n",
       "      <td>1.997177</td>\n",
       "      <td>0.811635</td>\n",
       "      <td>0.333166</td>\n",
       "      <td>1.139411</td>\n",
       "      <td>0.235408</td>\n",
       "      <td>-0.059956</td>\n",
       "      <td>0.789531</td>\n",
       "      <td>-0.040708</td>\n",
       "      <td>-0.726710</td>\n",
       "      <td>-0.972379</td>\n",
       "      <td>-0.677353</td>\n",
       "      <td>-0.488385</td>\n",
       "      <td>-0.626552</td>\n",
       "      <td>0.752678</td>\n",
       "      <td>-0.228315</td>\n",
       "      <td>-0.213311</td>\n",
       "      <td>0.774806</td>\n",
       "      <td>0.892837</td>\n",
       "      <td>0.874291</td>\n",
       "      <td>-1.411790</td>\n",
       "      <td>-0.446326</td>\n",
       "      <td>-1.297786</td>\n",
       "      <td>-0.503773</td>\n",
       "      <td>0.452777</td>\n",
       "      <td>0.103847</td>\n",
       "      <td>0.671636</td>\n",
       "      <td>0.621443</td>\n",
       "      <td>-0.074798</td>\n",
       "      <td>1.488750</td>\n",
       "      <td>0.290481</td>\n",
       "      <td>-0.202093</td>\n",
       "      <td>-0.917715</td>\n",
       "      <td>-0.636657</td>\n",
       "      <td>1.729508</td>\n",
       "      <td>0.079522</td>\n",
       "      <td>-1.216082</td>\n",
       "      <td>-0.983511</td>\n",
       "      <td>-0.244144</td>\n",
       "      <td>-0.378886</td>\n",
       "      <td>-0.323935</td>\n",
       "      <td>0.244617</td>\n",
       "      <td>-0.926933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>248</td>\n",
       "      <td>4804432</td>\n",
       "      <td>2512842</td>\n",
       "      <td>851538</td>\n",
       "      <td>2944146</td>\n",
       "      <td>4723291</td>\n",
       "      <td>86569</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.145264</td>\n",
       "      <td>32.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.270996</td>\n",
       "      <td>2382.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90608584.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>90609472.0</td>\n",
       "      <td>40938752.0</td>\n",
       "      <td>90609544.0</td>\n",
       "      <td>40939036.0</td>\n",
       "      <td>90612520.0</td>\n",
       "      <td>42205436.0</td>\n",
       "      <td>1350820.0</td>\n",
       "      <td>2240470.0</td>\n",
       "      <td>2099693.0</td>\n",
       "      <td>2874429.0</td>\n",
       "      <td>3674688.0</td>\n",
       "      <td>3385208.0</td>\n",
       "      <td>6019809.0</td>\n",
       "      <td>4483977.0</td>\n",
       "      <td>13454169.0</td>\n",
       "      <td>6529699.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40938752.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40939036.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90608584.0</td>\n",
       "      <td>40938752.0</td>\n",
       "      <td>90609544.0</td>\n",
       "      <td>40939040.0</td>\n",
       "      <td>90612472.0</td>\n",
       "      <td>42205420.0</td>\n",
       "      <td>90612576.0</td>\n",
       "      <td>42206236.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42333392.0</td>\n",
       "      <td>1350820.0</td>\n",
       "      <td>2240470.0</td>\n",
       "      <td>2099693.0</td>\n",
       "      <td>2874429.0</td>\n",
       "      <td>3674688.0</td>\n",
       "      <td>3385208.0</td>\n",
       "      <td>6019809.0</td>\n",
       "      <td>4483977.0</td>\n",
       "      <td>14159585.0</td>\n",
       "      <td>6529699.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40938752.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40938752.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90609472.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90609536.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>90609544.0</td>\n",
       "      <td>40939036.0</td>\n",
       "      <td>90612496.0</td>\n",
       "      <td>42205464.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42217096.0</td>\n",
       "      <td>90609544.0</td>\n",
       "      <td>42205464.0</td>\n",
       "      <td>90612520.0</td>\n",
       "      <td>42206236.0</td>\n",
       "      <td>214526096.0</td>\n",
       "      <td>42217176.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42320676.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40939036.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40938752.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40939036.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40939036.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017181</td>\n",
       "      <td>0.180420</td>\n",
       "      <td>-0.172485</td>\n",
       "      <td>0.398193</td>\n",
       "      <td>0.126709</td>\n",
       "      <td>-0.002977</td>\n",
       "      <td>-0.187988</td>\n",
       "      <td>-0.645996</td>\n",
       "      <td>0.311035</td>\n",
       "      <td>-0.372070</td>\n",
       "      <td>0.240112</td>\n",
       "      <td>0.133057</td>\n",
       "      <td>-0.197266</td>\n",
       "      <td>0.004799</td>\n",
       "      <td>0.413574</td>\n",
       "      <td>0.018066</td>\n",
       "      <td>0.611328</td>\n",
       "      <td>0.357422</td>\n",
       "      <td>-0.290771</td>\n",
       "      <td>0.357422</td>\n",
       "      <td>-0.220947</td>\n",
       "      <td>-0.071472</td>\n",
       "      <td>0.133667</td>\n",
       "      <td>-0.062103</td>\n",
       "      <td>-0.388184</td>\n",
       "      <td>0.105164</td>\n",
       "      <td>-0.602051</td>\n",
       "      <td>0.061584</td>\n",
       "      <td>-0.116211</td>\n",
       "      <td>-0.562500</td>\n",
       "      <td>0.099670</td>\n",
       "      <td>-0.265137</td>\n",
       "      <td>0.093445</td>\n",
       "      <td>0.076050</td>\n",
       "      <td>-0.055054</td>\n",
       "      <td>-0.210571</td>\n",
       "      <td>-0.171753</td>\n",
       "      <td>0.213013</td>\n",
       "      <td>-0.342773</td>\n",
       "      <td>-0.181519</td>\n",
       "      <td>0.663574</td>\n",
       "      <td>0.325684</td>\n",
       "      <td>-0.307617</td>\n",
       "      <td>0.065063</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.059937</td>\n",
       "      <td>0.145874</td>\n",
       "      <td>-0.323242</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.000321</td>\n",
       "      <td>0.864258</td>\n",
       "      <td>-0.019943</td>\n",
       "      <td>0.239014</td>\n",
       "      <td>-0.027313</td>\n",
       "      <td>-0.419678</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>-0.076904</td>\n",
       "      <td>0.067383</td>\n",
       "      <td>0.088379</td>\n",
       "      <td>-0.009117</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-0.273682</td>\n",
       "      <td>0.022263</td>\n",
       "      <td>-0.635742</td>\n",
       "      <td>0.011139</td>\n",
       "      <td>0.705566</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.017792</td>\n",
       "      <td>0.143677</td>\n",
       "      <td>-0.030518</td>\n",
       "      <td>0.017197</td>\n",
       "      <td>0.048981</td>\n",
       "      <td>0.790527</td>\n",
       "      <td>-0.272461</td>\n",
       "      <td>0.313477</td>\n",
       "      <td>-0.305176</td>\n",
       "      <td>-0.119568</td>\n",
       "      <td>-0.123840</td>\n",
       "      <td>-0.100281</td>\n",
       "      <td>0.054962</td>\n",
       "      <td>0.099060</td>\n",
       "      <td>-0.151367</td>\n",
       "      <td>0.177490</td>\n",
       "      <td>-0.016266</td>\n",
       "      <td>0.468018</td>\n",
       "      <td>-0.198486</td>\n",
       "      <td>0.291992</td>\n",
       "      <td>-0.109436</td>\n",
       "      <td>0.174683</td>\n",
       "      <td>0.549805</td>\n",
       "      <td>-0.027069</td>\n",
       "      <td>-0.059601</td>\n",
       "      <td>0.283691</td>\n",
       "      <td>0.074585</td>\n",
       "      <td>0.470215</td>\n",
       "      <td>8833.990282</td>\n",
       "      <td>726</td>\n",
       "      <td>6834.5</td>\n",
       "      <td>9742.080645</td>\n",
       "      <td>54727</td>\n",
       "      <td>0.983871</td>\n",
       "      <td>5.954196</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>2</td>\n",
       "      <td>0.178127</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>39</td>\n",
       "      <td>0.487007</td>\n",
       "      <td>0.338710</td>\n",
       "      <td>21</td>\n",
       "      <td>0.477134</td>\n",
       "      <td>0.954734</td>\n",
       "      <td>0.260951</td>\n",
       "      <td>-0.504951</td>\n",
       "      <td>1.799208</td>\n",
       "      <td>-1.132125</td>\n",
       "      <td>-0.098962</td>\n",
       "      <td>-0.753420</td>\n",
       "      <td>-0.125588</td>\n",
       "      <td>1.916600</td>\n",
       "      <td>1.888635</td>\n",
       "      <td>-0.908764</td>\n",
       "      <td>0.013501</td>\n",
       "      <td>1.923854</td>\n",
       "      <td>-1.444424</td>\n",
       "      <td>0.171221</td>\n",
       "      <td>-0.132168</td>\n",
       "      <td>-0.764097</td>\n",
       "      <td>1.372162</td>\n",
       "      <td>0.895375</td>\n",
       "      <td>0.445837</td>\n",
       "      <td>0.345051</td>\n",
       "      <td>0.586453</td>\n",
       "      <td>-0.045482</td>\n",
       "      <td>0.149633</td>\n",
       "      <td>-2.216098</td>\n",
       "      <td>0.381160</td>\n",
       "      <td>1.057738</td>\n",
       "      <td>-1.223602</td>\n",
       "      <td>0.074139</td>\n",
       "      <td>-2.436008</td>\n",
       "      <td>0.284429</td>\n",
       "      <td>0.469494</td>\n",
       "      <td>-0.345599</td>\n",
       "      <td>0.291438</td>\n",
       "      <td>0.069936</td>\n",
       "      <td>-0.273139</td>\n",
       "      <td>0.781932</td>\n",
       "      <td>-1.188197</td>\n",
       "      <td>1.492040</td>\n",
       "      <td>0.572475</td>\n",
       "      <td>-1.044357</td>\n",
       "      <td>0.810212</td>\n",
       "      <td>0.338468</td>\n",
       "      <td>0.057610</td>\n",
       "      <td>-1.062489</td>\n",
       "      <td>1.364387</td>\n",
       "      <td>0.097573</td>\n",
       "      <td>1.048951</td>\n",
       "      <td>-0.062811</td>\n",
       "      <td>-0.715884</td>\n",
       "      <td>-0.612811</td>\n",
       "      <td>0.463152</td>\n",
       "      <td>0.529903</td>\n",
       "      <td>-0.372357</td>\n",
       "      <td>1.056482</td>\n",
       "      <td>0.759485</td>\n",
       "      <td>-0.455366</td>\n",
       "      <td>-0.878562</td>\n",
       "      <td>0.900927</td>\n",
       "      <td>-1.025853</td>\n",
       "      <td>-1.810202</td>\n",
       "      <td>-0.571249</td>\n",
       "      <td>1.250130</td>\n",
       "      <td>-1.023961</td>\n",
       "      <td>0.083121</td>\n",
       "      <td>-0.240752</td>\n",
       "      <td>0.259732</td>\n",
       "      <td>-0.106717</td>\n",
       "      <td>0.399901</td>\n",
       "      <td>-0.527019</td>\n",
       "      <td>0.129820</td>\n",
       "      <td>0.257990</td>\n",
       "      <td>-0.255550</td>\n",
       "      <td>0.147038</td>\n",
       "      <td>-0.550301</td>\n",
       "      <td>-0.158245</td>\n",
       "      <td>0.135884</td>\n",
       "      <td>-0.273290</td>\n",
       "      <td>-0.327118</td>\n",
       "      <td>-0.365238</td>\n",
       "      <td>0.144167</td>\n",
       "      <td>0.532975</td>\n",
       "      <td>-0.003386</td>\n",
       "      <td>0.301236</td>\n",
       "      <td>0.128555</td>\n",
       "      <td>0.120494</td>\n",
       "      <td>0.514178</td>\n",
       "      <td>0.405775</td>\n",
       "      <td>-0.309713</td>\n",
       "      <td>0.224365</td>\n",
       "      <td>-0.382392</td>\n",
       "      <td>0.503778</td>\n",
       "      <td>0.160043</td>\n",
       "      <td>0.591017</td>\n",
       "      <td>0.277168</td>\n",
       "      <td>-0.253905</td>\n",
       "      <td>-0.026216</td>\n",
       "      <td>0.024109</td>\n",
       "      <td>-0.349101</td>\n",
       "      <td>0.553073</td>\n",
       "      <td>-0.098054</td>\n",
       "      <td>-0.282613</td>\n",
       "      <td>0.485168</td>\n",
       "      <td>-0.018452</td>\n",
       "      <td>0.130793</td>\n",
       "      <td>-0.634535</td>\n",
       "      <td>0.030932</td>\n",
       "      <td>0.419520</td>\n",
       "      <td>-0.083059</td>\n",
       "      <td>-0.224819</td>\n",
       "      <td>-0.205735</td>\n",
       "      <td>0.060189</td>\n",
       "      <td>0.479622</td>\n",
       "      <td>0.030506</td>\n",
       "      <td>0.166140</td>\n",
       "      <td>0.192798</td>\n",
       "      <td>-0.353424</td>\n",
       "      <td>0.061473</td>\n",
       "      <td>0.300586</td>\n",
       "      <td>0.387644</td>\n",
       "      <td>-0.138975</td>\n",
       "      <td>0.108618</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>-0.071233</td>\n",
       "      <td>0.015684</td>\n",
       "      <td>-0.055997</td>\n",
       "      <td>0.066533</td>\n",
       "      <td>0.022561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id  deviceid  newsid  pos  app_version  device_vendor  netmodel  osversion  \\\n",
       "0  1         0       0    0            0              0         0          0   \n",
       "1  2         0       0    0            0              0         1          0   \n",
       "2  3         1       1    1            1              1         1          1   \n",
       "3  4         1       2    0            1              1         1          1   \n",
       "4  5         2       3    2            2              2         1          0   \n",
       "\n",
       "   lng  lat  device_version  day  hour  minute  lng_lat  deviceid_count  \\\n",
       "0    0    0               0    9    19      14        0               9   \n",
       "1    1    1               0    9    19      14        1               9   \n",
       "2    2    2               1   10    17      11        2              19   \n",
       "3    2    2               1   10    17      10        2              19   \n",
       "4    3    3               2   10    18      16        3              50   \n",
       "\n",
       "   newsid_count  pos_count  app_version_count  device_vendor_count  \\\n",
       "0            28    3978968           10262467              1917997   \n",
       "1            28    3978968           10262467              1917997   \n",
       "2            87    3124234              21153              4191913   \n",
       "3            17    3978968              21153              4191913   \n",
       "4           248    4804432            2512842               851538   \n",
       "\n",
       "   netmodel_count  osversion_count  device_version_count  lng_count  \\\n",
       "0          608976          4723291                 16862          4   \n",
       "1         2944146          4723291                 16862          4   \n",
       "2         2944146          4335577                 51022    2231783   \n",
       "3         2944146          4335577                 51022    2231783   \n",
       "4         2944146          4723291                 86569          7   \n",
       "\n",
       "   lat_count  lng_lat_count  deviceid_prev_day_click_count  \\\n",
       "0          4              4                            0.0   \n",
       "1          4              4                            0.0   \n",
       "2    2231783        2231783                            0.0   \n",
       "3    2231783        2231783                            0.0   \n",
       "4          7              7                            0.0   \n",
       "\n",
       "   deviceid_prev_day_count  deviceid_prev_day_ctr  \\\n",
       "0                      0.0                    0.0   \n",
       "1                      0.0                    0.0   \n",
       "2                      0.0                    0.0   \n",
       "3                      0.0                    0.0   \n",
       "4                     11.0                    0.0   \n",
       "\n",
       "   pos_deviceid_prev_day_click_count  pos_deviceid_prev_day_count  \\\n",
       "0                                0.0                          0.0   \n",
       "1                                0.0                          0.0   \n",
       "2                                0.0                          0.0   \n",
       "3                                0.0                          0.0   \n",
       "4                                0.0                          5.0   \n",
       "\n",
       "   pos_deviceid_prev_day_ctr  newsid_prev_day_click_count  \\\n",
       "0                        0.0                          1.0   \n",
       "1                        0.0                          1.0   \n",
       "2                        0.0                          3.0   \n",
       "3                        0.0                          0.0   \n",
       "4                        0.0                         35.0   \n",
       "\n",
       "   newsid_prev_day_count  newsid_prev_day_ctr  \\\n",
       "0                    4.0             0.005379   \n",
       "1                    4.0             0.005379   \n",
       "2                   10.0             0.015625   \n",
       "3                    1.0             0.000000   \n",
       "4                   59.0             0.145264   \n",
       "\n",
       "   newsid_pos_prev_day_click_count  newsid_pos_prev_day_count  \\\n",
       "0                              0.0                        1.0   \n",
       "1                              0.0                        1.0   \n",
       "2                              0.0                        1.0   \n",
       "3                              0.0                        0.0   \n",
       "4                             32.0                       56.0   \n",
       "\n",
       "   newsid_pos_prev_day_ctr  deviceid_prev1_exposure_ts_gap  \\\n",
       "0                 0.000000                            30.0   \n",
       "1                 0.000000                          1098.0   \n",
       "2                 0.000000                         29098.0   \n",
       "3                 0.000000                            54.0   \n",
       "4                 0.270996                          2382.0   \n",
       "\n",
       "   deviceid_next1_exposure_ts_gap  deviceid_prev2_exposure_ts_gap  \\\n",
       "0                            36.0                            53.0   \n",
       "1                             1.0                          1134.0   \n",
       "2                           581.0                         31575.0   \n",
       "3                          2477.0                             NaN   \n",
       "4                             1.0                      90608584.0   \n",
       "\n",
       "   deviceid_next2_exposure_ts_gap  deviceid_prev3_exposure_ts_gap  \\\n",
       "0                          1134.0                             NaN   \n",
       "1                          1860.0                          1164.0   \n",
       "2                           703.0                         31629.0   \n",
       "3                         31575.0                             NaN   \n",
       "4                            81.0                      90609472.0   \n",
       "\n",
       "   deviceid_next3_exposure_ts_gap  deviceid_prev5_exposure_ts_gap  \\\n",
       "0                          1135.0                             NaN   \n",
       "1                          2206.0                             NaN   \n",
       "2                          1046.0                             NaN   \n",
       "3                         32156.0                             NaN   \n",
       "4                      40938752.0                      90609544.0   \n",
       "\n",
       "   deviceid_next5_exposure_ts_gap  deviceid_prev10_exposure_ts_gap  \\\n",
       "0                          3340.0                              NaN   \n",
       "1                             NaN                              NaN   \n",
       "2                         18560.0                              NaN   \n",
       "3                         32621.0                              NaN   \n",
       "4                      40939036.0                       90612520.0   \n",
       "\n",
       "   deviceid_next10_exposure_ts_gap  newsid_prev1_exposure_ts_gap  \\\n",
       "0                              NaN                    38706112.0   \n",
       "1                              NaN                        1134.0   \n",
       "2                          78409.0                      499575.0   \n",
       "3                          53840.0                    18044740.0   \n",
       "4                       42205436.0                     1350820.0   \n",
       "\n",
       "   newsid_next1_exposure_ts_gap  newsid_prev2_exposure_ts_gap  \\\n",
       "0                        1134.0                    38966296.0   \n",
       "1                      217048.0                    38707248.0   \n",
       "2                      951027.0                      538234.0   \n",
       "3                    14122617.0                    21919968.0   \n",
       "4                     2240470.0                     2099693.0   \n",
       "\n",
       "   newsid_next2_exposure_ts_gap  newsid_prev3_exposure_ts_gap  \\\n",
       "0                      218182.0                    45601856.0   \n",
       "1                     1844412.0                    38967432.0   \n",
       "2                     2108357.0                      934449.0   \n",
       "3                    16511740.0                    31771756.0   \n",
       "4                     2874429.0                     3674688.0   \n",
       "\n",
       "   newsid_next3_exposure_ts_gap  newsid_prev5_exposure_ts_gap  \\\n",
       "0                     1845546.0                   104100512.0   \n",
       "1                    19481908.0                    97951792.0   \n",
       "2                     2734495.0                     3920295.0   \n",
       "3                    18323212.0                    40624088.0   \n",
       "4                     3385208.0                     6019809.0   \n",
       "\n",
       "   newsid_next5_exposure_ts_gap  newsid_prev10_exposure_ts_gap  \\\n",
       "0                    42743124.0                            NaN   \n",
       "1                    43074800.0                            NaN   \n",
       "2                     3599072.0                      8957758.0   \n",
       "3                    19697480.0                            NaN   \n",
       "4                     4483977.0                     13454169.0   \n",
       "\n",
       "   newsid_next10_exposure_ts_gap  lng_lat_prev1_exposure_ts_gap  \\\n",
       "0                     74353472.0                           30.0   \n",
       "1                     91311352.0                            NaN   \n",
       "2                     11642736.0                           99.0   \n",
       "3                            NaN                           54.0   \n",
       "4                      6529699.0                            NaN   \n",
       "\n",
       "   lng_lat_next1_exposure_ts_gap  lng_lat_prev2_exposure_ts_gap  \\\n",
       "0                           36.0                           53.0   \n",
       "1                            1.0                            NaN   \n",
       "2                          229.0                          117.0   \n",
       "3                           10.0                          454.0   \n",
       "4                            1.0                            NaN   \n",
       "\n",
       "   lng_lat_next2_exposure_ts_gap  lng_lat_prev3_exposure_ts_gap  \\\n",
       "0                            NaN                            NaN   \n",
       "1                         1860.0                            NaN   \n",
       "2                          235.0                          125.0   \n",
       "3                          735.0                          650.0   \n",
       "4                           81.0                            NaN   \n",
       "\n",
       "   lng_lat_next3_exposure_ts_gap  lng_lat_prev5_exposure_ts_gap  \\\n",
       "0                            NaN                            NaN   \n",
       "1                         2206.0                            NaN   \n",
       "2                          581.0                         1142.0   \n",
       "3                         1517.0                         1072.0   \n",
       "4                     40938752.0                            NaN   \n",
       "\n",
       "   lng_lat_next5_exposure_ts_gap  lng_lat_prev10_exposure_ts_gap  \\\n",
       "0                            NaN                             NaN   \n",
       "1                            NaN                             NaN   \n",
       "2                          771.0                          2034.0   \n",
       "3                         2430.0                          2290.0   \n",
       "4                     40939036.0                             NaN   \n",
       "\n",
       "   lng_lat_next10_exposure_ts_gap  pos_deviceid_prev1_exposure_ts_gap  \\\n",
       "0                             NaN                                 NaN   \n",
       "1                             NaN                              1134.0   \n",
       "2                          2378.0                                 NaN   \n",
       "3                          4467.0                                 NaN   \n",
       "4                             NaN                          90608584.0   \n",
       "\n",
       "   pos_deviceid_next1_exposure_ts_gap  pos_deviceid_prev2_exposure_ts_gap  \\\n",
       "0                              1134.0                                 NaN   \n",
       "1                                 NaN                                 NaN   \n",
       "2                              1408.0                                 NaN   \n",
       "3                             32278.0                                 NaN   \n",
       "4                          40938752.0                          90609544.0   \n",
       "\n",
       "   pos_deviceid_next2_exposure_ts_gap  pos_deviceid_prev3_exposure_ts_gap  \\\n",
       "0                                 NaN                                 NaN   \n",
       "1                                 NaN                                 NaN   \n",
       "2                             18564.0                                 NaN   \n",
       "3                             50146.0                                 NaN   \n",
       "4                          40939040.0                          90612472.0   \n",
       "\n",
       "   pos_deviceid_next3_exposure_ts_gap  pos_deviceid_prev5_exposure_ts_gap  \\\n",
       "0                                 NaN                                 NaN   \n",
       "1                                 NaN                                 NaN   \n",
       "2                             37186.0                                 NaN   \n",
       "3                             53840.0                                 NaN   \n",
       "4                          42205420.0                          90612576.0   \n",
       "\n",
       "   pos_deviceid_next5_exposure_ts_gap  pos_deviceid_prev10_exposure_ts_gap  \\\n",
       "0                                 NaN                                  NaN   \n",
       "1                                 NaN                                  NaN   \n",
       "2                                 NaN                                  NaN   \n",
       "3                            136966.0                                  NaN   \n",
       "4                          42206236.0                                  NaN   \n",
       "\n",
       "   pos_deviceid_next10_exposure_ts_gap  pos_newsid_prev1_exposure_ts_gap  \\\n",
       "0                                  NaN                        97950664.0   \n",
       "1                                  NaN                            1134.0   \n",
       "2                                  NaN                         8957758.0   \n",
       "3                                  NaN                        21919968.0   \n",
       "4                           42333392.0                         1350820.0   \n",
       "\n",
       "   pos_newsid_next1_exposure_ts_gap  pos_newsid_prev2_exposure_ts_gap  \\\n",
       "0                            1134.0                               NaN   \n",
       "1                          217048.0                        97951792.0   \n",
       "2                         3599072.0                        19305764.0   \n",
       "3                        16511740.0                        31771756.0   \n",
       "4                         2240470.0                         2099693.0   \n",
       "\n",
       "   pos_newsid_next2_exposure_ts_gap  pos_newsid_prev3_exposure_ts_gap  \\\n",
       "0                          218182.0                               NaN   \n",
       "1                        43074800.0                               NaN   \n",
       "2                        11642736.0                        37800676.0   \n",
       "3                               NaN                        40624088.0   \n",
       "4                         2874429.0                         3674688.0   \n",
       "\n",
       "   pos_newsid_next3_exposure_ts_gap  pos_newsid_prev5_exposure_ts_gap  \\\n",
       "0                        43075932.0                               NaN   \n",
       "1                        58265816.0                               NaN   \n",
       "2                        16492735.0                       168928400.0   \n",
       "3                               NaN                               NaN   \n",
       "4                         3385208.0                         6019809.0   \n",
       "\n",
       "   pos_newsid_next5_exposure_ts_gap  pos_newsid_prev10_exposure_ts_gap  \\\n",
       "0                        59235176.0                                NaN   \n",
       "1                       158717248.0                                NaN   \n",
       "2                        66187736.0                                NaN   \n",
       "3                               NaN                                NaN   \n",
       "4                         4483977.0                         14159585.0   \n",
       "\n",
       "   pos_newsid_next10_exposure_ts_gap  pos_lng_lat_prev1_exposure_ts_gap  \\\n",
       "0                                NaN                                NaN   \n",
       "1                                NaN                                NaN   \n",
       "2                                NaN                               99.0   \n",
       "3                                NaN                              454.0   \n",
       "4                          6529699.0                                NaN   \n",
       "\n",
       "   pos_lng_lat_next1_exposure_ts_gap  pos_lng_lat_prev2_exposure_ts_gap  \\\n",
       "0                                NaN                                NaN   \n",
       "1                                NaN                                NaN   \n",
       "2                             1408.0                             1427.0   \n",
       "3                              735.0                             1958.0   \n",
       "4                         40938752.0                                NaN   \n",
       "\n",
       "   pos_lng_lat_next2_exposure_ts_gap  pos_lng_lat_prev3_exposure_ts_gap  \\\n",
       "0                                NaN                                NaN   \n",
       "1                                NaN                                NaN   \n",
       "2                             4293.0                             4251.0   \n",
       "3                             3656.0                             2700.0   \n",
       "4                                NaN                                NaN   \n",
       "\n",
       "   pos_lng_lat_next3_exposure_ts_gap  pos_lng_lat_prev5_exposure_ts_gap  \\\n",
       "0                                NaN                                NaN   \n",
       "1                                NaN                                NaN   \n",
       "2                             5707.0                             8676.0   \n",
       "3                             4448.0                             3510.0   \n",
       "4                                NaN                                NaN   \n",
       "\n",
       "   pos_lng_lat_next5_exposure_ts_gap  pos_lng_lat_prev10_exposure_ts_gap  \\\n",
       "0                                NaN                                 NaN   \n",
       "1                                NaN                                 NaN   \n",
       "2                             7495.0                             10598.0   \n",
       "3                             6097.0                              5029.0   \n",
       "4                                NaN                                 NaN   \n",
       "\n",
       "   pos_lng_lat_next10_exposure_ts_gap  \\\n",
       "0                                 NaN   \n",
       "1                                 NaN   \n",
       "2                             13198.0   \n",
       "3                              8007.0   \n",
       "4                                 NaN   \n",
       "\n",
       "   pos_deviceid_lng_lat_prev1_exposure_ts_gap  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2                                         NaN   \n",
       "3                                         NaN   \n",
       "4                                         NaN   \n",
       "\n",
       "   pos_deviceid_lng_lat_next1_exposure_ts_gap  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2                                      1408.0   \n",
       "3                                     32278.0   \n",
       "4                                  40938752.0   \n",
       "\n",
       "   pos_deviceid_lng_lat_prev2_exposure_ts_gap  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2                                         NaN   \n",
       "3                                         NaN   \n",
       "4                                         NaN   \n",
       "\n",
       "   pos_deviceid_lng_lat_next2_exposure_ts_gap  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2                                     37186.0   \n",
       "3                                     53840.0   \n",
       "4                                         NaN   \n",
       "\n",
       "   pos_deviceid_lng_lat_prev3_exposure_ts_gap  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2                                         NaN   \n",
       "3                                         NaN   \n",
       "4                                         NaN   \n",
       "\n",
       "   pos_deviceid_lng_lat_next3_exposure_ts_gap  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2                                         NaN   \n",
       "3                                    109984.0   \n",
       "4                                         NaN   \n",
       "\n",
       "   pos_deviceid_lng_lat_prev5_exposure_ts_gap  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2                                         NaN   \n",
       "3                                         NaN   \n",
       "4                                         NaN   \n",
       "\n",
       "   pos_deviceid_lng_lat_next5_exposure_ts_gap  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2                                         NaN   \n",
       "3                                         NaN   \n",
       "4                                         NaN   \n",
       "\n",
       "   pos_deviceid_lng_lat_prev10_exposure_ts_gap  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                          NaN   \n",
       "\n",
       "   pos_deviceid_lng_lat_next10_exposure_ts_gap  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                          NaN   \n",
       "\n",
       "   netmodel_deviceid_prev1_exposure_ts_gap  \\\n",
       "0                                     30.0   \n",
       "1                                      NaN   \n",
       "2                                  31575.0   \n",
       "3                                     54.0   \n",
       "4                               90609472.0   \n",
       "\n",
       "   netmodel_deviceid_next1_exposure_ts_gap  \\\n",
       "0                                     36.0   \n",
       "1                                      1.0   \n",
       "2                                    581.0   \n",
       "3                                  31575.0   \n",
       "4                                      1.0   \n",
       "\n",
       "   netmodel_deviceid_prev2_exposure_ts_gap  \\\n",
       "0                                      NaN   \n",
       "1                                      NaN   \n",
       "2                                  31629.0   \n",
       "3                                      NaN   \n",
       "4                               90609536.0   \n",
       "\n",
       "   netmodel_deviceid_next2_exposure_ts_gap  \\\n",
       "0                                      NaN   \n",
       "1                                   2206.0   \n",
       "2                                    703.0   \n",
       "3                                  32156.0   \n",
       "4                                     81.0   \n",
       "\n",
       "   netmodel_deviceid_prev3_exposure_ts_gap  \\\n",
       "0                                      NaN   \n",
       "1                                      NaN   \n",
       "2                                      NaN   \n",
       "3                                      NaN   \n",
       "4                               90609544.0   \n",
       "\n",
       "   netmodel_deviceid_next3_exposure_ts_gap  \\\n",
       "0                                      NaN   \n",
       "1                                      NaN   \n",
       "2                                   1408.0   \n",
       "3                                  32278.0   \n",
       "4                               40939036.0   \n",
       "\n",
       "   netmodel_deviceid_prev5_exposure_ts_gap  \\\n",
       "0                                      NaN   \n",
       "1                                      NaN   \n",
       "2                                      NaN   \n",
       "3                                      NaN   \n",
       "4                               90612496.0   \n",
       "\n",
       "   netmodel_deviceid_next5_exposure_ts_gap  \\\n",
       "0                                      NaN   \n",
       "1                                      NaN   \n",
       "2                                  18564.0   \n",
       "3                                  50135.0   \n",
       "4                               42205464.0   \n",
       "\n",
       "   netmodel_deviceid_prev10_exposure_ts_gap  \\\n",
       "0                                       NaN   \n",
       "1                                       NaN   \n",
       "2                                       NaN   \n",
       "3                                       NaN   \n",
       "4                                       NaN   \n",
       "\n",
       "   netmodel_deviceid_next10_exposure_ts_gap  \\\n",
       "0                                       NaN   \n",
       "1                                       NaN   \n",
       "2                                       NaN   \n",
       "3                                  137550.0   \n",
       "4                                42217096.0   \n",
       "\n",
       "   pos_netmodel_deviceid_prev1_exposure_ts_gap  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                   90609544.0   \n",
       "\n",
       "   pos_netmodel_deviceid_next1_exposure_ts_gap  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                       1408.0   \n",
       "3                                      32278.0   \n",
       "4                                   42205464.0   \n",
       "\n",
       "   pos_netmodel_deviceid_prev2_exposure_ts_gap  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                   90612520.0   \n",
       "\n",
       "   pos_netmodel_deviceid_next2_exposure_ts_gap  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                      18564.0   \n",
       "3                                      50146.0   \n",
       "4                                   42206236.0   \n",
       "\n",
       "   pos_netmodel_deviceid_prev3_exposure_ts_gap  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                  214526096.0   \n",
       "\n",
       "   pos_netmodel_deviceid_next3_exposure_ts_gap  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                     105975.0   \n",
       "3                                     136966.0   \n",
       "4                                   42217176.0   \n",
       "\n",
       "   pos_netmodel_deviceid_prev5_exposure_ts_gap  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                          NaN   \n",
       "\n",
       "   pos_netmodel_deviceid_next5_exposure_ts_gap  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                   42320676.0   \n",
       "\n",
       "   pos_netmodel_deviceid_prev10_exposure_ts_gap  \\\n",
       "0                                           NaN   \n",
       "1                                           NaN   \n",
       "2                                           NaN   \n",
       "3                                           NaN   \n",
       "4                                           NaN   \n",
       "\n",
       "   pos_netmodel_deviceid_next10_exposure_ts_gap  \\\n",
       "0                                           NaN   \n",
       "1                                           NaN   \n",
       "2                                           NaN   \n",
       "3                                           NaN   \n",
       "4                                           NaN   \n",
       "\n",
       "   netmodel_lng_lat_prev1_exposure_ts_gap  \\\n",
       "0                                    30.0   \n",
       "1                                     NaN   \n",
       "2                                    99.0   \n",
       "3                                    54.0   \n",
       "4                                     NaN   \n",
       "\n",
       "   netmodel_lng_lat_next1_exposure_ts_gap  \\\n",
       "0                                    36.0   \n",
       "1                                     1.0   \n",
       "2                                   581.0   \n",
       "3                                  6252.0   \n",
       "4                                     1.0   \n",
       "\n",
       "   netmodel_lng_lat_prev2_exposure_ts_gap  \\\n",
       "0                                     NaN   \n",
       "1                                     NaN   \n",
       "2                                   117.0   \n",
       "3                                  4000.0   \n",
       "4                                     NaN   \n",
       "\n",
       "   netmodel_lng_lat_next2_exposure_ts_gap  \\\n",
       "0                                     NaN   \n",
       "1                                  2206.0   \n",
       "2                                   703.0   \n",
       "3                                  6267.0   \n",
       "4                                    81.0   \n",
       "\n",
       "   netmodel_lng_lat_prev3_exposure_ts_gap  \\\n",
       "0                                     NaN   \n",
       "1                                     NaN   \n",
       "2                                   125.0   \n",
       "3                                  4017.0   \n",
       "4                                     NaN   \n",
       "\n",
       "   netmodel_lng_lat_next3_exposure_ts_gap  \\\n",
       "0                                     NaN   \n",
       "1                                     NaN   \n",
       "2                                  1408.0   \n",
       "3                                  6970.0   \n",
       "4                              40939036.0   \n",
       "\n",
       "   netmodel_lng_lat_prev5_exposure_ts_gap  \\\n",
       "0                                     NaN   \n",
       "1                                     NaN   \n",
       "2                                  1431.0   \n",
       "3                                  7824.0   \n",
       "4                                     NaN   \n",
       "\n",
       "   netmodel_lng_lat_next5_exposure_ts_gap  \\\n",
       "0                                     NaN   \n",
       "1                                     NaN   \n",
       "2                                  3372.0   \n",
       "3                                  7693.0   \n",
       "4                                     NaN   \n",
       "\n",
       "   netmodel_lng_lat_prev10_exposure_ts_gap  \\\n",
       "0                                      NaN   \n",
       "1                                      NaN   \n",
       "2                                   6140.0   \n",
       "3                                  12653.0   \n",
       "4                                      NaN   \n",
       "\n",
       "   netmodel_lng_lat_next10_exposure_ts_gap  \\\n",
       "0                                      NaN   \n",
       "1                                      NaN   \n",
       "2                                   7915.0   \n",
       "3                                   7947.0   \n",
       "4                                      NaN   \n",
       "\n",
       "   deviceid_lng_lat_prev1_exposure_ts_gap  \\\n",
       "0                                    30.0   \n",
       "1                                     NaN   \n",
       "2                                 29098.0   \n",
       "3                                    54.0   \n",
       "4                                     NaN   \n",
       "\n",
       "   deviceid_lng_lat_next1_exposure_ts_gap  \\\n",
       "0                                    36.0   \n",
       "1                                     1.0   \n",
       "2                                   581.0   \n",
       "3                                  2477.0   \n",
       "4                                     1.0   \n",
       "\n",
       "   deviceid_lng_lat_prev2_exposure_ts_gap  \\\n",
       "0                                    53.0   \n",
       "1                                     NaN   \n",
       "2                                 31575.0   \n",
       "3                                     NaN   \n",
       "4                                     NaN   \n",
       "\n",
       "   deviceid_lng_lat_next2_exposure_ts_gap  \\\n",
       "0                                     NaN   \n",
       "1                                  1860.0   \n",
       "2                                   703.0   \n",
       "3                                 31575.0   \n",
       "4                                    81.0   \n",
       "\n",
       "   deviceid_lng_lat_prev3_exposure_ts_gap  \\\n",
       "0                                     NaN   \n",
       "1                                     NaN   \n",
       "2                                 31629.0   \n",
       "3                                     NaN   \n",
       "4                                     NaN   \n",
       "\n",
       "   deviceid_lng_lat_next3_exposure_ts_gap  \\\n",
       "0                                     NaN   \n",
       "1                                  2206.0   \n",
       "2                                  1046.0   \n",
       "3                                 32156.0   \n",
       "4                              40938752.0   \n",
       "\n",
       "   deviceid_lng_lat_prev5_exposure_ts_gap  \\\n",
       "0                                     NaN   \n",
       "1                                     NaN   \n",
       "2                                     NaN   \n",
       "3                                     NaN   \n",
       "4                                     NaN   \n",
       "\n",
       "   deviceid_lng_lat_next5_exposure_ts_gap  \\\n",
       "0                                     NaN   \n",
       "1                                     NaN   \n",
       "2                                 22265.0   \n",
       "3                                 32621.0   \n",
       "4                              40939036.0   \n",
       "\n",
       "   deviceid_lng_lat_prev10_exposure_ts_gap  \\\n",
       "0                                      NaN   \n",
       "1                                      NaN   \n",
       "2                                      NaN   \n",
       "3                                      NaN   \n",
       "4                                      NaN   \n",
       "\n",
       "   deviceid_lng_lat_next10_exposure_ts_gap  \\\n",
       "0                                      NaN   \n",
       "1                                      NaN   \n",
       "2                                      NaN   \n",
       "3                                      NaN   \n",
       "4                                      NaN   \n",
       "\n",
       "   netmodel_deviceid_lng_lat_prev1_exposure_ts_gap  \\\n",
       "0                                             30.0   \n",
       "1                                              NaN   \n",
       "2                                          31575.0   \n",
       "3                                             54.0   \n",
       "4                                              NaN   \n",
       "\n",
       "   netmodel_deviceid_lng_lat_next1_exposure_ts_gap  \\\n",
       "0                                             36.0   \n",
       "1                                              1.0   \n",
       "2                                            581.0   \n",
       "3                                          31575.0   \n",
       "4                                              1.0   \n",
       "\n",
       "   netmodel_deviceid_lng_lat_prev2_exposure_ts_gap  \\\n",
       "0                                              NaN   \n",
       "1                                              NaN   \n",
       "2                                          31629.0   \n",
       "3                                              NaN   \n",
       "4                                              NaN   \n",
       "\n",
       "   netmodel_deviceid_lng_lat_next2_exposure_ts_gap  \\\n",
       "0                                              NaN   \n",
       "1                                           2206.0   \n",
       "2                                            703.0   \n",
       "3                                          32156.0   \n",
       "4                                             81.0   \n",
       "\n",
       "   netmodel_deviceid_lng_lat_prev3_exposure_ts_gap  \\\n",
       "0                                              NaN   \n",
       "1                                              NaN   \n",
       "2                                              NaN   \n",
       "3                                              NaN   \n",
       "4                                              NaN   \n",
       "\n",
       "   netmodel_deviceid_lng_lat_next3_exposure_ts_gap  \\\n",
       "0                                              NaN   \n",
       "1                                              NaN   \n",
       "2                                           1408.0   \n",
       "3                                          32278.0   \n",
       "4                                       40939036.0   \n",
       "\n",
       "   netmodel_deviceid_lng_lat_prev5_exposure_ts_gap  \\\n",
       "0                                              NaN   \n",
       "1                                              NaN   \n",
       "2                                              NaN   \n",
       "3                                              NaN   \n",
       "4                                              NaN   \n",
       "\n",
       "   netmodel_deviceid_lng_lat_next5_exposure_ts_gap  \\\n",
       "0                                              NaN   \n",
       "1                                              NaN   \n",
       "2                                              NaN   \n",
       "3                                              NaN   \n",
       "4                                              NaN   \n",
       "\n",
       "   netmodel_deviceid_lng_lat_prev10_exposure_ts_gap  \\\n",
       "0                                               NaN   \n",
       "1                                               NaN   \n",
       "2                                               NaN   \n",
       "3                                               NaN   \n",
       "4                                               NaN   \n",
       "\n",
       "   netmodel_deviceid_lng_lat_next10_exposure_ts_gap  \\\n",
       "0                                               NaN   \n",
       "1                                               NaN   \n",
       "2                                               NaN   \n",
       "3                                               NaN   \n",
       "4                                               NaN   \n",
       "\n",
       "   pos_netmodel_lng_lat_prev1_exposure_ts_gap  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2                                        99.0   \n",
       "3                                      4000.0   \n",
       "4                                         NaN   \n",
       "\n",
       "   pos_netmodel_lng_lat_next1_exposure_ts_gap  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2                                      1408.0   \n",
       "3                                      6267.0   \n",
       "4                                         NaN   \n",
       "\n",
       "   pos_netmodel_lng_lat_prev2_exposure_ts_gap  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2                                      1427.0   \n",
       "3                                      7795.0   \n",
       "4                                         NaN   \n",
       "\n",
       "   pos_netmodel_lng_lat_next2_exposure_ts_gap  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2                                      7495.0   \n",
       "3                                      7716.0   \n",
       "4                                         NaN   \n",
       "\n",
       "   pos_netmodel_lng_lat_prev3_exposure_ts_gap  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2                                      6144.0   \n",
       "3                                      8739.0   \n",
       "4                                         NaN   \n",
       "\n",
       "   pos_netmodel_lng_lat_next3_exposure_ts_gap  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2                                      7949.0   \n",
       "3                                      7847.0   \n",
       "4                                         NaN   \n",
       "\n",
       "   pos_netmodel_lng_lat_prev5_exposure_ts_gap  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2                                      9303.0   \n",
       "3                                     17841.0   \n",
       "4                                         NaN   \n",
       "\n",
       "   pos_netmodel_lng_lat_next5_exposure_ts_gap  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2                                     13819.0   \n",
       "3                                     10963.0   \n",
       "4                                         NaN   \n",
       "\n",
       "   pos_netmodel_lng_lat_prev10_exposure_ts_gap  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                      19652.0   \n",
       "3                                      35027.0   \n",
       "4                                          NaN   \n",
       "\n",
       "   pos_netmodel_lng_lat_next10_exposure_ts_gap  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                      20776.0   \n",
       "3                                      15064.0   \n",
       "4                                          NaN   \n",
       "\n",
       "   pos_netmodel_deviceid_lng_lat_prev1_exposure_ts_gap  \\\n",
       "0                                                NaN     \n",
       "1                                                NaN     \n",
       "2                                                NaN     \n",
       "3                                                NaN     \n",
       "4                                                NaN     \n",
       "\n",
       "   pos_netmodel_deviceid_lng_lat_next1_exposure_ts_gap  \\\n",
       "0                                                NaN     \n",
       "1                                                NaN     \n",
       "2                                             1408.0     \n",
       "3                                            32278.0     \n",
       "4                                                NaN     \n",
       "\n",
       "   pos_netmodel_deviceid_lng_lat_prev2_exposure_ts_gap  \\\n",
       "0                                                NaN     \n",
       "1                                                NaN     \n",
       "2                                                NaN     \n",
       "3                                                NaN     \n",
       "4                                                NaN     \n",
       "\n",
       "   pos_netmodel_deviceid_lng_lat_next2_exposure_ts_gap  \\\n",
       "0                                                NaN     \n",
       "1                                                NaN     \n",
       "2                                                NaN     \n",
       "3                                                NaN     \n",
       "4                                                NaN     \n",
       "\n",
       "   pos_netmodel_deviceid_lng_lat_prev3_exposure_ts_gap  \\\n",
       "0                                                NaN     \n",
       "1                                                NaN     \n",
       "2                                                NaN     \n",
       "3                                                NaN     \n",
       "4                                                NaN     \n",
       "\n",
       "   pos_netmodel_deviceid_lng_lat_next3_exposure_ts_gap  \\\n",
       "0                                                NaN     \n",
       "1                                                NaN     \n",
       "2                                                NaN     \n",
       "3                                                NaN     \n",
       "4                                                NaN     \n",
       "\n",
       "   pos_netmodel_deviceid_lng_lat_prev5_exposure_ts_gap  \\\n",
       "0                                                NaN     \n",
       "1                                                NaN     \n",
       "2                                                NaN     \n",
       "3                                                NaN     \n",
       "4                                                NaN     \n",
       "\n",
       "   pos_netmodel_deviceid_lng_lat_next5_exposure_ts_gap  \\\n",
       "0                                                NaN     \n",
       "1                                                NaN     \n",
       "2                                                NaN     \n",
       "3                                                NaN     \n",
       "4                                                NaN     \n",
       "\n",
       "   pos_netmodel_deviceid_lng_lat_prev10_exposure_ts_gap  \\\n",
       "0                                                NaN      \n",
       "1                                                NaN      \n",
       "2                                                NaN      \n",
       "3                                                NaN      \n",
       "4                                                NaN      \n",
       "\n",
       "   pos_netmodel_deviceid_lng_lat_next10_exposure_ts_gap  \\\n",
       "0                                                NaN      \n",
       "1                                                NaN      \n",
       "2                                                NaN      \n",
       "3                                                NaN      \n",
       "4                                                NaN      \n",
       "\n",
       "   ProNE_Emb_deviceidapplist_0  ProNE_Emb_deviceidapplist_1  \\\n",
       "0                    -0.502930                     0.014778   \n",
       "1                    -0.502930                     0.014778   \n",
       "2                     0.078186                     0.263428   \n",
       "3                     0.078186                     0.263428   \n",
       "4                     0.017181                     0.180420   \n",
       "\n",
       "   ProNE_Emb_deviceidapplist_2  ProNE_Emb_deviceidapplist_3  \\\n",
       "0                     0.129883                     0.162964   \n",
       "1                     0.129883                     0.162964   \n",
       "2                     0.289551                     0.046448   \n",
       "3                     0.289551                     0.046448   \n",
       "4                    -0.172485                     0.398193   \n",
       "\n",
       "   ProNE_Emb_deviceidapplist_4  ProNE_Emb_deviceidapplist_5  \\\n",
       "0                     0.152954                    -0.049377   \n",
       "1                     0.152954                    -0.049377   \n",
       "2                     0.199829                    -0.338379   \n",
       "3                     0.199829                    -0.338379   \n",
       "4                     0.126709                    -0.002977   \n",
       "\n",
       "   ProNE_Emb_deviceidapplist_6  ProNE_Emb_deviceidapplist_7  \\\n",
       "0                     0.108521                     0.099731   \n",
       "1                     0.108521                     0.099731   \n",
       "2                    -0.049225                    -0.733887   \n",
       "3                    -0.049225                    -0.733887   \n",
       "4                    -0.187988                    -0.645996   \n",
       "\n",
       "   ProNE_Emb_deviceidapplist_8  ProNE_Emb_deviceidapplist_9  \\\n",
       "0                     0.397217                    -0.130859   \n",
       "1                     0.397217                    -0.130859   \n",
       "2                    -0.030838                     0.093689   \n",
       "3                    -0.030838                     0.093689   \n",
       "4                     0.311035                    -0.372070   \n",
       "\n",
       "   ProNE_Emb_deviceidapplist_10  ProNE_Emb_deviceidapplist_11  \\\n",
       "0                     -0.044067                     -0.691895   \n",
       "1                     -0.044067                     -0.691895   \n",
       "2                     -0.267334                     -0.248535   \n",
       "3                     -0.267334                     -0.248535   \n",
       "4                      0.240112                      0.133057   \n",
       "\n",
       "   ProNE_Emb_deviceidall_tag_word_0  ProNE_Emb_deviceidall_tag_word_1  \\\n",
       "0                         -0.000022                         -0.344482   \n",
       "1                         -0.000022                         -0.344482   \n",
       "2                         -0.245361                          0.000771   \n",
       "3                         -0.245361                          0.000771   \n",
       "4                         -0.197266                          0.004799   \n",
       "\n",
       "   ProNE_Emb_deviceidall_tag_word_2  ProNE_Emb_deviceidall_tag_word_3  \\\n",
       "0                          0.001275                          0.000440   \n",
       "1                          0.001275                          0.000440   \n",
       "2                          0.059174                          0.233154   \n",
       "3                          0.059174                          0.233154   \n",
       "4                          0.413574                          0.018066   \n",
       "\n",
       "   ProNE_Emb_deviceidall_tag_word_4  ProNE_Emb_deviceidall_tag_word_5  \\\n",
       "0                          0.000890                          0.000070   \n",
       "1                          0.000890                          0.000070   \n",
       "2                          0.586426                          0.047699   \n",
       "3                          0.586426                          0.047699   \n",
       "4                          0.611328                          0.357422   \n",
       "\n",
       "   ProNE_Emb_deviceidall_tag_word_6  ProNE_Emb_deviceidall_tag_word_7  \\\n",
       "0                          0.001015                         -0.000605   \n",
       "1                          0.001015                         -0.000605   \n",
       "2                          0.249756                          0.051117   \n",
       "3                          0.249756                          0.051117   \n",
       "4                         -0.290771                          0.357422   \n",
       "\n",
       "   ProNE_Emb_deviceidall_tag_word_8  ProNE_Emb_deviceidall_tag_word_9  \\\n",
       "0                         -0.002760                         -0.003790   \n",
       "1                         -0.002760                         -0.003790   \n",
       "2                         -0.220581                          0.637695   \n",
       "3                         -0.220581                          0.637695   \n",
       "4                         -0.220947                         -0.071472   \n",
       "\n",
       "   ProNE_Emb_deviceidall_tag_word_10  ProNE_Emb_deviceidall_tag_word_11  \\\n",
       "0                          -0.002687                          -0.938965   \n",
       "1                          -0.002687                          -0.938965   \n",
       "2                           0.123352                          -0.007858   \n",
       "3                           0.123352                          -0.007858   \n",
       "4                           0.133667                          -0.062103   \n",
       "\n",
       "   ProNE_Emb_deviceidnewsid_0  ProNE_Emb_deviceidnewsid_1  \\\n",
       "0                   -0.493896                    0.178345   \n",
       "1                   -0.493896                    0.178345   \n",
       "2                   -0.501465                    0.174561   \n",
       "3                   -0.501465                    0.174561   \n",
       "4                   -0.388184                    0.105164   \n",
       "\n",
       "   ProNE_Emb_deviceidnewsid_2  ProNE_Emb_deviceidnewsid_3  \\\n",
       "0                   -0.666504                    0.039032   \n",
       "1                   -0.666504                    0.039032   \n",
       "2                   -0.657715                    0.022232   \n",
       "3                   -0.657715                    0.022232   \n",
       "4                   -0.602051                    0.061584   \n",
       "\n",
       "   ProNE_Emb_deviceidnewsid_4  ProNE_Emb_deviceidnewsid_5  \\\n",
       "0                   -0.119263                   -0.439453   \n",
       "1                   -0.119263                   -0.439453   \n",
       "2                   -0.029495                   -0.478760   \n",
       "3                   -0.029495                   -0.478760   \n",
       "4                   -0.116211                   -0.562500   \n",
       "\n",
       "   ProNE_Emb_deviceidnewsid_6  ProNE_Emb_deviceidnewsid_7  \\\n",
       "0                   -0.027100                   -0.102661   \n",
       "1                   -0.027100                   -0.102661   \n",
       "2                   -0.010292                   -0.204224   \n",
       "3                   -0.010292                   -0.204224   \n",
       "4                    0.099670                   -0.265137   \n",
       "\n",
       "   ProNE_Emb_deviceidnewsid_8  ProNE_Emb_deviceidnewsid_9  \\\n",
       "0                    0.026093                    0.104431   \n",
       "1                    0.026093                    0.104431   \n",
       "2                    0.097107                    0.035980   \n",
       "3                    0.097107                    0.035980   \n",
       "4                    0.093445                    0.076050   \n",
       "\n",
       "   ProNE_Emb_deviceidnewsid_10  ProNE_Emb_deviceidnewsid_11  \\\n",
       "0                    -0.027176                    -0.217163   \n",
       "1                    -0.027176                    -0.217163   \n",
       "2                    -0.051910                    -0.001026   \n",
       "3                    -0.051910                    -0.001026   \n",
       "4                    -0.055054                    -0.210571   \n",
       "\n",
       "   ProNE_Emb_newsiddeviceid_0  ProNE_Emb_newsiddeviceid_1  \\\n",
       "0                   -0.256836                    0.190674   \n",
       "1                   -0.256836                    0.190674   \n",
       "2                   -0.428711                    0.255371   \n",
       "3                   -0.550781                    0.251221   \n",
       "4                   -0.171753                    0.213013   \n",
       "\n",
       "   ProNE_Emb_newsiddeviceid_2  ProNE_Emb_newsiddeviceid_3  \\\n",
       "0                   -0.386230                   -0.181885   \n",
       "1                   -0.386230                   -0.181885   \n",
       "2                   -0.456543                   -0.115417   \n",
       "3                   -0.387451                   -0.122009   \n",
       "4                   -0.342773                   -0.181519   \n",
       "\n",
       "   ProNE_Emb_newsiddeviceid_4  ProNE_Emb_newsiddeviceid_5  \\\n",
       "0                    0.701172                    0.299316   \n",
       "1                    0.701172                    0.299316   \n",
       "2                    0.599121                    0.090637   \n",
       "3                    0.603516                   -0.103943   \n",
       "4                    0.663574                    0.325684   \n",
       "\n",
       "   ProNE_Emb_newsiddeviceid_6  ProNE_Emb_newsiddeviceid_7  \\\n",
       "0                   -0.311279                    0.074585   \n",
       "1                   -0.311279                    0.074585   \n",
       "2                   -0.317139                   -0.086609   \n",
       "3                   -0.263184                   -0.091064   \n",
       "4                   -0.307617                    0.065063   \n",
       "\n",
       "   ProNE_Emb_newsiddeviceid_8  ProNE_Emb_newsiddeviceid_9  \\\n",
       "0                   -0.028839                    0.070312   \n",
       "1                   -0.028839                    0.070312   \n",
       "2                    0.055817                    0.111694   \n",
       "3                   -0.024979                    0.044098   \n",
       "4                    0.000292                    0.059937   \n",
       "\n",
       "   ProNE_Emb_newsiddeviceid_10  ProNE_Emb_newsiddeviceid_11  \\\n",
       "0                     0.060944                    -0.149414   \n",
       "1                     0.060944                    -0.149414   \n",
       "2                     0.054413                    -0.187988   \n",
       "3                     0.007622                    -0.117004   \n",
       "4                     0.145874                    -0.323242   \n",
       "\n",
       "   ProNE_Emb_deviceidlng_lat_0  ProNE_Emb_deviceidlng_lat_1  \\\n",
       "0                    -0.000019                     0.000119   \n",
       "1                    -0.000019                     0.000119   \n",
       "2                     0.059479                     0.586914   \n",
       "3                     0.059479                     0.586914   \n",
       "4                     0.000017                    -0.000321   \n",
       "\n",
       "   ProNE_Emb_deviceidlng_lat_2  ProNE_Emb_deviceidlng_lat_3  \\\n",
       "0                    -0.361572                     0.010559   \n",
       "1                    -0.361572                     0.010559   \n",
       "2                    -0.001003                    -0.736328   \n",
       "3                    -0.001003                    -0.736328   \n",
       "4                     0.864258                    -0.019943   \n",
       "\n",
       "   ProNE_Emb_deviceidlng_lat_4  ProNE_Emb_deviceidlng_lat_5  \\\n",
       "0                    -0.175537                     0.038452   \n",
       "1                    -0.175537                     0.038452   \n",
       "2                    -0.058136                    -0.000503   \n",
       "3                    -0.058136                    -0.000503   \n",
       "4                     0.239014                    -0.027313   \n",
       "\n",
       "   ProNE_Emb_deviceidlng_lat_6  ProNE_Emb_deviceidlng_lat_7  \\\n",
       "0                     0.873047                    -0.003801   \n",
       "1                     0.873047                    -0.003801   \n",
       "2                    -0.002249                    -0.326172   \n",
       "3                    -0.002249                    -0.326172   \n",
       "4                    -0.419678                     0.001897   \n",
       "\n",
       "   ProNE_Emb_deviceidlng_lat_8  ProNE_Emb_deviceidlng_lat_9  \\\n",
       "0                    -0.267090                    -0.011574   \n",
       "1                    -0.267090                    -0.011574   \n",
       "2                     0.010796                     0.001066   \n",
       "3                     0.010796                     0.001066   \n",
       "4                    -0.076904                     0.067383   \n",
       "\n",
       "   ProNE_Emb_deviceidlng_lat_10  ProNE_Emb_deviceidlng_lat_11  \\\n",
       "0                      0.054718                      0.000218   \n",
       "1                      0.054718                      0.000218   \n",
       "2                     -0.001086                      0.000703   \n",
       "3                     -0.001086                      0.000703   \n",
       "4                      0.088379                     -0.009117   \n",
       "\n",
       "   ProNE_Emb_lng_latdeviceid_0  ProNE_Emb_lng_latdeviceid_1  \\\n",
       "0                     0.000021                     0.000096   \n",
       "1                     0.000021                     0.000096   \n",
       "2                    -0.260010                     0.965820   \n",
       "3                    -0.260010                     0.965820   \n",
       "4                     0.000018                    -0.000018   \n",
       "\n",
       "   ProNE_Emb_lng_latdeviceid_2  ProNE_Emb_lng_latdeviceid_3  \\\n",
       "0                    -0.445557                     0.003216   \n",
       "1                    -0.445557                     0.003216   \n",
       "2                     0.000080                    -0.006207   \n",
       "3                     0.000080                    -0.006207   \n",
       "4                    -0.273682                     0.022263   \n",
       "\n",
       "   ProNE_Emb_lng_latdeviceid_4  ProNE_Emb_lng_latdeviceid_5  \\\n",
       "0                     0.662598                    -0.000787   \n",
       "1                     0.662598                    -0.000787   \n",
       "2                    -0.000084                     0.000006   \n",
       "3                    -0.000084                     0.000006   \n",
       "4                    -0.635742                     0.011139   \n",
       "\n",
       "   ProNE_Emb_lng_latdeviceid_6  ProNE_Emb_lng_latdeviceid_7  \\\n",
       "0                     0.520996                    -0.210449   \n",
       "1                     0.520996                    -0.210449   \n",
       "2                     0.000184                    -0.000030   \n",
       "3                     0.000184                    -0.000030   \n",
       "4                     0.705566                     0.000156   \n",
       "\n",
       "   ProNE_Emb_lng_latdeviceid_8  ProNE_Emb_lng_latdeviceid_9  \\\n",
       "0                     0.012054                     0.125732   \n",
       "1                     0.012054                     0.125732   \n",
       "2                     0.001305                    -0.000005   \n",
       "3                     0.001305                    -0.000005   \n",
       "4                     0.017792                     0.143677   \n",
       "\n",
       "   ProNE_Emb_lng_latdeviceid_10  ProNE_Emb_lng_latdeviceid_11  \\\n",
       "0                     -0.174927                     -0.006397   \n",
       "1                     -0.174927                     -0.006397   \n",
       "2                     -0.000013                      0.000002   \n",
       "3                     -0.000013                      0.000002   \n",
       "4                     -0.030518                      0.017197   \n",
       "\n",
       "   ProNE_Emb_newsidlng_lat_0  ProNE_Emb_newsidlng_lat_1  \\\n",
       "0                  -0.244385                   0.677246   \n",
       "1                  -0.244385                   0.677246   \n",
       "2                  -0.226318                   0.659180   \n",
       "3                  -0.407471                   0.448975   \n",
       "4                   0.048981                   0.790527   \n",
       "\n",
       "   ProNE_Emb_newsidlng_lat_2  ProNE_Emb_newsidlng_lat_3  \\\n",
       "0                  -0.023605                   0.248535   \n",
       "1                  -0.023605                   0.248535   \n",
       "2                  -0.123352                   0.211548   \n",
       "3                  -0.065369                   0.130981   \n",
       "4                  -0.272461                   0.313477   \n",
       "\n",
       "   ProNE_Emb_newsidlng_lat_4  ProNE_Emb_newsidlng_lat_5  \\\n",
       "0                  -0.416992                  -0.255371   \n",
       "1                  -0.416992                  -0.255371   \n",
       "2                  -0.154419                  -0.024704   \n",
       "3                   0.008987                  -0.044159   \n",
       "4                  -0.305176                  -0.119568   \n",
       "\n",
       "   ProNE_Emb_newsidlng_lat_6  ProNE_Emb_newsidlng_lat_7  \\\n",
       "0                  -0.323242                   0.046844   \n",
       "1                  -0.323242                   0.046844   \n",
       "2                  -0.329834                   0.016953   \n",
       "3                  -0.336426                  -0.155029   \n",
       "4                  -0.123840                  -0.100281   \n",
       "\n",
       "   ProNE_Emb_newsidlng_lat_8  ProNE_Emb_newsidlng_lat_9  \\\n",
       "0                   0.059753                  -0.115845   \n",
       "1                   0.059753                  -0.115845   \n",
       "2                   0.152710                  -0.366211   \n",
       "3                   0.211426                  -0.209473   \n",
       "4                   0.054962                   0.099060   \n",
       "\n",
       "   ProNE_Emb_newsidlng_lat_10  ProNE_Emb_newsidlng_lat_11  \\\n",
       "0                    0.229370                   -0.062744   \n",
       "1                    0.229370                   -0.062744   \n",
       "2                    0.019531                    0.403320   \n",
       "3                   -0.061279                   -0.616211   \n",
       "4                   -0.151367                    0.177490   \n",
       "\n",
       "   ProNE_Emb_lng_latnewsid_0  ProNE_Emb_lng_latnewsid_1  \\\n",
       "0                   0.392090                   0.312744   \n",
       "1                   0.375488                   0.319824   \n",
       "2                   0.999512                  -0.029022   \n",
       "3                   0.999512                  -0.029022   \n",
       "4                  -0.016266                   0.468018   \n",
       "\n",
       "   ProNE_Emb_lng_latnewsid_2  ProNE_Emb_lng_latnewsid_3  \\\n",
       "0                  -0.057617                   0.248169   \n",
       "1                  -0.021744                   0.266113   \n",
       "2                  -0.006161                  -0.001901   \n",
       "3                  -0.006161                  -0.001901   \n",
       "4                  -0.198486                   0.291992   \n",
       "\n",
       "   ProNE_Emb_lng_latnewsid_4  ProNE_Emb_lng_latnewsid_5  \\\n",
       "0                  -0.309082                   0.051453   \n",
       "1                  -0.322510                   0.093567   \n",
       "2                   0.000611                  -0.001487   \n",
       "3                   0.000611                  -0.001487   \n",
       "4                  -0.109436                   0.174683   \n",
       "\n",
       "   ProNE_Emb_lng_latnewsid_6  ProNE_Emb_lng_latnewsid_7  \\\n",
       "0                   0.306396                   0.084961   \n",
       "1                   0.349609                   0.142822   \n",
       "2                  -0.002813                  -0.000049   \n",
       "3                  -0.002813                  -0.000049   \n",
       "4                   0.549805                  -0.027069   \n",
       "\n",
       "   ProNE_Emb_lng_latnewsid_8  ProNE_Emb_lng_latnewsid_9  \\\n",
       "0                  -0.006470                  -0.001395   \n",
       "1                  -0.030502                  -0.083679   \n",
       "2                   0.000376                  -0.001728   \n",
       "3                   0.000376                  -0.001728   \n",
       "4                  -0.059601                   0.283691   \n",
       "\n",
       "   ProNE_Emb_lng_latnewsid_10  ProNE_Emb_lng_latnewsid_11      app_std  \\\n",
       "0                    0.443115                   -0.536621          NaN   \n",
       "1                    0.398193                   -0.513672          NaN   \n",
       "2                   -0.001726                    0.000089  8007.348429   \n",
       "3                   -0.001726                    0.000089  8007.348429   \n",
       "4                    0.074585                    0.470215  8833.990282   \n",
       "\n",
       "   app_min  app_median      app_mean  app_max  app_Gini  app_entropy  \\\n",
       "0    82968     82968.0  82968.000000    82968  0.000000     0.000000   \n",
       "1    82968     82968.0  82968.000000    82968  0.000000     0.000000   \n",
       "2      232      8728.0   9892.807229    54727  0.987952     6.375039   \n",
       "3      232      8728.0   9892.807229    54727  0.987952     6.375039   \n",
       "4      726      6834.5   9742.080645    54727  0.983871     5.954196   \n",
       "\n",
       "   app_appid_count_0_1e3_mean  app_appid_count_0_1e3_sum  \\\n",
       "0                    0.000000                          0   \n",
       "1                    0.000000                          0   \n",
       "2                    0.060241                          5   \n",
       "3                    0.060241                          5   \n",
       "4                    0.032258                          2   \n",
       "\n",
       "   app_appid_count_0_1e3_std  app_appid_count_1e3_1e4_mean  \\\n",
       "0                        NaN                      0.000000   \n",
       "1                        NaN                      0.000000   \n",
       "2                   0.239379                      0.530120   \n",
       "3                   0.239379                      0.530120   \n",
       "4                   0.178127                      0.629032   \n",
       "\n",
       "   app_appid_count_1e3_1e4_sum  app_appid_count_1e3_1e4_std  \\\n",
       "0                            0                          NaN   \n",
       "1                            0                          NaN   \n",
       "2                           44                     0.502126   \n",
       "3                           44                     0.502126   \n",
       "4                           39                     0.487007   \n",
       "\n",
       "   app_appid_count_1e4_2e5_mean  app_appid_count_1e4_2e5_sum  \\\n",
       "0                      1.000000                            1   \n",
       "1                      1.000000                            1   \n",
       "2                      0.409639                           34   \n",
       "3                      0.409639                           34   \n",
       "4                      0.338710                           21   \n",
       "\n",
       "   app_appid_count_1e4_2e5_std  d2v_AVG_device_app0  d2v_AVG_device_app1  \\\n",
       "0                          NaN             0.229667             0.169944   \n",
       "1                          NaN             0.229667             0.169944   \n",
       "2                     0.494757             0.083251            -1.161481   \n",
       "3                     0.494757             0.083251            -1.161481   \n",
       "4                     0.477134             0.954734             0.260951   \n",
       "\n",
       "   d2v_AVG_device_app2  d2v_AVG_device_app3  d2v_AVG_device_app4  \\\n",
       "0            -2.900885            -0.315794             0.124433   \n",
       "1            -2.900885            -0.315794             0.124433   \n",
       "2            -2.432074            -0.398634            -0.051843   \n",
       "3            -2.432074            -0.398634            -0.051843   \n",
       "4            -0.504951             1.799208            -1.132125   \n",
       "\n",
       "   d2v_AVG_device_app5  d2v_AVG_device_app6  d2v_AVG_device_app7  \\\n",
       "0             2.031552             0.353802            -2.051236   \n",
       "1             2.031552             0.353802            -2.051236   \n",
       "2            -1.733800             0.555071            -0.139786   \n",
       "3            -1.733800             0.555071            -0.139786   \n",
       "4            -0.098962            -0.753420            -0.125588   \n",
       "\n",
       "   d2v_AVG_device_app8  d2v_AVG_device_app9  d2v_AVG_device_app10  \\\n",
       "0            -0.223169             1.835867              0.867515   \n",
       "1            -0.223169             1.835867              0.867515   \n",
       "2             0.959530             0.568446             -0.598247   \n",
       "3             0.959530             0.568446             -0.598247   \n",
       "4             1.916600             1.888635             -0.908764   \n",
       "\n",
       "   d2v_AVG_device_app11  d2v_AVG_device_app12  d2v_AVG_device_app13  \\\n",
       "0              0.551410              0.138699             -1.922290   \n",
       "1              0.551410              0.138699             -1.922290   \n",
       "2              0.270606              0.376979              0.118636   \n",
       "3              0.270606              0.376979              0.118636   \n",
       "4              0.013501              1.923854             -1.444424   \n",
       "\n",
       "   d2v_AVG_device_app14  d2v_AVG_device_app15  d2v_AVG_device_app16  \\\n",
       "0              0.704013              0.352666             -0.955298   \n",
       "1              0.704013              0.352666             -0.955298   \n",
       "2             -0.806627             -0.648791             -1.445588   \n",
       "3             -0.806627             -0.648791             -1.445588   \n",
       "4              0.171221             -0.132168             -0.764097   \n",
       "\n",
       "   d2v_AVG_device_app17  d2v_AVG_device_app18  d2v_AVG_device_app19  \\\n",
       "0             -0.462648             -0.598233              0.018943   \n",
       "1             -0.462648             -0.598233              0.018943   \n",
       "2             -0.630914             -0.314666              0.202973   \n",
       "3             -0.630914             -0.314666              0.202973   \n",
       "4              1.372162              0.895375              0.445837   \n",
       "\n",
       "   d2v_AVG_device_app20  d2v_AVG_device_app21  d2v_AVG_device_app22  \\\n",
       "0              0.021031             -1.203783              1.928731   \n",
       "1              0.021031             -1.203783              1.928731   \n",
       "2              0.743717              0.755314             -0.124471   \n",
       "3              0.743717              0.755314             -0.124471   \n",
       "4              0.345051              0.586453             -0.045482   \n",
       "\n",
       "   d2v_AVG_device_app23  d2v_AVG_device_app24  d2v_AVG_device_app25  \\\n",
       "0              2.574627              0.105483              0.294248   \n",
       "1              2.574627              0.105483              0.294248   \n",
       "2              0.657093             -0.126836              0.587155   \n",
       "3              0.657093             -0.126836              0.587155   \n",
       "4              0.149633             -2.216098              0.381160   \n",
       "\n",
       "   d2v_AVG_device_app26  d2v_AVG_device_app27  d2v_AVG_device_app28  \\\n",
       "0              2.049570             -1.422524              1.005745   \n",
       "1              2.049570             -1.422524              1.005745   \n",
       "2             -1.227516             -0.327221             -0.416939   \n",
       "3             -1.227516             -0.327221             -0.416939   \n",
       "4              1.057738             -1.223602              0.074139   \n",
       "\n",
       "   d2v_AVG_device_app29  d2v_AVG_device_app30  d2v_AVG_device_app31  \\\n",
       "0             -2.768200              0.037534             -4.287595   \n",
       "1             -2.768200              0.037534             -4.287595   \n",
       "2             -2.411052             -0.488869             -0.431798   \n",
       "3             -2.411052             -0.488869             -0.431798   \n",
       "4             -2.436008              0.284429              0.469494   \n",
       "\n",
       "   d2v_AVG_device_app32  d2v_AVG_device_app33  d2v_AVG_device_app34  \\\n",
       "0              0.360542              1.584735              0.122490   \n",
       "1              0.360542              1.584735              0.122490   \n",
       "2              0.595850              1.019894              0.141429   \n",
       "3              0.595850              1.019894              0.141429   \n",
       "4             -0.345599              0.291438              0.069936   \n",
       "\n",
       "   d2v_AVG_device_app35  d2v_AVG_device_app36  d2v_AVG_device_app37  \\\n",
       "0             -1.142156             -3.268960             -2.070098   \n",
       "1             -1.142156             -3.268960             -2.070098   \n",
       "2             -0.595154             -0.995288             -0.620115   \n",
       "3             -0.595154             -0.995288             -0.620115   \n",
       "4             -0.273139              0.781932             -1.188197   \n",
       "\n",
       "   d2v_AVG_device_app38  d2v_AVG_device_app39  d2v_AVG_device_app40  \\\n",
       "0             -1.195602             -0.467857              3.079487   \n",
       "1             -1.195602             -0.467857              3.079487   \n",
       "2             -1.025364              0.373070              0.488267   \n",
       "3             -1.025364              0.373070              0.488267   \n",
       "4              1.492040              0.572475             -1.044357   \n",
       "\n",
       "   d2v_AVG_device_app41  d2v_AVG_device_app42  d2v_AVG_device_app43  \\\n",
       "0              0.163314              0.277376             -0.257015   \n",
       "1              0.163314              0.277376             -0.257015   \n",
       "2             -0.158316              0.925359             -0.932690   \n",
       "3             -0.158316              0.925359             -0.932690   \n",
       "4              0.810212              0.338468              0.057610   \n",
       "\n",
       "   d2v_AVG_device_app44  d2v_AVG_device_app45  d2v_AVG_device_app46  \\\n",
       "0             -2.257203              4.383832             -1.318662   \n",
       "1             -2.257203              4.383832             -1.318662   \n",
       "2             -0.287787              0.167010             -1.062522   \n",
       "3             -0.287787              0.167010             -1.062522   \n",
       "4             -1.062489              1.364387              0.097573   \n",
       "\n",
       "   d2v_AVG_device_app47  d2v_AVG_device_app48  d2v_AVG_device_app49  \\\n",
       "0              1.172728              0.787811             -0.427047   \n",
       "1              1.172728              0.787811             -0.427047   \n",
       "2              0.940552             -1.887199             -1.232756   \n",
       "3              0.940552             -1.887199             -1.232756   \n",
       "4              1.048951             -0.062811             -0.715884   \n",
       "\n",
       "   d2v_AVG_device_app50  d2v_AVG_device_app51  d2v_AVG_device_app52  \\\n",
       "0             -0.960159              0.298820              0.155137   \n",
       "1             -0.960159              0.298820              0.155137   \n",
       "2              1.301492              0.286067             -0.099003   \n",
       "3              1.301492              0.286067             -0.099003   \n",
       "4             -0.612811              0.463152              0.529903   \n",
       "\n",
       "   d2v_AVG_device_app53  d2v_AVG_device_app54  d2v_AVG_device_app55  \\\n",
       "0             -1.832210              0.402113              0.563161   \n",
       "1             -1.832210              0.402113              0.563161   \n",
       "2             -0.703239             -0.824787             -0.481791   \n",
       "3             -0.703239             -0.824787             -0.481791   \n",
       "4             -0.372357              1.056482              0.759485   \n",
       "\n",
       "   d2v_AVG_device_app56  d2v_AVG_device_app57  d2v_AVG_device_app58  \\\n",
       "0              0.848237             -2.778049              1.024568   \n",
       "1              0.848237             -2.778049              1.024568   \n",
       "2              0.822675             -0.023474             -0.938707   \n",
       "3              0.822675             -0.023474             -0.938707   \n",
       "4             -0.455366             -0.878562              0.900927   \n",
       "\n",
       "   d2v_AVG_device_app59  d2v_AVG_device_app60  d2v_AVG_device_app61  \\\n",
       "0              1.785690             -0.591784             -2.410546   \n",
       "1              1.785690             -0.591784             -2.410546   \n",
       "2             -0.236663              1.508289             -0.073710   \n",
       "3             -0.236663              1.508289             -0.073710   \n",
       "4             -1.025853             -1.810202             -0.571249   \n",
       "\n",
       "   d2v_AVG_device_app62  d2v_AVG_device_app63  d2v_AVG_tag_data0  \\\n",
       "0              1.044089              1.520381          -0.129813   \n",
       "1              1.044089              1.520381          -0.129813   \n",
       "2              0.321595              1.408211           0.332665   \n",
       "3              0.321595              1.408211           0.332665   \n",
       "4              1.250130             -1.023961           0.083121   \n",
       "\n",
       "   d2v_AVG_tag_data1  d2v_AVG_tag_data2  d2v_AVG_tag_data3  d2v_AVG_tag_data4  \\\n",
       "0          -0.756047           0.143118          -3.003398           1.596543   \n",
       "1          -0.756047           0.143118          -3.003398           1.596543   \n",
       "2          -1.183276           0.460998           0.678209          -0.088636   \n",
       "3          -1.183276           0.460998           0.678209          -0.088636   \n",
       "4          -0.240752           0.259732          -0.106717           0.399901   \n",
       "\n",
       "   d2v_AVG_tag_data5  d2v_AVG_tag_data6  d2v_AVG_tag_data7  d2v_AVG_tag_data8  \\\n",
       "0          -0.584900          -1.596267           0.030542           0.388159   \n",
       "1          -0.584900          -1.596267           0.030542           0.388159   \n",
       "2           0.753745           0.270165           0.993128          -0.927194   \n",
       "3           0.753745           0.270165           0.993128          -0.927194   \n",
       "4          -0.527019           0.129820           0.257990          -0.255550   \n",
       "\n",
       "   d2v_AVG_tag_data9  d2v_AVG_tag_data10  d2v_AVG_tag_data11  \\\n",
       "0          -0.557379            0.854521            0.894725   \n",
       "1          -0.557379            0.854521            0.894725   \n",
       "2          -0.484972            0.327580            0.353591   \n",
       "3          -0.484972            0.327580            0.353591   \n",
       "4           0.147038           -0.550301           -0.158245   \n",
       "\n",
       "   d2v_AVG_tag_data12  d2v_AVG_tag_data13  d2v_AVG_tag_data14  \\\n",
       "0           -0.186736           -1.806087            1.897598   \n",
       "1           -0.186736           -1.806087            1.897598   \n",
       "2            1.495096            0.292199           -1.466242   \n",
       "3            1.495096            0.292199           -1.466242   \n",
       "4            0.135884           -0.273290           -0.327118   \n",
       "\n",
       "   d2v_AVG_tag_data15  d2v_AVG_tag_data16  d2v_AVG_tag_data17  \\\n",
       "0           -0.131564            0.024668           -2.561837   \n",
       "1           -0.131564            0.024668           -2.561837   \n",
       "2           -1.294926            0.586212            1.577252   \n",
       "3           -1.294926            0.586212            1.577252   \n",
       "4           -0.365238            0.144167            0.532975   \n",
       "\n",
       "   d2v_AVG_tag_data18  d2v_AVG_tag_data19  d2v_AVG_tag_data20  \\\n",
       "0            2.267524           -2.068393           -2.761788   \n",
       "1            2.267524           -2.068393           -2.761788   \n",
       "2           -0.345576            0.389614            1.346425   \n",
       "3           -0.345576            0.389614            1.346425   \n",
       "4           -0.003386            0.301236            0.128555   \n",
       "\n",
       "   d2v_AVG_tag_data21  d2v_AVG_tag_data22  d2v_AVG_tag_data23  \\\n",
       "0            2.386210           -2.718360           -0.548159   \n",
       "1            2.386210           -2.718360           -0.548159   \n",
       "2           -1.408652            1.997177            0.811635   \n",
       "3           -1.408652            1.997177            0.811635   \n",
       "4            0.120494            0.514178            0.405775   \n",
       "\n",
       "   d2v_AVG_tag_data24  d2v_AVG_tag_data25  d2v_AVG_tag_data26  \\\n",
       "0            1.835239           -1.510004            1.048621   \n",
       "1            1.835239           -1.510004            1.048621   \n",
       "2            0.333166            1.139411            0.235408   \n",
       "3            0.333166            1.139411            0.235408   \n",
       "4           -0.309713            0.224365           -0.382392   \n",
       "\n",
       "   d2v_AVG_tag_data27  d2v_AVG_tag_data28  d2v_AVG_tag_data29  \\\n",
       "0            0.541290           -0.633753            0.796095   \n",
       "1            0.541290           -0.633753            0.796095   \n",
       "2           -0.059956            0.789531           -0.040708   \n",
       "3           -0.059956            0.789531           -0.040708   \n",
       "4            0.503778            0.160043            0.591017   \n",
       "\n",
       "   d2v_AVG_tag_data30  d2v_AVG_tag_data31  d2v_AVG_tag_data32  \\\n",
       "0            1.088916           -0.767209            1.343837   \n",
       "1            1.088916           -0.767209            1.343837   \n",
       "2           -0.726710           -0.972379           -0.677353   \n",
       "3           -0.726710           -0.972379           -0.677353   \n",
       "4            0.277168           -0.253905           -0.026216   \n",
       "\n",
       "   d2v_AVG_tag_data33  d2v_AVG_tag_data34  d2v_AVG_tag_data35  \\\n",
       "0            0.606001           -0.455894            0.051227   \n",
       "1            0.606001           -0.455894            0.051227   \n",
       "2           -0.488385           -0.626552            0.752678   \n",
       "3           -0.488385           -0.626552            0.752678   \n",
       "4            0.024109           -0.349101            0.553073   \n",
       "\n",
       "   d2v_AVG_tag_data36  d2v_AVG_tag_data37  d2v_AVG_tag_data38  \\\n",
       "0            1.232644            0.424371            0.432421   \n",
       "1            1.232644            0.424371            0.432421   \n",
       "2           -0.228315           -0.213311            0.774806   \n",
       "3           -0.228315           -0.213311            0.774806   \n",
       "4           -0.098054           -0.282613            0.485168   \n",
       "\n",
       "   d2v_AVG_tag_data39  d2v_AVG_tag_data40  d2v_AVG_tag_data41  \\\n",
       "0            0.239747           -1.199381           -0.008993   \n",
       "1            0.239747           -1.199381           -0.008993   \n",
       "2            0.892837            0.874291           -1.411790   \n",
       "3            0.892837            0.874291           -1.411790   \n",
       "4           -0.018452            0.130793           -0.634535   \n",
       "\n",
       "   d2v_AVG_tag_data42  d2v_AVG_tag_data43  d2v_AVG_tag_data44  \\\n",
       "0           -2.286062           -0.058223           -0.152359   \n",
       "1           -2.286062           -0.058223           -0.152359   \n",
       "2           -0.446326           -1.297786           -0.503773   \n",
       "3           -0.446326           -1.297786           -0.503773   \n",
       "4            0.030932            0.419520           -0.083059   \n",
       "\n",
       "   d2v_AVG_tag_data45  d2v_AVG_tag_data46  d2v_AVG_tag_data47  \\\n",
       "0           -0.061779           -0.566637           -1.288559   \n",
       "1           -0.061779           -0.566637           -1.288559   \n",
       "2            0.452777            0.103847            0.671636   \n",
       "3            0.452777            0.103847            0.671636   \n",
       "4           -0.224819           -0.205735            0.060189   \n",
       "\n",
       "   d2v_AVG_tag_data48  d2v_AVG_tag_data49  d2v_AVG_tag_data50  \\\n",
       "0           -2.503040           -0.225740           -0.904949   \n",
       "1           -2.503040           -0.225740           -0.904949   \n",
       "2            0.621443           -0.074798            1.488750   \n",
       "3            0.621443           -0.074798            1.488750   \n",
       "4            0.479622            0.030506            0.166140   \n",
       "\n",
       "   d2v_AVG_tag_data51  d2v_AVG_tag_data52  d2v_AVG_tag_data53  \\\n",
       "0            0.103600            2.627889            0.587643   \n",
       "1            0.103600            2.627889            0.587643   \n",
       "2            0.290481           -0.202093           -0.917715   \n",
       "3            0.290481           -0.202093           -0.917715   \n",
       "4            0.192798           -0.353424            0.061473   \n",
       "\n",
       "   d2v_AVG_tag_data54  d2v_AVG_tag_data55  d2v_AVG_tag_data56  \\\n",
       "0            1.011122           -2.079236           -0.159566   \n",
       "1            1.011122           -2.079236           -0.159566   \n",
       "2           -0.636657            1.729508            0.079522   \n",
       "3           -0.636657            1.729508            0.079522   \n",
       "4            0.300586            0.387644           -0.138975   \n",
       "\n",
       "   d2v_AVG_tag_data57  d2v_AVG_tag_data58  d2v_AVG_tag_data59  \\\n",
       "0            1.615453            3.527793            2.074279   \n",
       "1            1.615453            3.527793            2.074279   \n",
       "2           -1.216082           -0.983511           -0.244144   \n",
       "3           -1.216082           -0.983511           -0.244144   \n",
       "4            0.108618            0.192000           -0.071233   \n",
       "\n",
       "   d2v_AVG_tag_data60  d2v_AVG_tag_data61  d2v_AVG_tag_data62  \\\n",
       "0           -0.530506            1.772412            0.015235   \n",
       "1           -0.530506            1.772412            0.015235   \n",
       "2           -0.378886           -0.323935            0.244617   \n",
       "3           -0.378886           -0.323935            0.244617   \n",
       "4            0.015684           -0.055997            0.066533   \n",
       "\n",
       "   d2v_AVG_tag_data63  \n",
       "0            0.065970  \n",
       "1            0.065970  \n",
       "2           -0.926933  \n",
       "3           -0.926933  \n",
       "4            0.022561  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11376681, 274), (3653592, 274))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape,test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average score: 0.9840631756268536 线上 0.81467\n",
    "feas2drop = [\n",
    "    #'lng', 'lat', 'lng_lat',\n",
    "    'deviceid_prev_day_click_count',\n",
    "    'deviceid_prev_day_count', 'deviceid_prev_day_ctr',\n",
    "    'pos_deviceid_prev_day_click_count', 'pos_deviceid_prev_day_count',\n",
    "    'pos_deviceid_prev_day_ctr', 'newsid_next5_exposure_ts_gap',\n",
    "    'newsid_next10_exposure_ts_gap', 'pos_deviceid_next10_exposure_ts_gap',\n",
    "    'pos_newsid_next2_exposure_ts_gap', 'pos_newsid_next3_exposure_ts_gap',\n",
    "    'pos_newsid_next5_exposure_ts_gap',\n",
    "    'pos_netmodel_deviceid_next10_exposure_ts_gap', 'newsid_lng_lat_emb_7'\n",
    "]\n",
    "# corr_s<0.005\n",
    "low_corr_feas = [\n",
    "    'cross_pos_netmodel_count', 'device_vendor', 'deviceid_lng_lat_emb_6',\n",
    "    'city_level', 'minute',\n",
    "    'cross_province_device_version_nunique_ratio_province_count',\n",
    "    'deviceid_lng_lat_prev10_exposure_ts_gap',\n",
    "    'lng_lat_next10_exposure_ts_gap', 'cross_province_newsid_ent',\n",
    "    'cross_city_deviceid_ent', 'netmodel_lng_lat_prev5_exposure_ts_gap', \n",
    "    'pos_deviceid_lng_lat_prev2_exposure_ts_gap',\n",
    "    'pos_netmodel_deviceid_lng_lat_prev1_exposure_ts_gap',\n",
    "    'cross_province_device_version_ent',\n",
    "    'pos_netmodel_deviceid_next1_exposure_ts_gap',\n",
    "    'pos_netmodel_lng_lat_next2_exposure_ts_gap',\n",
    "    'pos_netmodel_deviceid_lng_lat_next2_exposure_ts_gap',\n",
    "    'lng_lat_newsid_emb_3', 'lng_lat_deviceid_emb_2',\n",
    "    'netmodel_deviceid_lng_lat_prev5_exposure_ts_gap',\n",
    "    'cross_city_deviceid_nunique_ratio_city_count'\n",
    "]\n",
    "\n",
    "low_importance = ['cross_pos_netmodel_nunique_ratio_pos_count',\n",
    "                  'cross_lng_lat_deviceid_ent',\n",
    "                  'cross_netmodel_pos_nunique_ratio_netmodel_count',\n",
    "                  'cross_pos_newsid_nunique',\n",
    "                  'cross_netmodel_newsid_nunique',\n",
    "                  'cross_netmodel_newsid_ent',\n",
    "                  'cross_lng_lat_deviceid_nunique',\n",
    "                  'cross_pos_netmodel_nunique',\n",
    "                  'cross_pos_lng_lat_nunique',\n",
    "                  'cross_netmodel_pos_nunique',\n",
    "                  'cross_netmodel_pos_ent',\n",
    "                  'cross_netmodel_lng_lat_nunique'\n",
    "                 ]\n",
    "\n",
    "\n",
    "\n",
    "feas2drop = list(set(feas2drop+low_corr_feas+low_importance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deviceid', 'newsid', 'pos', 'app_version', 'netmodel', 'osversion', 'device_version', 'lng', 'lat', 'lng_lat']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in feas2drop:\n",
    "    try:\n",
    "        cate_cols.remove(i)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "        \n",
    "print(cate_cols)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete fea finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in feas2drop:\n",
    "    try:\n",
    "        #del train_x[i]\n",
    "        #del val_x[i]\n",
    "        del train_df[i]\n",
    "        del test_df[i]\n",
    "    except:\n",
    "        continue\n",
    "print('delete fea finished')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feas = [i for i in train_df.columns if i not in ['day','id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21883.74 Mb, 12574.74 Mb (42.54 %)\n",
      "7027.91 Mb, 4038.35 Mb (42.54 %)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = reduce_mem(train_df)\n",
    "test_df = reduce_mem(test_df)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feas = [i for i in train_df.columns if i not in ['day']]\n",
    "print('============================== training validate =====================================')\n",
    "fea_imp_list = []\n",
    "clf = LGBMClassifier(\n",
    "    learning_rate=0.03,\n",
    "    n_estimators=6000,\n",
    "    num_leaves=255,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=2019,\n",
    "    metric=None\n",
    ")\n",
    "gc.collect()\n",
    "print('************** training **************')\n",
    "clf.fit(\n",
    "    train_x[feas], train_y,\n",
    "    eval_set=[(val_x[feas], val_y)],\n",
    "    eval_metric='auc',\n",
    "    categorical_feature=cate_cols,\n",
    "    early_stopping_rounds=200,\n",
    "    verbose=100\n",
    ")\n",
    "gc.collect()\n",
    "print('runtime:', time.time() - t)\n",
    "\n",
    "print('************** validate predict **************')\n",
    "best_rounds = clf.best_iteration_\n",
    "best_auc = clf.best_score_['valid_0']['auc']\n",
    "val_pred = clf.predict_proba(val_x[feas])[:, 1]\n",
    "fea_imp_list.append(clf.feature_importances_)\n",
    "print('runtime:', time.time() - t)\n",
    "\n",
    "print('============================ training predict ====================================')\n",
    "clf = LGBMClassifier(\n",
    "    learning_rate=0.03,\n",
    "    n_estimators=best_rounds,\n",
    "    num_leaves=255,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=2019\n",
    ")\n",
    "gc.collect()\n",
    "print('************** training **************')\n",
    "clf.fit(\n",
    "    train_df[feas], labels,\n",
    "    eval_set=[(train_df[feas], labels)],\n",
    "    categorical_feature=cate_cols,\n",
    "    verbose=100\n",
    ")\n",
    "print('runtime:', time.time() - t)\n",
    "gc.collect()\n",
    "print('************** test predict **************')\n",
    "sub = pd.read_csv('../data/sample.csv')\n",
    "sub['target'] = clf.predict_proba(test_df[feas])[:, 1]\n",
    "fea_imp_list.append(clf.feature_importances_)\n",
    "print('runtime:', time.time() - t)\n",
    "\n",
    "print('============================ feat importances ====================================')\n",
    "# 特征重要性可以好好看看\n",
    "fea_imp_dict = dict(zip(train_df.columns.values, np.mean(fea_imp_list, axis=0)))\n",
    "fea_imp_item = sorted(fea_imp_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "for f, imp in fea_imp_item:\n",
    "    print('{} = {}'.format(f, imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('============================== threshold search ==================================')\n",
    "# f1阈值敏感，所以对阈值做一个简单的迭代搜索。\n",
    "t0 = 0.05\n",
    "v = 0.002\n",
    "best_t = t0\n",
    "best_f1 = 0\n",
    "for step in range(201):\n",
    "    curr_t = t0 + step * v\n",
    "    y = [1 if x >= curr_t else 0 for x in val_pred]\n",
    "    curr_f1 = f1_score(val_y, y)\n",
    "    if curr_f1 > best_f1:\n",
    "        best_t = curr_t\n",
    "        best_f1 = curr_f1\n",
    "        print('step: {}   best threshold: {}   best f1: {}'.format(step, best_t, best_f1))\n",
    "print('search finish.')\n",
    "\n",
    "val_pred = [1 if x >= best_t else 0 for x in val_pred]\n",
    "print('\\nbest auc:', best_auc)\n",
    "print('best f1:', f1_score(val_y, val_pred))\n",
    "print('validate mean:', np.mean(val_pred))\n",
    "print('runtime:', time.time() - t)\n",
    "\n",
    "print('================================= sub save ======================================')\n",
    "sub.to_csv('sub_prob_{}_{}_{}.csv'.format(best_auc, best_f1, sub['target'].mean()), index=False)\n",
    "sub['target'] = sub['target'].apply(lambda x: 1 if x >= best_t else 0)\n",
    "sub.to_csv('sub_{}_{}_{}.csv'.format(best_auc, best_f1, sub['target'].mean()), index=False)\n",
    "print('runtime:', time.time() - t)\n",
    "print('finish.')\n",
    "print('=================================================================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5flod-lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {  'bagging_freq': 5,\n",
    "            'bagging_fraction': 0.331,\n",
    "            'boost_from_average':'false',\n",
    "            'boost': 'gbdt',\n",
    "            'feature_fraction': 0.0405,\n",
    "            'learning_rate': 0.083,\n",
    "            'max_depth': -1,\n",
    "            'metric':'auc',\n",
    "            'min_data_in_leaf': 80,\n",
    "            'min_sum_hessian_in_leaf': 10.0,\n",
    "#             'num_leaves': 3,\n",
    "#             'num_threads': 8,\n",
    "            'tree_learner': 'serial',\n",
    "            'objective': 'binary',\n",
    "            'verbosity': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zxh/.local/lib/python3.6/site-packages/lightgbm/basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['app_version', 'device_vendor', 'device_version', 'deviceid', 'lat', 'lng', 'lng_lat', 'netmodel', 'newsid', 'osversion', 'pos']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's binary_logloss: 0.209725\n",
      "[100]\tvalid_0's binary_logloss: 0.164613\n",
      "[150]\tvalid_0's binary_logloss: 0.141811\n",
      "[200]\tvalid_0's binary_logloss: 0.128746\n",
      "[250]\tvalid_0's binary_logloss: 0.120536\n",
      "[300]\tvalid_0's binary_logloss: 0.115255\n",
      "[350]\tvalid_0's binary_logloss: 0.111579\n",
      "[400]\tvalid_0's binary_logloss: 0.10883\n",
      "[450]\tvalid_0's binary_logloss: 0.106807\n",
      "[500]\tvalid_0's binary_logloss: 0.105241\n",
      "[550]\tvalid_0's binary_logloss: 0.103989\n",
      "[600]\tvalid_0's binary_logloss: 0.102912\n",
      "[650]\tvalid_0's binary_logloss: 0.102036\n",
      "[700]\tvalid_0's binary_logloss: 0.101253\n",
      "[750]\tvalid_0's binary_logloss: 0.100651\n",
      "[800]\tvalid_0's binary_logloss: 0.100162\n",
      "[850]\tvalid_0's binary_logloss: 0.0997133\n",
      "[900]\tvalid_0's binary_logloss: 0.0993687\n",
      "[950]\tvalid_0's binary_logloss: 0.0990755\n",
      "[1000]\tvalid_0's binary_logloss: 0.098796\n",
      "[1050]\tvalid_0's binary_logloss: 0.0985696\n",
      "[1100]\tvalid_0's binary_logloss: 0.0983703\n",
      "[1150]\tvalid_0's binary_logloss: 0.0981644\n",
      "[1200]\tvalid_0's binary_logloss: 0.0979771\n",
      "[1250]\tvalid_0's binary_logloss: 0.0978293\n",
      "[1300]\tvalid_0's binary_logloss: 0.0976817\n",
      "[1350]\tvalid_0's binary_logloss: 0.0975292\n",
      "[1400]\tvalid_0's binary_logloss: 0.0974003\n",
      "[1450]\tvalid_0's binary_logloss: 0.097273\n",
      "[1500]\tvalid_0's binary_logloss: 0.0971492\n",
      "[1550]\tvalid_0's binary_logloss: 0.0970367\n",
      "[1600]\tvalid_0's binary_logloss: 0.0969457\n",
      "[1650]\tvalid_0's binary_logloss: 0.0968704\n",
      "[1700]\tvalid_0's binary_logloss: 0.0967757\n",
      "[1750]\tvalid_0's binary_logloss: 0.0966955\n",
      "[1800]\tvalid_0's binary_logloss: 0.0966221\n",
      "[1850]\tvalid_0's binary_logloss: 0.0965565\n",
      "[1900]\tvalid_0's binary_logloss: 0.0964935\n",
      "[1950]\tvalid_0's binary_logloss: 0.0964409\n",
      "[2000]\tvalid_0's binary_logloss: 0.0963899\n",
      "[2050]\tvalid_0's binary_logloss: 0.096335\n",
      "[2100]\tvalid_0's binary_logloss: 0.0962698\n",
      "[2150]\tvalid_0's binary_logloss: 0.0962124\n",
      "[2200]\tvalid_0's binary_logloss: 0.0961736\n",
      "[2250]\tvalid_0's binary_logloss: 0.0961308\n",
      "[2300]\tvalid_0's binary_logloss: 0.0960816\n",
      "[2350]\tvalid_0's binary_logloss: 0.0960387\n",
      "[2400]\tvalid_0's binary_logloss: 0.0960188\n",
      "[2450]\tvalid_0's binary_logloss: 0.095972\n",
      "[2500]\tvalid_0's binary_logloss: 0.0959439\n",
      "[2550]\tvalid_0's binary_logloss: 0.0959032\n",
      "[2600]\tvalid_0's binary_logloss: 0.0958779\n",
      "[2650]\tvalid_0's binary_logloss: 0.095843\n",
      "[2700]\tvalid_0's binary_logloss: 0.0958185\n",
      "[2750]\tvalid_0's binary_logloss: 0.095816\n",
      "[2800]\tvalid_0's binary_logloss: 0.0957931\n",
      "[2850]\tvalid_0's binary_logloss: 0.0957635\n",
      "[2900]\tvalid_0's binary_logloss: 0.0957465\n",
      "[2950]\tvalid_0's binary_logloss: 0.0957278\n",
      "[3000]\tvalid_0's binary_logloss: 0.0956932\n",
      "[3050]\tvalid_0's binary_logloss: 0.09567\n",
      "[3100]\tvalid_0's binary_logloss: 0.0956497\n",
      "[3150]\tvalid_0's binary_logloss: 0.0956411\n",
      "[3200]\tvalid_0's binary_logloss: 0.0956339\n",
      "[3250]\tvalid_0's binary_logloss: 0.0956301\n",
      "[3300]\tvalid_0's binary_logloss: 0.095617\n",
      "[3350]\tvalid_0's binary_logloss: 0.0956095\n",
      "[3400]\tvalid_0's binary_logloss: 0.0955904\n",
      "[3450]\tvalid_0's binary_logloss: 0.0955879\n",
      "[3500]\tvalid_0's binary_logloss: 0.0955747\n",
      "[3550]\tvalid_0's binary_logloss: 0.095559\n",
      "[3600]\tvalid_0's binary_logloss: 0.0955529\n",
      "[3650]\tvalid_0's binary_logloss: 0.0955383\n",
      "[3700]\tvalid_0's binary_logloss: 0.095537\n",
      "[3750]\tvalid_0's binary_logloss: 0.0955366\n",
      "[3800]\tvalid_0's binary_logloss: 0.0955361\n",
      "[3850]\tvalid_0's binary_logloss: 0.0955336\n",
      "[3900]\tvalid_0's binary_logloss: 0.0955302\n",
      "[3950]\tvalid_0's binary_logloss: 0.0955206\n",
      "[4000]\tvalid_0's binary_logloss: 0.0955225\n",
      "[4050]\tvalid_0's binary_logloss: 0.09552\n",
      "[4100]\tvalid_0's binary_logloss: 0.0955242\n",
      "[4150]\tvalid_0's binary_logloss: 0.0955257\n",
      "[4200]\tvalid_0's binary_logloss: 0.0955187\n",
      "[4250]\tvalid_0's binary_logloss: 0.0955208\n",
      "[4300]\tvalid_0's binary_logloss: 0.0955144\n",
      "[4350]\tvalid_0's binary_logloss: 0.0955144\n",
      "[4400]\tvalid_0's binary_logloss: 0.0955162\n",
      "[4450]\tvalid_0's binary_logloss: 0.0955153\n",
      "[4500]\tvalid_0's binary_logloss: 0.0955148\n",
      "[4550]\tvalid_0's binary_logloss: 0.0955123\n",
      "[4600]\tvalid_0's binary_logloss: 0.0955113\n",
      "[4650]\tvalid_0's binary_logloss: 0.095509\n",
      "[4700]\tvalid_0's binary_logloss: 0.0955051\n",
      "[4750]\tvalid_0's binary_logloss: 0.0955082\n",
      "[4800]\tvalid_0's binary_logloss: 0.0955082\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-1f59e2124bf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         )\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0moof2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mpredictions2\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeas\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, raw_score, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    798\u001b[0m         \"\"\"\n\u001b[1;32m    799\u001b[0m         result = super(LGBMClassifier, self).predict(X, raw_score, num_iteration,\n\u001b[0;32m--> 800\u001b[0;31m                                                      pred_leaf, pred_contrib, **kwargs)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_classes\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mraw_score\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpred_leaf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, raw_score, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    605\u001b[0m                              % (self._n_features, n_features))\n\u001b[1;32m    606\u001b[0m         return self.booster_.predict(X, raw_score=raw_score, num_iteration=num_iteration,\n\u001b[0;32m--> 607\u001b[0;31m                                      pred_leaf=pred_leaf, pred_contrib=pred_contrib, **kwargs)\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, **kwargs)\u001b[0m\n\u001b[1;32m   2201\u001b[0m         return predictor.predict(data, num_iteration,\n\u001b[1;32m   2202\u001b[0m                                  \u001b[0mraw_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2203\u001b[0;31m                                  data_has_header, is_reshape)\n\u001b[0m\u001b[1;32m   2204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pred_for_csc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pred_for_np2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__pred_for_np2d\u001b[0;34m(self, mat, num_iteration, predict_type)\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__pred_for_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36minner_predict\u001b[0;34m(mat, num_iteration, predict_type, preds)\u001b[0m\n\u001b[1;32m    536\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_parameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_num_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m                 preds.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[1;32m    539\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_preds\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mout_num_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wrong length for predict results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "feas = [i for i in train_df.columns if i not in ['day','id']]\n",
    "folds = StratifiedKFold(n_splits=3, shuffle=False, random_state=2319)\n",
    "oof_lgb =  np.zeros(len(train_df)) \n",
    "predictions_lgb =np.zeros(len(test_df))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, labels)):\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "\n",
    "    X_train, X_valid = train_df.iloc[trn_idx][feas], train_df.iloc[val_idx][feas]\n",
    "    y_train, y_valid = labels[trn_idx], labels[val_idx]\n",
    "     \n",
    "    trn_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_valid, label=y_valid)   \n",
    "        \n",
    "    \n",
    "    clf = lgb.train(param, \n",
    "                    trn_data, \n",
    "                    5000, \n",
    "                    valid_sets = [trn_data, val_data], \n",
    "                    verbose_eval=100, \n",
    "                    early_stopping_rounds = 200)\n",
    "    oof_lgb[val_idx] = clf.predict(X_train, num_iteration=clf.best_iteration)\n",
    "    predictions_lgb += clf.predict(test_df[feas], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(labels, oof_lgb)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('============================ threshold search ============================')\n",
    "# f1阈值敏感，所以对阈值做一个简单的迭代搜索。\n",
    "t0 = 0.05\n",
    "v = 0.002\n",
    "best_t = t0\n",
    "best_f1 = 0\n",
    "for step in range(201):\n",
    "    curr_t = t0 + step * v\n",
    "    y = [1 if x >= curr_t else 0 for x in oof2]\n",
    "    curr_f1 = f1_score(labels, y)\n",
    "    if curr_f1 > best_f1:\n",
    "        best_t = curr_t\n",
    "        best_f1 = curr_f1\n",
    "        print('step: {}   best threshold: {}   best f1: {}'.format(step, best_t, best_f1))\n",
    "print('search finish.')\n",
    "\n",
    "\n",
    "\n",
    "oof2 = [1 if x >= best_t else 0 for x in oof2]\n",
    "print('\\nbest auc:', roc_auc_score(labels, oof2))\n",
    "print('best f1:', f1_score(labels , oof2))\n",
    "print('validate mean:', np.mean(oof2))\n",
    "\n",
    "\n",
    "print('=================================== sub save =============================')\n",
    "sub = pd.read_csv('../data/sample.csv')\n",
    "sub['target'] = predictions2\n",
    "sub.to_csv('sub_prob_5flod_base_{}_{}.csv'.format(best_f1, sub['target'].mean()), index=False)\n",
    "sub['target'] = sub['target'].apply(lambda x: 1 if x > best_t else 0)\n",
    "sub.to_csv('sub_5flod_base_{}_{}.csv'.format(best_f1, sub['target'].mean()), index=False)\n",
    "print('finish.')\n",
    "print('==============================================================')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feas = [i for i in train_df.columns if i not in ['day','id']]\n",
    "params = {'objective': 'binary:logistic',\n",
    "               'eval_metric': 'auc',\n",
    "               'max_depth': 14,\n",
    "               'eta': 0.1,\n",
    "               'gamma': 6,\n",
    "               'subsample': 0.8,\n",
    "               'colsample_bytree': 0.8,\n",
    "               'min_child_weight': 51,\n",
    "               'colsample_bylevel': 0.6,\n",
    "               'lambda': 0.5,\n",
    "               'alpha': 0.1,\n",
    "              'scale_pos_weight': 5,\n",
    "               'silent':0}\n",
    "    \n",
    "    \n",
    "folds = StratifiedKFold(n_splits=3, shuffle=False, random_state=2019)\n",
    "oof_xgb =  np.zeros(len(train_df)) \n",
    "predictions_xgb =np.zeros(len(test_df))\n",
    "\n",
    "for i, (trn, val) in enumerate(folds.split(train_df[feas].values,labels)):\n",
    "    print(i+1, \"fold.    AUC\")\n",
    "    \n",
    "    trn_x = train_df.iloc[trn][feas]\n",
    "    trn_y = labels[trn]\n",
    "    val_x = train_df.iloc[val][feas]\n",
    "    val_y = labels[val]\n",
    "\n",
    "    \n",
    "\n",
    "    model = xgb.train(params\n",
    "                      , xgb.DMatrix(trn_x, trn_y)\n",
    "                      , 200\n",
    "                      , [(xgb.DMatrix(trn_x, trn_y), 'train'), (xgb.DMatrix(val_x, val_y), 'valid')]\n",
    "                      , verbose_eval=100\n",
    "                      , early_stopping_rounds=200\n",
    "                      ,\n",
    "                      )\n",
    "\n",
    "    oof_xgb[val] = model.predict(xgb.DMatrix(val_x), ntree_limit=model.best_ntree_limit)\n",
    "    predictions_xgb += model.predict(xgb.DMatrix(test_df[feas]), ntree_limit=model.best_ntree_limit) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(labels, oof_xgb)))\n",
    "cv_auc = roc_auc_score(labels, oof_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1503"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('============================ threshold search ============================')\n",
    "# f1阈值敏感，所以对阈值做一个简单的迭代搜索。\n",
    "t0 = 0.05\n",
    "v = 0.002\n",
    "best_t = t0\n",
    "best_f1 = 0\n",
    "for step in range(201):\n",
    "    curr_t = t0 + step * v\n",
    "    y = [1 if x >= curr_t else 0 for x in oof_xgb]\n",
    "    curr_f1 = f1_score(labels, y)\n",
    "    if curr_f1 > best_f1:\n",
    "        best_t = curr_t\n",
    "        best_f1 = curr_f1\n",
    "        print('step: {}   best threshold: {}   best f1: {}'.format(step, best_t, best_f1))\n",
    "print('search finish.')\n",
    "\n",
    "\n",
    "\n",
    "oof_xgb_2 = [1 if x >= best_t else 0 for x in oof_xgb]\n",
    "print('\\nbest auc:', roc_auc_score(labels, oof_xgb))\n",
    "print('best f1:', f1_score(labels , oof_xgb_2))\n",
    "print('validate mean:', np.mean(oof_xgb_2))\n",
    "\n",
    "\n",
    "print('=================================== sub save =============================')\n",
    "sub = pd.read_csv('../data/sample.csv')\n",
    "sub['target'] = predictions_xgb\n",
    "sub.to_csv('sub_xgb_prob_5flod_base_{}_{}.csv'.format(best_f1, sub['target'].mean()), index=False)\n",
    "sub['target'] = sub['target'].apply(lambda x: 1 if x > best_t else 0)\n",
    "sub.to_csv('sub_xgb_5flod_base_{}_{}.csv'.format(best_f1, sub['target'].mean()), index=False)\n",
    "print('finish.')\n",
    "print('==============================================================')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model begin\n",
      "1 fold.    AUC\n",
      "0:\tlearn: 0.9369365\ttest: 0.9445722\tbest: 0.9445722 (0)\ttotal: 700ms\tremaining: 1h 33m 15s\n",
      "100:\tlearn: 0.9740548\ttest: 0.9773235\tbest: 0.9773235 (100)\ttotal: 1m 11s\tremaining: 1h 33m 14s\n",
      "200:\tlearn: 0.9778317\ttest: 0.9805130\tbest: 0.9805130 (200)\ttotal: 2m 24s\tremaining: 1h 33m 41s\n",
      "300:\tlearn: 0.9794760\ttest: 0.9818072\tbest: 0.9818072 (300)\ttotal: 3m 35s\tremaining: 1h 31m 42s\n",
      "400:\tlearn: 0.9804896\ttest: 0.9826404\tbest: 0.9826404 (400)\ttotal: 4m 45s\tremaining: 1h 30m 13s\n",
      "500:\tlearn: 0.9812031\ttest: 0.9832330\tbest: 0.9832330 (500)\ttotal: 5m 54s\tremaining: 1h 28m 24s\n",
      "600:\tlearn: 0.9816883\ttest: 0.9836264\tbest: 0.9836264 (600)\ttotal: 7m 4s\tremaining: 1h 27m 3s\n",
      "700:\tlearn: 0.9820799\ttest: 0.9839494\tbest: 0.9839494 (700)\ttotal: 8m 12s\tremaining: 1h 25m 32s\n",
      "800:\tlearn: 0.9823778\ttest: 0.9841849\tbest: 0.9841849 (800)\ttotal: 9m 22s\tremaining: 1h 24m 15s\n",
      "900:\tlearn: 0.9826504\ttest: 0.9844061\tbest: 0.9844061 (900)\ttotal: 10m 32s\tremaining: 1h 23m 7s\n",
      "1000:\tlearn: 0.9828992\ttest: 0.9846107\tbest: 0.9846107 (1000)\ttotal: 11m 40s\tremaining: 1h 21m 37s\n",
      "1100:\tlearn: 0.9831059\ttest: 0.9847733\tbest: 0.9847733 (1100)\ttotal: 12m 49s\tremaining: 1h 20m 22s\n",
      "1200:\tlearn: 0.9832816\ttest: 0.9849101\tbest: 0.9849101 (1200)\ttotal: 13m 56s\tremaining: 1h 18m 53s\n",
      "1300:\tlearn: 0.9834177\ttest: 0.9850121\tbest: 0.9850121 (1300)\ttotal: 15m 6s\tremaining: 1h 17m 48s\n",
      "1400:\tlearn: 0.9836015\ttest: 0.9851606\tbest: 0.9851606 (1400)\ttotal: 16m 26s\tremaining: 1h 17m 26s\n",
      "1500:\tlearn: 0.9837470\ttest: 0.9852646\tbest: 0.9852646 (1500)\ttotal: 17m 41s\tremaining: 1h 16m 37s\n",
      "1600:\tlearn: 0.9838623\ttest: 0.9853436\tbest: 0.9853436 (1600)\ttotal: 18m 53s\tremaining: 1h 15m 31s\n",
      "1700:\tlearn: 0.9839538\ttest: 0.9854057\tbest: 0.9854057 (1700)\ttotal: 20m 8s\tremaining: 1h 14m 36s\n",
      "1800:\tlearn: 0.9840947\ttest: 0.9855163\tbest: 0.9855163 (1799)\ttotal: 21m 20s\tremaining: 1h 13m 28s\n",
      "1900:\tlearn: 0.9842055\ttest: 0.9855905\tbest: 0.9855905 (1900)\ttotal: 22m 35s\tremaining: 1h 12m 29s\n",
      "2000:\tlearn: 0.9843181\ttest: 0.9856710\tbest: 0.9856710 (2000)\ttotal: 23m 55s\tremaining: 1h 11m 42s\n",
      "2100:\tlearn: 0.9844073\ttest: 0.9857312\tbest: 0.9857312 (2100)\ttotal: 25m 11s\tremaining: 1h 10m 44s\n",
      "2200:\tlearn: 0.9845044\ttest: 0.9858016\tbest: 0.9858016 (2200)\ttotal: 26m 26s\tremaining: 1h 9m 40s\n",
      "2300:\tlearn: 0.9845854\ttest: 0.9858544\tbest: 0.9858545 (2298)\ttotal: 27m 40s\tremaining: 1h 8m 33s\n",
      "2400:\tlearn: 0.9846518\ttest: 0.9858958\tbest: 0.9858958 (2400)\ttotal: 28m 57s\tremaining: 1h 7m 32s\n",
      "2500:\tlearn: 0.9847220\ttest: 0.9859376\tbest: 0.9859376 (2500)\ttotal: 30m 15s\tremaining: 1h 6m 31s\n",
      "2600:\tlearn: 0.9848024\ttest: 0.9859906\tbest: 0.9859906 (2600)\ttotal: 31m 34s\tremaining: 1h 5m 31s\n",
      "2700:\tlearn: 0.9848742\ttest: 0.9860354\tbest: 0.9860354 (2700)\ttotal: 32m 50s\tremaining: 1h 4m 26s\n",
      "2800:\tlearn: 0.9849589\ttest: 0.9860830\tbest: 0.9860830 (2800)\ttotal: 34m 3s\tremaining: 1h 3m 13s\n",
      "2900:\tlearn: 0.9850363\ttest: 0.9861293\tbest: 0.9861293 (2900)\ttotal: 35m 17s\tremaining: 1h 2m 1s\n",
      "3000:\tlearn: 0.9850957\ttest: 0.9861616\tbest: 0.9861616 (3000)\ttotal: 36m 30s\tremaining: 1h 48s\n",
      "3100:\tlearn: 0.9851621\ttest: 0.9861997\tbest: 0.9861997 (3100)\ttotal: 37m 45s\tremaining: 59m 39s\n",
      "3200:\tlearn: 0.9852173\ttest: 0.9862311\tbest: 0.9862311 (3200)\ttotal: 38m 59s\tremaining: 58m 27s\n",
      "3300:\tlearn: 0.9852681\ttest: 0.9862593\tbest: 0.9862593 (3300)\ttotal: 40m 13s\tremaining: 57m 15s\n",
      "3400:\tlearn: 0.9853273\ttest: 0.9862939\tbest: 0.9862939 (3400)\ttotal: 41m 28s\tremaining: 56m 5s\n",
      "3500:\tlearn: 0.9853770\ttest: 0.9863213\tbest: 0.9863213 (3500)\ttotal: 42m 40s\tremaining: 54m 49s\n",
      "3600:\tlearn: 0.9854284\ttest: 0.9863462\tbest: 0.9863462 (3600)\ttotal: 43m 50s\tremaining: 53m 33s\n",
      "3700:\tlearn: 0.9854796\ttest: 0.9863733\tbest: 0.9863733 (3700)\ttotal: 45m\tremaining: 52m 17s\n",
      "3800:\tlearn: 0.9855189\ttest: 0.9863926\tbest: 0.9863926 (3800)\ttotal: 46m 14s\tremaining: 51m 4s\n",
      "3900:\tlearn: 0.9855641\ttest: 0.9864180\tbest: 0.9864180 (3900)\ttotal: 47m 26s\tremaining: 49m 50s\n",
      "4000:\tlearn: 0.9856051\ttest: 0.9864372\tbest: 0.9864372 (4000)\ttotal: 48m 34s\tremaining: 48m 33s\n",
      "4100:\tlearn: 0.9856435\ttest: 0.9864548\tbest: 0.9864548 (4100)\ttotal: 49m 45s\tremaining: 47m 18s\n",
      "4200:\tlearn: 0.9856856\ttest: 0.9864730\tbest: 0.9864730 (4200)\ttotal: 50m 56s\tremaining: 46m 3s\n",
      "4300:\tlearn: 0.9857371\ttest: 0.9865088\tbest: 0.9865088 (4300)\ttotal: 52m 8s\tremaining: 44m 50s\n",
      "4400:\tlearn: 0.9857727\ttest: 0.9865217\tbest: 0.9865217 (4399)\ttotal: 53m 18s\tremaining: 43m 35s\n",
      "4500:\tlearn: 0.9858202\ttest: 0.9865466\tbest: 0.9865466 (4500)\ttotal: 54m 29s\tremaining: 42m 21s\n",
      "4600:\tlearn: 0.9858551\ttest: 0.9865604\tbest: 0.9865606 (4599)\ttotal: 55m 41s\tremaining: 41m 8s\n",
      "4700:\tlearn: 0.9858939\ttest: 0.9865775\tbest: 0.9865776 (4697)\ttotal: 56m 50s\tremaining: 39m 53s\n",
      "4800:\tlearn: 0.9859340\ttest: 0.9865969\tbest: 0.9865969 (4800)\ttotal: 58m 2s\tremaining: 38m 40s\n",
      "4900:\tlearn: 0.9859681\ttest: 0.9866116\tbest: 0.9866116 (4900)\ttotal: 59m 12s\tremaining: 37m 26s\n",
      "5000:\tlearn: 0.9860010\ttest: 0.9866255\tbest: 0.9866256 (4996)\ttotal: 1h 25s\tremaining: 36m 14s\n",
      "5100:\tlearn: 0.9860370\ttest: 0.9866417\tbest: 0.9866417 (5099)\ttotal: 1h 1m 36s\tremaining: 35m\n",
      "5200:\tlearn: 0.9860725\ttest: 0.9866584\tbest: 0.9866584 (5200)\ttotal: 1h 2m 46s\tremaining: 33m 47s\n",
      "5300:\tlearn: 0.9861097\ttest: 0.9866753\tbest: 0.9866753 (5300)\ttotal: 1h 3m 57s\tremaining: 32m 33s\n",
      "5400:\tlearn: 0.9861388\ttest: 0.9866852\tbest: 0.9866853 (5395)\ttotal: 1h 5m 7s\tremaining: 31m 20s\n",
      "5500:\tlearn: 0.9861722\ttest: 0.9866984\tbest: 0.9866984 (5500)\ttotal: 1h 6m 15s\tremaining: 30m 6s\n",
      "5600:\tlearn: 0.9862315\ttest: 0.9867389\tbest: 0.9867390 (5597)\ttotal: 1h 7m 23s\tremaining: 28m 51s\n",
      "5700:\tlearn: 0.9862701\ttest: 0.9867530\tbest: 0.9867530 (5699)\ttotal: 1h 8m 36s\tremaining: 27m 39s\n",
      "5800:\tlearn: 0.9863083\ttest: 0.9867694\tbest: 0.9867695 (5797)\ttotal: 1h 9m 46s\tremaining: 26m 26s\n",
      "5900:\tlearn: 0.9863385\ttest: 0.9867783\tbest: 0.9867784 (5896)\ttotal: 1h 10m 55s\tremaining: 25m 13s\n",
      "6000:\tlearn: 0.9863729\ttest: 0.9867944\tbest: 0.9867945 (5998)\ttotal: 1h 12m 4s\tremaining: 24m\n",
      "6100:\tlearn: 0.9864042\ttest: 0.9868062\tbest: 0.9868064 (6098)\ttotal: 1h 13m 14s\tremaining: 22m 47s\n",
      "6200:\tlearn: 0.9864330\ttest: 0.9868194\tbest: 0.9868194 (6200)\ttotal: 1h 14m 22s\tremaining: 21m 34s\n",
      "6300:\tlearn: 0.9864658\ttest: 0.9868313\tbest: 0.9868313 (6300)\ttotal: 1h 15m 32s\tremaining: 20m 22s\n",
      "6400:\tlearn: 0.9864950\ttest: 0.9868408\tbest: 0.9868408 (6400)\ttotal: 1h 16m 43s\tremaining: 19m 9s\n",
      "6500:\tlearn: 0.9865231\ttest: 0.9868515\tbest: 0.9868515 (6497)\ttotal: 1h 17m 53s\tremaining: 17m 57s\n",
      "6600:\tlearn: 0.9865547\ttest: 0.9868636\tbest: 0.9868636 (6600)\ttotal: 1h 19m 2s\tremaining: 16m 45s\n",
      "6700:\tlearn: 0.9865819\ttest: 0.9868726\tbest: 0.9868726 (6700)\ttotal: 1h 20m 11s\tremaining: 15m 32s\n",
      "6800:\tlearn: 0.9866130\ttest: 0.9868835\tbest: 0.9868836 (6799)\ttotal: 1h 21m 19s\tremaining: 14m 20s\n",
      "6900:\tlearn: 0.9866412\ttest: 0.9868923\tbest: 0.9868923 (6898)\ttotal: 1h 22m 29s\tremaining: 13m 8s\n",
      "7000:\tlearn: 0.9866675\ttest: 0.9868996\tbest: 0.9868996 (7000)\ttotal: 1h 23m 38s\tremaining: 11m 56s\n",
      "7100:\tlearn: 0.9866924\ttest: 0.9869063\tbest: 0.9869065 (7099)\ttotal: 1h 24m 48s\tremaining: 10m 44s\n",
      "7200:\tlearn: 0.9867227\ttest: 0.9869171\tbest: 0.9869171 (7200)\ttotal: 1h 25m 57s\tremaining: 9m 32s\n",
      "7300:\tlearn: 0.9867502\ttest: 0.9869258\tbest: 0.9869258 (7300)\ttotal: 1h 27m 8s\tremaining: 8m 20s\n",
      "7400:\tlearn: 0.9867827\ttest: 0.9869397\tbest: 0.9869397 (7400)\ttotal: 1h 28m 19s\tremaining: 7m 8s\n",
      "7500:\tlearn: 0.9868069\ttest: 0.9869467\tbest: 0.9869467 (7500)\ttotal: 1h 29m 29s\tremaining: 5m 57s\n",
      "7600:\tlearn: 0.9868358\ttest: 0.9869581\tbest: 0.9869581 (7599)\ttotal: 1h 30m 38s\tremaining: 4m 45s\n",
      "7700:\tlearn: 0.9868629\ttest: 0.9869669\tbest: 0.9869669 (7699)\ttotal: 1h 31m 45s\tremaining: 3m 33s\n",
      "7800:\tlearn: 0.9868889\ttest: 0.9869760\tbest: 0.9869760 (7800)\ttotal: 1h 32m 53s\tremaining: 2m 22s\n",
      "7900:\tlearn: 0.9869109\ttest: 0.9869813\tbest: 0.9869815 (7899)\ttotal: 1h 34m\tremaining: 1m 10s\n",
      "7999:\tlearn: 0.9869367\ttest: 0.9869904\tbest: 0.9869905 (7996)\ttotal: 1h 35m 11s\tremaining: 0us\n",
      "bestTest = 0.9869905114\n",
      "bestIteration = 7996\n",
      "Shrink model to first 7997 iterations.\n"
     ]
    }
   ],
   "source": [
    "cat_featrreas = cate_cols\n",
    "feas = [i for i in train_df.columns if i not in ['day']]\n",
    "\n",
    "folds = StratifiedKFold(n_splits=3, shuffle=True, random_state=2019)\n",
    "oof_cat =  np.zeros(len(train_df)) \n",
    "predictions_cat =np.zeros(len(test_df))\n",
    "print('model begin')\n",
    "for i, (trn, val) in enumerate(folds.split(train_df[feas].values,labels)):\n",
    "\n",
    "    print(i+1, \"fold.    AUC\")\n",
    "    \n",
    "    trn_x = train_df.loc[trn, feas]\n",
    "    trn_y = labels[trn]\n",
    "    val_x = train_df.loc[val, feas]\n",
    "    val_y = labels[val]\n",
    "\n",
    "    model = CatBoostClassifier(\n",
    "                            iterations=2500,\n",
    "                            thread_count=-1,\n",
    "                            loss_function='Logloss',\n",
    "                            # depth = 3,\n",
    "                            # l2_leaf_reg = 29,\n",
    "                            learning_rate = 0.19,\n",
    "                            use_best_model=True,\n",
    "                            task_type=\"GPU\",\n",
    "#                             devices='0',\n",
    "                            gpu_ram_part=0.9,\n",
    "                            eval_metric='AUC',\n",
    "                            early_stopping_rounds=200,\n",
    "                            od_type=\"Iter\",\n",
    "                            verbose=100,\n",
    "                            cat_features=cat_featrreas,\n",
    "                            #bagging_temperature = 0.18,\n",
    "                            #border_count = 136,\n",
    "                            #random_strength = 0.57,\n",
    "                            # scale_pos_weight = 0.8\n",
    "                            )\n",
    "    model.fit(trn_x, trn_y,\n",
    "                    eval_set=(val_x, val_y),\n",
    "                    use_best_model=True,\n",
    "#                       plot=True\n",
    "             )\n",
    "    print('flod ',i+1,'  finished')\n",
    "    oof_cat[val] = model.predict_proba(val_x)[:,1]\n",
    "    predictions_cat += model.predict_proba(test_df[feas])[:,1] / folds.n_splits\n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(labels, oof_cat)))\n",
    "cv_auc = roc_auc_score(labels, oof_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('============================ threshold search ============================')\n",
    "# f1阈值敏感，所以对阈值做一个简单的迭代搜索。\n",
    "t0 = 0.05\n",
    "v = 0.002\n",
    "best_t = t0\n",
    "best_f1 = 0\n",
    "for step in range(201):\n",
    "    curr_t = t0 + step * v\n",
    "    y = [1 if x >= curr_t else 0 for x in oof_cat]\n",
    "    curr_f1 = f1_score(labels, y)\n",
    "    if curr_f1 > best_f1:\n",
    "        best_t = curr_t\n",
    "        best_f1 = curr_f1\n",
    "        print('step: {}   best threshold: {}   best f1: {}'.format(step, best_t, best_f1))\n",
    "print('search finish.')\n",
    "\n",
    "\n",
    "\n",
    "oof_cat = [1 if x >= best_t else 0 for x in oof_cat]\n",
    "print('\\nbest auc:', roc_auc_score(labels, oof_cat))\n",
    "print('best f1:', f1_score(labels , oof_cat))\n",
    "print('validate mean:', np.mean(oof_cat))\n",
    "\n",
    "\n",
    "print('=================================== sub save =============================')\n",
    "sub = pd.read_csv('../data/sample.csv')\n",
    "sub['target'] = predictions_cat\n",
    "sub.to_csv('sub_cat_prob_5flod_base_{}_{}.csv'.format(best_f1, sub['target'].mean()), index=False)\n",
    "sub['target'] = sub['target'].apply(lambda x: 1 if x > best_t else 0)\n",
    "sub.to_csv('sub_cat_5flod_base_{}_{}.csv'.format(best_f1, sub['target'].mean()), index=False)\n",
    "print('finish.')\n",
    "print('==============================================================')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.metrics import log_loss, roc_auc_score,f1_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler \n",
    "from deepctr.models import DeepFM \n",
    "from deepctr.inputs import SparseFeat, DenseFeat,get_feature_names\n",
    "import gc\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os \n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 16613.09 Mb (0.0% reduction)\n",
      "read data finished\n"
     ]
    }
   ],
   "source": [
    "data = train_df.append(test_df,sort = False)\n",
    "train_len = train_df.shape[0]\n",
    "data = reduce_mem_usage(data)\n",
    "del train_df,test_df\n",
    "gc.collect()\n",
    "print('read data finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_features = ['deviceid',\n",
    " 'newsid',\n",
    " 'pos',\n",
    " 'app_version',\n",
    " 'device_vendor',\n",
    " 'netmodel',\n",
    " 'osversion',\n",
    " 'lng',\n",
    " 'lat',\n",
    " 'device_version',\n",
    " 'hour',\n",
    " 'minute',\n",
    " 'lng_lat']\n",
    "dense_features = [i for i in data.columns if i not in sparse_features + ['id','label']]\n",
    "\n",
    "target = ['label']    \n",
    "\n",
    "\n",
    "data[sparse_features] = data[sparse_features].fillna('-1', )\n",
    "data[dense_features] = data[dense_features].fillna(0, )\n",
    "\n",
    "for feat in tqdm(sparse_features):\n",
    "        lbe = LabelEncoder()\n",
    "        data[feat] = lbe.fit_transform(data[feat])\n",
    "        gc.collect()\n",
    "        \n",
    "for feat in tqdm(dense_features):\n",
    "        mms = MinMaxScaler(feature_range=(0, 1))\n",
    "        data[feat] = mms.fit_transform(data[feat].values.reshape(-1,1))\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "fixlen_feature_columns = [SparseFeat(feat, vocabulary_size=data[feat].nunique(),embedding_dim=8)\n",
    "                           for i,feat in enumerate(sparse_features)] + [DenseFeat(feat, 1,)\n",
    "                          for feat in dense_features]\n",
    "\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "\n",
    "\n",
    "data.reset_index(drop = True,inplace = True)\n",
    "\n",
    "train = data[:train_len].reset_index(drop=True)\n",
    "test = data[train_len:].reset_index(drop=True)\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras import backend as K\n",
    "\n",
    "def metric_precision(y_true,y_pred):    \n",
    "    TP=tf.reduce_sum(y_true*tf.round(y_pred))\n",
    "    TN=tf.reduce_sum((1-y_true)*(1-tf.round(y_pred)))\n",
    "    FP=tf.reduce_sum((1-y_true)*tf.round(y_pred))\n",
    "    FN=tf.reduce_sum(y_true*(1-tf.round(y_pred)))\n",
    "    precision=TP/(TP+FP)\n",
    "    return precision\n",
    "\n",
    "#召回率评价指标\n",
    "def metric_recall(y_true,y_pred):  \n",
    "    TP=tf.reduce_sum(y_true*tf.round(y_pred))\n",
    "    TN=tf.reduce_sum((1-y_true)*(1-tf.round(y_pred)))\n",
    "    FP=tf.reduce_sum((1-y_true)*tf.round(y_pred))\n",
    "    FN=tf.reduce_sum(y_true*(1-tf.round(y_pred)))\n",
    "    recall=TP/(TP+FN)\n",
    "    return recall\n",
    "\n",
    "#F1-score评价指标\n",
    "def metric_F1score(y_true,y_pred):    \n",
    "    TP=tf.reduce_sum(y_true*tf.round(y_pred))\n",
    "    TN=tf.reduce_sum((1-y_true)*(1-tf.round(y_pred)))\n",
    "    FP=tf.reduce_sum((1-y_true)*tf.round(y_pred))\n",
    "    FN=tf.reduce_sum(y_true*(1-tf.round(y_pred)))\n",
    "    precision=TP/(TP+FP)\n",
    "    recall=TP/(TP+FN)\n",
    "    F1score=2*precision*recall/(precision+recall)\n",
    "    return F1score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model begin\n",
      "==========flod 0 ===============\n",
      "Train on 7584454 samples, validate on 3792227 samples\n",
      "WARNING:tensorflow:From /home/zxh/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zxh/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7584454/7584454 [==============================] - 3835s 506us/sample - loss: 0.5995 - acc: 0.7705 - metric_F1score: 0.4450 - val_loss: 0.8738 - val_acc: 0.3432 - val_metric_F1score: 0.2399\n",
      "Epoch 2/5\n",
      "7584454/7584454 [==============================] - 3794s 500us/sample - loss: 0.5519 - acc: 0.7714 - metric_F1score: 0.4460 - val_loss: 0.6828 - val_acc: 0.8931 - val_metric_F1score: nan\n",
      "Epoch 3/5\n",
      "7584454/7584454 [==============================] - 3694s 487us/sample - loss: 0.5518 - acc: 0.7717 - metric_F1score: 0.4461 - val_loss: 0.5982 - val_acc: 0.8935 - val_metric_F1score: nan\n",
      "Epoch 4/5\n",
      "7584454/7584454 [==============================] - 3589s 473us/sample - loss: 0.5513 - acc: 0.7720 - metric_F1score: 0.4466 - val_loss: 0.7903 - val_acc: 0.5854 - val_metric_F1score: 0.2899\n",
      "Epoch 5/5\n",
      "7584454/7584454 [==============================] - 3819s 504us/sample - loss: 0.5515 - acc: 0.7715 - metric_F1score: 0.4460 - val_loss: 0.6816 - val_acc: 0.8922 - val_metric_F1score: nan\n",
      "==========flod 1 ===============\n",
      "Train on 7584454 samples, validate on 3792227 samples\n",
      "Epoch 1/5\n",
      "7584454/7584454 [==============================] - 3842s 507us/sample - loss: 0.5515 - acc: 0.7725 - metric_F1score: 0.4468 - val_loss: 0.6152 - val_acc: 0.8935 - val_metric_F1score: nan\n",
      "Epoch 2/5\n",
      "7584454/7584454 [==============================] - 3838s 506us/sample - loss: 0.5514 - acc: 0.7720 - metric_F1score: 0.4464 - val_loss: 0.7420 - val_acc: 0.8206 - val_metric_F1score: 0.3369\n",
      "Epoch 3/5\n",
      "7584454/7584454 [==============================] - 3842s 507us/sample - loss: 0.5512 - acc: 0.7720 - metric_F1score: 0.4465 - val_loss: 0.7017 - val_acc: 0.8927 - val_metric_F1score: nan\n",
      "Epoch 4/5\n",
      "7584454/7584454 [==============================] - 3832s 505us/sample - loss: 0.5517 - acc: 0.7718 - metric_F1score: 0.4462 - val_loss: 0.6898 - val_acc: 0.8914 - val_metric_F1score: nan\n",
      "Epoch 5/5\n",
      "7584454/7584454 [==============================] - 3830s 505us/sample - loss: 0.5512 - acc: 0.7719 - metric_F1score: 0.4463 - val_loss: 0.7668 - val_acc: 0.7228 - val_metric_F1score: 0.3537\n",
      "==========flod 2 ===============\n",
      "Train on 7584454 samples, validate on 3792227 samples\n",
      "Epoch 1/5\n",
      "7584454/7584454 [==============================] - 3813s 503us/sample - loss: 0.5512 - acc: 0.7719 - metric_F1score: 0.4465 - val_loss: 0.6063 - val_acc: 0.8934 - val_metric_F1score: nan\n",
      "Epoch 2/5\n",
      "7584454/7584454 [==============================] - 3839s 506us/sample - loss: 0.5515 - acc: 0.7715 - metric_F1score: 0.4460 - val_loss: 0.7162 - val_acc: 0.8789 - val_metric_F1score: nan\n",
      "Epoch 3/5\n",
      "7584454/7584454 [==============================] - 3856s 508us/sample - loss: 0.5514 - acc: 0.7718 - metric_F1score: 0.4463 - val_loss: 0.6569 - val_acc: 0.8934 - val_metric_F1score: nan\n",
      "Epoch 4/5\n",
      "7584454/7584454 [==============================] - 3952s 521us/sample - loss: 0.5515 - acc: 0.7718 - metric_F1score: 0.4463 - val_loss: 0.6761 - val_acc: 0.8933 - val_metric_F1score: nan\n",
      "Epoch 5/5\n",
      "7584454/7584454 [==============================] - 3947s 520us/sample - loss: 0.5514 - acc: 0.7719 - metric_F1score: 0.4465 - val_loss: 0.7224 - val_acc: 0.8244 - val_metric_F1score: nan\n",
      "CV score: 0.72899 \n"
     ]
    }
   ],
   "source": [
    "print('model begin')\n",
    "class_weights = {0:0.5,1:5}\n",
    "model = DeepFM(linear_feature_columns, dnn_feature_columns, task='binary',\n",
    "               l2_reg_linear=0.1, l2_reg_embedding=0.1,\n",
    "               l2_reg_dnn=0.1,  seed=1024, dnn_dropout=0.2,\n",
    "                dnn_activation='relu', dnn_use_bn=True,\n",
    "              )\n",
    "model.compile(\"adam\", \"binary_crossentropy\",\n",
    "              metrics=['accuracy',metric_F1score], )\n",
    "\n",
    "\n",
    "folds = StratifiedKFold(n_splits=3, shuffle=False, random_state=44000)\n",
    "oof_DEEPFM = np.zeros(len(train))\n",
    "preds_DEEPFM = np.zeros(len(test))\n",
    "\n",
    "\n",
    "test_model_input = {name:test[name] for name in feature_names}\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values,labels)):\n",
    "    print(\"==========flod\",fold_,\"===============\")\n",
    "    tr = train.iloc[trn_idx]\n",
    "    tr_y = labels[trn_idx]\n",
    "    val = train.iloc[val_idx]\n",
    "    val_y = labels[val_idx]\n",
    "\n",
    "    tr_model_input = {name:tr[name] for name in feature_names}\n",
    "    val_model_input = {name:val[name] for name in feature_names}\n",
    "\n",
    "    history = model.fit(tr_model_input, tr_y,\n",
    "                        validation_data = (val_model_input,val_y),\n",
    "                        batch_size=256, epochs=5, verbose=1,class_weight = class_weights)\n",
    "\n",
    "    oof_DEEPFM[val_idx] = model.predict(val_model_input,batch_size=512)[:,0]\n",
    "    # pred_train = model.predict(train_model_input, batch_size=512)\n",
    "    preds_DEEPFM += model.predict(test_model_input,batch_size=512)[:,0]/ folds.n_splits\n",
    "    # pred_test = model.predict(test_model_input, batch_size=512)\n",
    "    \n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(labels, oof_DEEPFM)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================ threshold search ============================\n",
      "step: 0   best threshold: 0.05   best f1: 0.1925565143784914\n",
      "step: 105   best threshold: 0.26   best f1: 0.19255652967447465\n",
      "step: 107   best threshold: 0.264   best f1: 0.1925565449704604\n",
      "step: 108   best threshold: 0.266   best f1: 0.19255657556243913\n",
      "step: 109   best threshold: 0.268   best f1: 0.19255682029861906\n",
      "step: 110   best threshold: 0.27   best f1: 0.1925571415157994\n",
      "step: 111   best threshold: 0.272   best f1: 0.19255787573052147\n",
      "step: 112   best threshold: 0.274   best f1: 0.19255888528490667\n",
      "step: 113   best threshold: 0.276   best f1: 0.19256050671258818\n",
      "step: 114   best threshold: 0.278   best f1: 0.19256382613555958\n",
      "step: 115   best threshold: 0.28   best f1: 0.1925694097549257\n",
      "step: 116   best threshold: 0.28200000000000003   best f1: 0.19257650830291137\n",
      "step: 117   best threshold: 0.28400000000000003   best f1: 0.1925874113317829\n",
      "step: 118   best threshold: 0.28600000000000003   best f1: 0.19260301718993858\n",
      "step: 119   best threshold: 0.28800000000000003   best f1: 0.19262424895960892\n",
      "step: 120   best threshold: 0.29   best f1: 0.1926533129554524\n",
      "step: 121   best threshold: 0.292   best f1: 0.1926907409793666\n",
      "step: 122   best threshold: 0.294   best f1: 0.19274040528524233\n",
      "step: 123   best threshold: 0.296   best f1: 0.19280678429062714\n",
      "step: 124   best threshold: 0.298   best f1: 0.19289147095403508\n",
      "step: 125   best threshold: 0.3   best f1: 0.19299829129516005\n",
      "step: 126   best threshold: 0.302   best f1: 0.1931285452269993\n",
      "step: 127   best threshold: 0.304   best f1: 0.19328705005122518\n",
      "step: 128   best threshold: 0.306   best f1: 0.19347744835968694\n",
      "step: 129   best threshold: 0.308   best f1: 0.19370526930968715\n",
      "step: 130   best threshold: 0.31   best f1: 0.19397638445073012\n",
      "step: 131   best threshold: 0.312   best f1: 0.1942938742554844\n",
      "step: 132   best threshold: 0.314   best f1: 0.19465700460659566\n",
      "step: 133   best threshold: 0.316   best f1: 0.19507166555526695\n",
      "step: 134   best threshold: 0.318   best f1: 0.19553690382641625\n",
      "step: 135   best threshold: 0.32   best f1: 0.19606308588717533\n",
      "step: 136   best threshold: 0.322   best f1: 0.19664669983743233\n",
      "step: 137   best threshold: 0.324   best f1: 0.19728544456775587\n",
      "step: 138   best threshold: 0.326   best f1: 0.19799163485215956\n",
      "step: 139   best threshold: 0.328   best f1: 0.19876121093914287\n",
      "step: 140   best threshold: 0.33   best f1: 0.19959686336328308\n",
      "step: 141   best threshold: 0.332   best f1: 0.2004790833623457\n",
      "step: 142   best threshold: 0.334   best f1: 0.20144459784331287\n",
      "step: 143   best threshold: 0.336   best f1: 0.20245849558185128\n",
      "step: 144   best threshold: 0.338   best f1: 0.2035238956535811\n",
      "step: 145   best threshold: 0.33999999999999997   best f1: 0.20463578859865197\n",
      "step: 146   best threshold: 0.34199999999999997   best f1: 0.2058028452379784\n",
      "step: 147   best threshold: 0.344   best f1: 0.2070204323066914\n",
      "step: 148   best threshold: 0.346   best f1: 0.20826868327586726\n",
      "step: 149   best threshold: 0.348   best f1: 0.20954615716692893\n",
      "step: 150   best threshold: 0.35   best f1: 0.21086298829460165\n",
      "step: 151   best threshold: 0.352   best f1: 0.21220327093998817\n",
      "step: 152   best threshold: 0.354   best f1: 0.21356547151883826\n",
      "step: 153   best threshold: 0.356   best f1: 0.21492464957275972\n",
      "step: 154   best threshold: 0.358   best f1: 0.21629342824660094\n",
      "step: 155   best threshold: 0.36   best f1: 0.21766320110457413\n",
      "step: 156   best threshold: 0.362   best f1: 0.21898539121279254\n",
      "step: 157   best threshold: 0.364   best f1: 0.2202954233424982\n",
      "step: 158   best threshold: 0.366   best f1: 0.22158465468777772\n",
      "step: 159   best threshold: 0.368   best f1: 0.22283733940906805\n",
      "step: 160   best threshold: 0.37   best f1: 0.22405180209814404\n",
      "step: 161   best threshold: 0.372   best f1: 0.2252108073188984\n",
      "step: 162   best threshold: 0.374   best f1: 0.22634806196836274\n",
      "step: 163   best threshold: 0.376   best f1: 0.22742614134100889\n",
      "step: 164   best threshold: 0.378   best f1: 0.2284514033873969\n",
      "step: 165   best threshold: 0.38   best f1: 0.22942158823957262\n",
      "step: 166   best threshold: 0.382   best f1: 0.23034102433598574\n",
      "step: 167   best threshold: 0.384   best f1: 0.23124075642851968\n",
      "step: 168   best threshold: 0.386   best f1: 0.23207446803318932\n",
      "step: 169   best threshold: 0.388   best f1: 0.23288308556771825\n",
      "step: 170   best threshold: 0.39   best f1: 0.23365681959522397\n",
      "step: 171   best threshold: 0.392   best f1: 0.23441726231231336\n",
      "step: 172   best threshold: 0.394   best f1: 0.23515377190856038\n",
      "step: 173   best threshold: 0.396   best f1: 0.2358715446766549\n",
      "step: 174   best threshold: 0.398   best f1: 0.23661801597056442\n",
      "step: 175   best threshold: 0.4   best f1: 0.23738105536332182\n",
      "step: 176   best threshold: 0.40199999999999997   best f1: 0.23817762086095878\n",
      "step: 177   best threshold: 0.40399999999999997   best f1: 0.23902712130749978\n",
      "step: 178   best threshold: 0.40599999999999997   best f1: 0.23991335539854405\n",
      "step: 179   best threshold: 0.408   best f1: 0.24085740543210132\n",
      "step: 180   best threshold: 0.41   best f1: 0.24189828784446035\n",
      "step: 181   best threshold: 0.412   best f1: 0.24302753071988786\n",
      "step: 182   best threshold: 0.414   best f1: 0.24422897248559783\n",
      "step: 183   best threshold: 0.416   best f1: 0.24552400148313777\n",
      "step: 184   best threshold: 0.418   best f1: 0.24688015637789879\n",
      "step: 185   best threshold: 0.42   best f1: 0.24831004589105696\n",
      "step: 186   best threshold: 0.422   best f1: 0.249824854746953\n",
      "step: 187   best threshold: 0.424   best f1: 0.251410670923075\n",
      "step: 188   best threshold: 0.426   best f1: 0.2530346027196447\n",
      "step: 189   best threshold: 0.428   best f1: 0.25468232218070047\n",
      "step: 190   best threshold: 0.43   best f1: 0.2563293527592615\n",
      "step: 191   best threshold: 0.432   best f1: 0.2579682423172453\n",
      "step: 192   best threshold: 0.434   best f1: 0.2595998574132972\n",
      "step: 193   best threshold: 0.436   best f1: 0.2611792920424063\n",
      "step: 194   best threshold: 0.438   best f1: 0.2627253299362451\n",
      "step: 195   best threshold: 0.44   best f1: 0.2641765489143563\n",
      "step: 196   best threshold: 0.442   best f1: 0.2655430297135953\n",
      "step: 197   best threshold: 0.444   best f1: 0.2668272317473013\n",
      "step: 198   best threshold: 0.446   best f1: 0.2680140316472037\n",
      "step: 199   best threshold: 0.448   best f1: 0.2691010939813542\n",
      "step: 200   best threshold: 0.45   best f1: 0.2700478579511875\n",
      "search finish.\n",
      "\n",
      "best auc: 0.7289939757884981\n",
      "best f1: 0.2700478579511875\n",
      "validate mean: 0.44428506552424746\n",
      "=================================== sub save =============================\n",
      "finish.\n",
      "==============================================================\n"
     ]
    }
   ],
   "source": [
    "print('============================ threshold search ============================')\n",
    "# f1阈值敏感，所以对阈值做一个简单的迭代搜索。\n",
    "t0 = 0.05\n",
    "v = 0.002\n",
    "best_t = t0\n",
    "best_f1 = 0\n",
    "for step in range(201):\n",
    "    curr_t = t0 + step * v\n",
    "    y = [1 if x >= curr_t else 0 for x in oof_DEEPFM]\n",
    "    curr_f1 = f1_score(labels, y)\n",
    "    if curr_f1 > best_f1:\n",
    "        best_t = curr_t\n",
    "        best_f1 = curr_f1\n",
    "        print('step: {}   best threshold: {}   best f1: {}'.format(step, best_t, best_f1))\n",
    "print('search finish.')\n",
    "\n",
    "\n",
    "\n",
    "oof_DEEPFM_1 = [1 if x >= best_t else 0 for x in oof_DEEPFM]\n",
    "print('\\nbest auc:', roc_auc_score(labels, oof_DEEPFM))\n",
    "print('best f1:', f1_score(labels , oof_DEEPFM_1))\n",
    "print('validate mean:', np.mean(oof_DEEPFM))\n",
    "\n",
    "\n",
    "print('=================================== sub save =============================')\n",
    "sub = pd.read_csv('../data/sample.csv')\n",
    "sub['target'] = preds_DEEPFM\n",
    "sub.to_csv('sub_deepfm_prob_5flod_base_{}_{}.csv'.format(best_f1, sub['target'].mean()), index=False)\n",
    "sub['target'] = sub['target'].apply(lambda x: 1 if x > best_t else 0)\n",
    "sub.to_csv('sub_deepfm_5flod_base_{}_{}.csv'.format(best_f1, sub['target'].mean()), index=False)\n",
    "print('finish.')\n",
    "print('==============================================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = pd.DataFrame({'real_target':labels,'pred_target':oof_DEEPFM})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result.to_pickle('train_deepfm_rseult.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "data = pd.concat([train_df,test_df],axis = 0,sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_data = pd.read_pickle('../pickle/device_new_app.pickle')\n",
    "tag_data = pd.read_pickle('../pickle/tag_weight_new_data.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15030273, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_label = data['deviceid']\n",
    "del train_df\n",
    "del test_df\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label = pd.DataFrame(data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label = data_label.merge(app_data,how = 'left',on = 'deviceid')\n",
    "data_label = data_label.merge(tag_data,how = 'left',on = 'deviceid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deviceid</th>\n",
       "      <th>applist</th>\n",
       "      <th>all_tag_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8b2d7f2aed47ab32e9c6ae4f5ae00147</td>\n",
       "      <td>[app_133]</td>\n",
       "      <td>[未知]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8b2d7f2aed47ab32e9c6ae4f5ae00147</td>\n",
       "      <td>[app_133]</td>\n",
       "      <td>[未知]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>832aaa33cdf4a0938ba2c795eb3ffefd</td>\n",
       "      <td>[app_1, app_2, app_3, app_4, app_5, app_6, app...</td>\n",
       "      <td>[乔振宇, 婚姻, 离婚, 杨紫, 约会, 出轨, 夫妻, 浪漫, 王子文, 合照, 婆媳,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>832aaa33cdf4a0938ba2c795eb3ffefd</td>\n",
       "      <td>[app_1, app_2, app_3, app_4, app_5, app_6, app...</td>\n",
       "      <td>[乔振宇, 婚姻, 离婚, 杨紫, 约会, 出轨, 夫妻, 浪漫, 王子文, 合照, 婆媳,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67dd9dac18cce1a6d79e8f20eefd98ab</td>\n",
       "      <td>[app_84, app_85, app_4, app_5, app_86, app_87,...</td>\n",
       "      <td>[片段, 社会热点, 美食, --其他, 花絮片段, 陆军, 坦克, 机枪, 家庭, 武器,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           deviceid  \\\n",
       "0  8b2d7f2aed47ab32e9c6ae4f5ae00147   \n",
       "1  8b2d7f2aed47ab32e9c6ae4f5ae00147   \n",
       "2  832aaa33cdf4a0938ba2c795eb3ffefd   \n",
       "3  832aaa33cdf4a0938ba2c795eb3ffefd   \n",
       "4  67dd9dac18cce1a6d79e8f20eefd98ab   \n",
       "\n",
       "                                             applist  \\\n",
       "0                                          [app_133]   \n",
       "1                                          [app_133]   \n",
       "2  [app_1, app_2, app_3, app_4, app_5, app_6, app...   \n",
       "3  [app_1, app_2, app_3, app_4, app_5, app_6, app...   \n",
       "4  [app_84, app_85, app_4, app_5, app_86, app_87,...   \n",
       "\n",
       "                                        all_tag_word  \n",
       "0                                               [未知]  \n",
       "1                                               [未知]  \n",
       "2  [乔振宇, 婚姻, 离婚, 杨紫, 约会, 出轨, 夫妻, 浪漫, 王子文, 合照, 婆媳,...  \n",
       "3  [乔振宇, 婚姻, 离婚, 杨紫, 约会, 出轨, 夫妻, 浪漫, 王子文, 合照, 婆媳,...  \n",
       "4  [片段, 社会热点, 美食, --其他, 花絮片段, 陆军, 坦克, 机枪, 家庭, 武器,...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data_label['app_len']\n",
    "del data_label['all_tag_weight']\n",
    "\n",
    "data_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tokenizer 序列化文本\n",
    "def set_tokenizer(docs, split_char=' ', max_len=100):\n",
    "    '''\n",
    "    输入\n",
    "    docs:文本列表\n",
    "    split_char:按什么字符切割\n",
    "    max_len:截取的最大长度\n",
    "    \n",
    "    输出\n",
    "    X:序列化后的数据\n",
    "    word_index:文本和数字对应的索引\n",
    "    '''\n",
    "    tokenizer = Tokenizer(lower=False, char_level=False, split=split_char)\n",
    "    tokenizer.fit_on_texts(docs)\n",
    "    X = tokenizer.texts_to_sequences(docs)\n",
    "    maxlen = max_len\n",
    "    X = pad_sequences(X, maxlen=maxlen, value=0)\n",
    "    word_index=tokenizer.word_index\n",
    "    return X, word_index\n",
    "\n",
    "### 做embedding 这里采用word2vec 可以换成其他例如（glove词向量）\n",
    "def trian_save_word2vec(docs, embed_size=300, save_name='w2v.txt', split_char=' '):\n",
    "    '''\n",
    "    输入\n",
    "    docs:输入的文本列表\n",
    "    embed_size:embed长度\n",
    "    save_name:保存的word2vec位置\n",
    "    \n",
    "    输出\n",
    "    w2v:返回的模型\n",
    "    '''\n",
    "    input_docs = []\n",
    "    for i in docs:\n",
    "        input_docs.append(i.split(split_char))\n",
    "    logging.basicConfig(\n",
    "    format='%(asctime)s:%(levelname)s:%(message)s', level=logging.INFO)\n",
    "    w2v = Word2Vec(input_docs, size=embed_size, sg=1, window=8, seed=1017, workers=24, min_count=1, iter=10)\n",
    "    w2v.wv.save_word2vec_format(save_name)\n",
    "    print(\"w2v model done\")\n",
    "    return w2v\n",
    "\n",
    "# 得到embedding矩阵\n",
    "def get_embedding_matrix(word_index, embed_size=300, Emed_path=\"w2v_300.txt\"):\n",
    "    embeddings_index = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "        Emed_path, binary=False)\n",
    "    nb_words = len(word_index)+1\n",
    "    embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "    count = 0\n",
    "    for word, i in tqdm(word_index.items()):\n",
    "        if i >= nb_words:\n",
    "            continue\n",
    "        try:\n",
    "            embedding_vector = embeddings_index[word]\n",
    "        except:\n",
    "            embedding_vector = np.zeros(embed_size)\n",
    "            count += 1\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector    \n",
    "    print(\"null cnt\",count)\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_data(row):\n",
    "    review = ''\n",
    "    for i in row:\n",
    "        review += i + ' '\n",
    "    return review\n",
    "\n",
    "text_1_list = list(data_label['applist'].apply(lambda row:get_list_data(row)))\n",
    "text_2_list = list(data_label['all_tag_word'].apply(lambda row:get_list_data(row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, index_1 = set_tokenizer(text_1_list, split_char=' ', max_len=160)\n",
    "x2, index_2 = set_tokenizer(text_2_list, split_char=' ', max_len=160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 值得提醒的是这个保存方法是采用w2v.wv.save_word2vec_format\n",
    "# 因此你如果载入自己训练模型的时候，需要载入后再按照这个函数来保存再在emed_path中输入\n",
    "trian_save_word2vec(text_1_list, save_name='w2v_model/cate_w2v_300.txt', split_char=' ')\n",
    "gc.collect()\n",
    "trian_save_word2vec(text_1_list, save_name='w2v_model/w2v_300.txt', split_char=' ')\n",
    "gc.collect()\n",
    "# 得到emb矩阵\n",
    "emb1 = get_embedding_matrix(index_1, Emed_path='w2v_model/cate_w2v_300.txt')\n",
    "emb2 = get_embedding_matrix(index_2, Emed_path='w2v_model/w2v_300.txt')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(-1)\n",
    "# 处理类别特征\n",
    "for col in cate_fea:\n",
    "    df[col] = df[col].map(df[col].value_counts().rank()/len(df[col].unique()))\n",
    "# 处理数值特征\n",
    "for i in num_fea\n",
    "    ss=StandardScaler()\n",
    "    df[col] = ss.fit_transform(df[col])\n",
    "num_feature_input = len(cate_fea + num_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 区分开train和valid,test\n",
    "# 这里是假设三输入\n",
    "train_data = data[data['age_group']!=-1]\n",
    "train_input_1 = x1[:len(train_data)]\n",
    "test_input_1 = x1[len(train_data):]\n",
    "train_input_2 = x2[:len(train_data)]\n",
    "test_input_2 = x2[len(train_data):]\n",
    "train_input_3 = df[:len(train_data)][]\n",
    "test_input_3 = df[len(train_data):][]\n",
    "label = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zsy/anaconda3/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea185c9a4904afdace33943f30f85c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25731), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "null cnt 25731\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6c0dbab7bd4236ba60173f78d825e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30394), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "null cnt 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 得到emb矩阵\n",
    "index_1 = np.load('NN_model/index_1.npy',allow_pickle = 'True')\n",
    "index_2 = np.load('NN_model/index_2.npy',allow_pickle = 'True')\n",
    "emb1 = get_embedding_matrix(index_1.tolist(), Emed_path='NN_model/app_w2v_300.txt')\n",
    "emb2 = get_embedding_matrix(index_2.tolist(), Emed_path='NN_model/tag_w2v_300.txt')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7668"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.initializers import *\n",
    "\n",
    "def model_conv(emb1, emb3, num_feature_input):\n",
    "    '''\n",
    "    注意这个inputs\n",
    "    seq1、seq2分别是两个输入\n",
    "    hin是feature层输入\n",
    "    是否做emb可选可不选，\n",
    "    这个就是我们之前训练已经得到的用于embedding的（embedding_matrix1， embedding_matrix2）\n",
    "    '''\n",
    "    K.clear_session()\n",
    "\n",
    "    emb_layer_1 = Embedding(\n",
    "        input_dim=emb1.shape[0],\n",
    "        output_dim=emb1.shape[1],\n",
    "        weights=[emb1],\n",
    "        input_length=90,\n",
    "        trainable=False\n",
    "    )\n",
    "    \n",
    "    emb_layer_3 = Embedding(\n",
    "        input_dim=emb3.shape[0],\n",
    "        output_dim=emb3.shape[1],\n",
    "        weights=[emb3],\n",
    "        input_length=600,\n",
    "        trainable=False\n",
    "    )\n",
    "    \n",
    "    \n",
    "    seq1 = Input(shape=(90,))\n",
    "    seq3 = Input(shape=(600,))    \n",
    "    \n",
    "    x1 = emb_layer_1(seq1)\n",
    "    x3 = emb_layer_3(seq3)\n",
    "    \n",
    "    sdrop=SpatialDropout1D(rate=0.2)\n",
    "\n",
    "    x1 = sdrop(x1)\n",
    "    x3 = sdrop(x3)\n",
    "    \n",
    "    x = Dropout(0.2)(Bidirectional(CuDNNLSTM(200, return_sequences=True))(x1))\n",
    "    semantic = TimeDistributed(Dense(100, activation=\"tanh\"))(x)\n",
    "    merged_1 = Lambda(lambda x: K.max(x, axis=1), output_shape=(100,))(semantic)\n",
    "    merged_1_avg = Lambda(lambda x: K.mean(x, axis=1), output_shape=(100,))(semantic)\n",
    "    \n",
    "    x = Dropout(0.2)(Bidirectional(CuDNNLSTM(200, return_sequences=True))(x3))\n",
    "    semantic = TimeDistributed(Dense(100, activation=\"tanh\"))(x)\n",
    "    merged_3 = Lambda(lambda x: K.max(x, axis=1), output_shape=(100,))(semantic)\n",
    "    merged_3_avg = Lambda(lambda x: K.mean(x, axis=1), output_shape=(100,))(semantic)\n",
    "    \n",
    "    hin = Input(shape=(num_feature_input, ))\n",
    "    htime = Dense(16, activation='relu')(hin)\n",
    "    \n",
    "    x = concatenate([merged_1, merged_3, merged_1_avg, merged_3_avg, htime])\n",
    "    \n",
    "    x = Dropout(0.2)(Activation(activation=\"relu\")(BatchNormalization()(Dense(1000)(x))))\n",
    "    x = Activation(activation=\"relu\")(BatchNormalization()(Dense(500)(x)))\n",
    "    x = Activation(activation=\"relu\")(BatchNormalization()(Dense(120)(x)))\n",
    "    pred = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=[seq1, seq3, hin], outputs=pred)\n",
    "    from keras.utils import multi_gpu_model\n",
    "#     model = multi_gpu_model(model, 2)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=Adam(lr=0.001),metrics=[\"accuracy\"])\n",
    "    return model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=1017, shuffle=True)\n",
    "oof_pred = np.zeros(len(train_input_3))\n",
    "sub = np.zeros(len(test_input_3))\n",
    "score = []\n",
    "count = 0\n",
    "if not os.path.exists(\"nn_model\"):\n",
    "    os.mkdir(\"nn_model\")\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(train_input_3, labels)):\n",
    "    print(\"FOLD | \", count+1)\n",
    "    print(\"###\"*35)\n",
    "    gc.collect()\n",
    "    filepath = \"nn_model/nn_v1_%d.h5\" % count\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max',save_weights_only=True)\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_acc', factor=0.5, patience=3, min_lr=0.0001, verbose=1)\n",
    "    earlystopping = EarlyStopping(\n",
    "        monitor='val_acc', min_delta=0.0001, patience=5, verbose=1, mode='max')\n",
    "    callbacks = [checkpoint, reduce_lr, earlystopping]\n",
    "    model_ctr = model_conv(emb1, emb2, num_feature_input)\n",
    "    if count==0:model_age.summary()\n",
    "    x1_tr, x1_va = np.array(train_input_1)[train_index], np.array(train_input_1)[test_index]    \n",
    "    x2_tr, x2_va = np.array(train_input_2)[train_index], np.array(train_input_2)[test_index]\n",
    "    x3_tr, x3_va = np.array(train_input_3)[train_index], np.array(train_input_3)[test_index]\n",
    "    y_tr, y_va = labels[train_index], labels[test_index]\n",
    "    \n",
    "    hist = model_ctr.fit([x1_tr, x2_tr, x3_tr],\n",
    "                         y_tr, batch_size=4096, epochs=50, \n",
    "                         validation_data=([x1_va, x2_va, x3_va], y_va),\n",
    "                         callbacks=callbacks, verbose=1, shuffle=True)\n",
    "\n",
    "    model_ctr.load_weights(filepath)\n",
    "    oof_pred[test_index] = model_ctr.predict([x1_va, x2_va, x3_va],batch_size=2048,verbose=1)\n",
    "    sub += model_ctr.predict([test_input_1, test_input_2, test_input_3],batch_size=2048,verbose=1)/skf.n_splits\n",
    "    score.append(np.max(hist.history['val_acc']))\n",
    "    count += 1\n",
    "print('acc:', np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
